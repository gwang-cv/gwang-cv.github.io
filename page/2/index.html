<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <meta http-equiv="X-UA-Compatible" content="IE=edge" >
  <title>Hello World</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Hello World">
<meta property="og:url" content="http://gwang-cv.github.io/page/2/index.html">
<meta property="og:site_name" content="Hello World">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Hello World">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link rel="stylesheet" href="/css/style.css">
</head>

<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			
			<img lazy-src="https://sites.google.com/site/2013gwang/logss.jpg" class="js-avatar">
			
		</a>

		<hgroup>
		  <h1 class="header-author"><a href="/">Gang Wang</a></h1>
		</hgroup>

		
		<p class="header-subtitle">a computer vision researchGO</p>
		

		
			<div class="switch-btn">
				<div class="icon">
					<div class="icon-ctn">
						<div class="icon-wrap icon-house" data-idx="0">
							<div class="birdhouse"></div>
							<div class="birdhouse_holes"></div>
						</div>
						<div class="icon-wrap icon-ribbon hide" data-idx="1">
							<div class="ribbon"></div>
						</div>
						
						
						<div class="icon-wrap icon-me hide" data-idx="3">
							<div class="user"></div>
							<div class="shoulder"></div>
						</div>
						
					</div>
					
				</div>
				<div class="tips-box hide">
					<div class="tips-arrow"></div>
					<ul class="tips-inner">
						<li>Menu</li>
						<li>Tags</li>
						
						
						<li>About</li>
						
					</ul>
				</div>
			</div>
		

		<div class="switch-area">
			<div class="switch-wrap">
				<section class="switch-part switch-part1">
					<nav class="header-menu">
						<ul>
						
							<li><a href="/">Home</a></li>
				        
							<li><a href="/archives">Archives</a></li>
				        
						</ul>
					</nav>
					<nav class="header-nav">
						<div class="social">
							
								<a class="github" target="_blank" href="https://github.com/gwang-cv" title="github">github</a>
					        
								<a class="weibo" target="_blank" href="http://weibo.com/messiwang" title="weibo">weibo</a>
					        
								<a class="google" target="_blank" href="https://sites.google.com/site/2013gwang/" title="google">google</a>
					        
						</div>
					</nav>
				</section>
				
				
				<section class="switch-part switch-part2">
					<div class="widget tagcloud" id="js-tagcloud">
						<a href="/tags/Debug/" style="font-size: 12.5px;">Debug</a> <a href="/tags/DeepLearning/" style="font-size: 20px;">DeepLearning</a> <a href="/tags/ML/" style="font-size: 10px;">ML</a> <a href="/tags/Mac/" style="font-size: 17.5px;">Mac</a> <a href="/tags/Math/" style="font-size: 10px;">Math</a> <a href="/tags/Matlab/" style="font-size: 10px;">Matlab</a> <a href="/tags/Python/" style="font-size: 15px;">Python</a> <a href="/tags/Researcher/" style="font-size: 10px;">Researcher</a> <a href="/tags/python/" style="font-size: 10px;">python</a>
					</div>
				</section>
				
				
				

				
				
				<section class="switch-part switch-part3">
				
					<div id="js-aboutme">Hello, I&#39;m Gang Wang. This is my blog, enjoy it.</div>
				</section>
				
			</div>
		</div>
	</header>				
</div>

    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
  	<div class="overlay">
  		<div class="slider-trigger"></div>
  		<h1 class="header-author js-mobile-header hide">Gang Wang</h1>
  	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
			
				<img lazy-src="https://sites.google.com/site/2013gwang/logss.jpg" class="js-avatar">
			
			</div>
			<hgroup>
			  <h1 class="header-author">Gang Wang</h1>
			</hgroup>
			
			<p class="header-subtitle">a computer vision researchGO</p>
			
			<nav class="header-menu">
				<ul>
				
					<li><a href="/">Home</a></li>
		        
					<li><a href="/archives">Archives</a></li>
		        
		        <div class="clearfix"></div>
				</ul>
			</nav>
			<nav class="header-nav">
				<div class="social">
					
						<a class="github" target="_blank" href="https://github.com/gwang-cv" title="github">github</a>
			        
						<a class="weibo" target="_blank" href="http://weibo.com/messiwang" title="weibo">weibo</a>
			        
						<a class="google" target="_blank" href="https://sites.google.com/site/2013gwang/" title="google">google</a>
			        
				</div>
			</nav>
		</header>				
	</div>
</nav>

      <div class="body-wrap">
  
    <article id="post-Python除法" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2017/07/06/Python除法/" class="article-date">
  	<time datetime="2017-07-06T03:20:16.000Z" itemprop="datePublished">2017-07-06</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/07/06/Python除法/">Python除法</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>python 2.x版本中存在两种除法运算:</p>
<p>即所谓的true除法和floor除法。</p>
<p>当使用x/y形式进行除法运算时，如果x和y都是整形，那么运算的会对结果进行截取，取运算的整数部分，比如2/3的运算结果是0；</p>
<p>如果x和y中有一个是浮点数，那么会进行所谓的true除法，比如2.0/3的结果是 0.66666666666666663。</p>
<p>另外一种除法是采用x//y的形式，那么这里采用的是所谓floor除法，即得到不大于结果的最大整数值，这个运算时与操作数无关的。比如2//3的结果是0，-2//3的结果是-1，-2.0//3的结果是-1.0。</p>
<hr>
<p>在python 3.x中，x/y将只执行true除法，而与操作数无关；x//y则执行floor除法。</p>
<hr>
<p>如果需要在2.x版本的python中进行这样的用法，则需要在代码最前加入from <strong>future</strong> import division的声明。</p>
<p>Python代码 </p>
<pre><code><span class="keyword">from</span> __future__ <span class="keyword">import</span> division  
a=<span class="number">2</span>/<span class="number">3</span>                  
</code></pre><p>这时变量a的结果将是0.66666666666666663，而不是原来的0了。</p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/python/">python</a></li></ul>
	</div>

      
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/Debug/">Debug</a>
	</div>


      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-Ubuntu16.04+Titan X+CUDA8.0+cudnn5" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/12/30/Ubuntu16.04+Titan X+CUDA8.0+cudnn5/" class="article-date">
  	<time datetime="2016-12-30T03:15:04.000Z" itemprop="datePublished">2016-12-30</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/12/30/Ubuntu16.04+Titan X+CUDA8.0+cudnn5/">Ubuntu16.04+Titan X+CUDA8.0+cudnn5.1+Caffe</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>1.安装Ubuntu16.04 LTS x64</strong></p>
<p>利用工具rufus制作USB系统盘(官方下载64位版本: <a href="http://www.ubuntu.com/download/alternative-downloads" target="_blank" rel="external">ubuntu-16.04-desktop-amd64.iso</a>)，因为已有Win7系统，此处选择“Install Ubuntu alongside Windows Boot Manager”，分区采用默认选择，语言选择English，安装完毕。</p>
<p><em>注：此时显示器VGA接口接到主板集成显卡接口上。</em><br><em>PS: or always plug VGA to Nvidia Titan X, and then set “nomodeset” in /etc/default/grub, then install nvidia drivers in tty…</em></p>
<p><strong>2.更新源</strong></p>
<pre><code>cd /etc/apt/
sudo cp sources<span class="class">.list</span> sources<span class="class">.list</span><span class="class">.bak</span>
sudo gedit sources.list
</code></pre><p>在sources.list文件头部添加如下源：</p>
<pre><code>deb <span class="string">http:</span><span class="comment">//mirrors.ustc.edu.cn/ubuntu/ xenial main restricted universe multiverse</span>
deb <span class="string">http:</span><span class="comment">//mirrors.ustc.edu.cn/ubuntu/ xenial-security main restricted universe multiverse</span>
deb <span class="string">http:</span><span class="comment">//mirrors.ustc.edu.cn/ubuntu/ xenial-updates main restricted universe multiverse</span>
deb <span class="string">http:</span><span class="comment">//mirrors.ustc.edu.cn/ubuntu/ xenial-proposed main restricted universe multiverse</span>
deb <span class="string">http:</span><span class="comment">//mirrors.ustc.edu.cn/ubuntu/ xenial-backports main restricted universe multiverse</span>
deb-src <span class="string">http:</span><span class="comment">//mirrors.ustc.edu.cn/ubuntu/ xenial main restricted universe multiverse</span>
deb-src <span class="string">http:</span><span class="comment">//mirrors.ustc.edu.cn/ubuntu/ xenial-security main restricted universe multiverse</span>
deb-src <span class="string">http:</span><span class="comment">//mirrors.ustc.edu.cn/ubuntu/ xenial-updates main restricted universe multiverse</span>
deb-src <span class="string">http:</span><span class="comment">//mirrors.ustc.edu.cn/ubuntu/ xenial-proposed main restricted universe multiverse</span>
deb-src <span class="string">http:</span><span class="comment">//mirrors.ustc.edu.cn/ubuntu/ xenial-backports main restricted universe multiverse</span>
</code></pre><p>然后更新源和安装的包:</p>
<pre><code>sudo apt-<span class="built_in">get</span> <span class="keyword">update</span>
sudo apt-<span class="built_in">get</span> upgrade
</code></pre><p><strong>3.安装NVIDIA显卡驱动</strong></p>
<p>采用ppa安装方式，没选择最新的nvidia-370，我选择了nvidia-367。</p>
<p>Ctrl+Alt+F1进入tty命令控制台，停止lightdm，然后开始安装驱动。</p>
<pre><code>sudo services lightdm stop

sudo<span class="instruction"> add-apt-repository </span>ppa:graphics-drivers/ppa
sudo apt-get update
sudo apt-get install nvidia-367
sudo apt-get install mesa-common-dev
sudo apt-get install freeglut3-dev
sudo reboot
</code></pre><p><em>将显示器VGA接口换到NVIDIA显卡上。</em></p>
<p>PS: If login loop, then Ctrl+Alt+F1, and then uninstall nvidia driver and reinstall again..</p>
<pre><code>sudo apt-get purge nvidia-*
sudo<span class="instruction"> add-apt-repository </span>ppa:graphics-drivers/ppa
sudo apt-get update 
sudo apt-get install nvidia-367
sudo apt-get install mesa-common-dev
sudo apt-get install freeglut3-dev
sudo reboot
</code></pre><p><strong>4.修改分辨率</strong></p>
<p>启动到界面之后发现分辨率只有1366x768，显示器适合1920x1080，采用xrandr并修改xorg.conf来解决。[或者，更容易的是采用一个HDMI的转接头来解决！]</p>
<pre><code>sudo gedit /etc/X11/xorg<span class="class">.conf</span>
修改如下：
HorizSync <span class="number">31.0</span> - <span class="number">84.0</span>
VertRefresh <span class="number">56.0</span>-<span class="number">77.0</span>
</code></pre><p>即最终的xorg.conf文件为：</p>
<pre><code><span class="title">Section "Device"    </span>
    Identifier <span class="string">"Configured Video Device"</span>
EndSection

<span class="title">Section "Monitor"</span>
    Identifier <span class="string">"Configured Monitor"</span>
    Horizsync 30-84
    Vertrefresh 56-77
EndSection

<span class="title">Section "Screen"</span>
Identifier <span class="string">"Default Screen"</span>
Monitor <span class="string">"Configured Monitor"</span>
Device <span class="string">"Configured Video Device"</span>
    SubSection <span class="string">"Display"</span>
        Modes <span class="string">"1920x1080"</span> <span class="string">"1360x768"</span> <span class="string">"1024x768"</span> <span class="string">"1152x864"</span>
    EndSubSection
EndSection        
</code></pre><p>注销系统再次登录后，选择适合的桌面分辨率即可。</p>
<p><strong>5.安装CUDA8.0</strong></p>
<p>到官网下载<a href="https://developer.nvidia.com/cuda-release-candidate-download" target="_blank" rel="external">cuda_8.0.44_linux.run</a>，复制到根目录下。</p>
<pre><code>sudo sh cuda_8.0.44_linux.<span class="command">run</span> <span class="comment">--tmpdir=/tmp/</span>
</code></pre><p>遇到问题：incomplete installation，然后执行</p>
<pre><code>sudo apt-<span class="built_in">get</span> install freeglut3-<span class="built_in">dev</span> build-essential libx11-<span class="built_in">dev</span> libxmu-<span class="built_in">dev</span> libxi-<span class="built_in">dev</span> libgl1-mesa-glx libglu1-mesa libglu1-mesa-<span class="built_in">dev</span>
sudo sh cuda_8.0.44_linux.run -silent -driver
</code></pre><p>注：此时安装过程中提示是否要安装NVIDIA驱动时选择no。其他选择yes或默认即可。</p>
<pre><code>Install NVIDIA Accelerated Graphics Driver <span class="keyword">for</span> Linux-x86_64 <span class="number">361.62</span>? <span class="params">(y)</span>es/<span class="params">(n)</span>o/<span class="params">(q)</span>uit: n
</code></pre><p>安装完毕后声明环境变量：</p>
<pre><code><span class="title">sudo</span> gedit ~/.bashrc
</code></pre><p>在.bashrc尾部添加如下内容：</p>
<pre><code>export <span class="constant">PATH</span>=<span class="regexp">/usr/local</span><span class="regexp">/cuda-8.0/bin</span><span class="variable">${</span><span class="constant">PATH</span><span class="symbol">:+</span><span class="symbol">:</span><span class="variable">${</span><span class="constant">PATH</span>}}
export <span class="constant">LD_LIBRARY_PATH</span>=<span class="regexp">/usr/local</span><span class="regexp">/cuda-8.0/lib</span>64<span class="variable">${</span><span class="constant">LD_LIBRARY_PATH</span><span class="symbol">:+</span><span class="symbol">:</span><span class="variable">${</span><span class="constant">LD_LIBRARY_PATH</span>}}
</code></pre><p>测试下安装是否成功：</p>
<p>测试1：</p>
<pre><code>cd NVIDI<span class="built_in">A_CUDA</span>-<span class="number">8.0</span>_Samples/
nvidia-smi
</code></pre><p>输出：</p>
<pre><code>Tue Oct 18 15:20:34 2016       
+-----------------------------------------------------------------------------+
|<span class="string"> NVIDIA-SMI 367.44                 Driver Version: 367.44                    </span>|
|<span class="string">-------------------------------+----------------------+----------------------+
</span>|<span class="string"> GPU  Name        Persistence-M</span>|<span class="string"> Bus-Id        Disp.A </span>|<span class="string"> Volatile Uncorr. ECC </span>|
|<span class="string"> Fan  Temp  Perf  Pwr:Usage/Cap</span>|<span class="string">         Memory-Usage </span>|<span class="string"> GPU-Util  Compute M. </span>|
|<span class="string">===============================+======================+======================</span>|
|<span class="string">   0  GeForce GTX TIT...  Off  </span>|<span class="string"> 0000:01:00.0      On </span>|<span class="string">                  N/A </span>|
|<span class="string"> 22%   48C    P5    27W / 250W </span>|<span class="string">    169MiB / 12205MiB </span>|<span class="string">      1%      Default </span>|
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
|<span class="string"> Processes:                                                       GPU Memory </span>|
|<span class="string">  GPU       PID  Type  Process name                               Usage      </span>|
|<span class="string">=============================================================================</span>|
|<span class="string">    0      2421    G   /usr/lib/xorg/Xorg                             105MiB </span>|
|<span class="string">    0     10062    G   compiz                                          63MiB </span>|
+-----------------------------------------------------------------------------+
</code></pre><p>测试2：</p>
<pre><code>cd <span class="number">1</span>_Utilities/deviceQuery
make
<span class="attribute">...</span><span class="attribute">...</span><span class="built_in">..
</span><span class="built_in">.</span>/deviceQuery 
</code></pre><p>输出：</p>
<pre><code>./deviceQuery Starting...

 CUDA Device Query (Runtime API) version (CUDART static linking)

Detected 1 CUDA Capable device(s)

Device 0: "GeForce GTX TITAN X"
  CUDA Driver Version / Runtime Version          8.0 / 8.0
  CUDA Capability Major/Minor version number:    5.2
  Total amount of global memory:                 12205 MBytes (12798197760 bytes)
  (24) Multiprocessors, (128) CUDA Cores/MP:     3072 CUDA Cores
  GPU Max Clock rate:                            1076 MHz (1.08 GHz)
  Memory Clock rate:                             3505 Mhz
  Memory Bus Width:                              384-bit
  L2 <span class="operator"><span class="keyword">Cache</span> <span class="keyword">Size</span>:                                 <span class="number">3145728</span> bytes
  Maximum Texture Dimension <span class="keyword">Size</span> (x,y,z)         <span class="number">1</span>D=(<span class="number">65536</span>), <span class="number">2</span>D=(<span class="number">65536</span>, <span class="number">65536</span>), <span class="number">3</span>D=(<span class="number">4096</span>, <span class="number">4096</span>, <span class="number">4096</span>)
  Maximum Layered <span class="number">1</span>D Texture <span class="keyword">Size</span>, (num) layers  <span class="number">1</span>D=(<span class="number">16384</span>), <span class="number">2048</span> layers
  Maximum Layered <span class="number">2</span>D Texture <span class="keyword">Size</span>, (num) layers  <span class="number">2</span>D=(<span class="number">16384</span>, <span class="number">16384</span>), <span class="number">2048</span> layers
  Total amount <span class="keyword">of</span> constant memory:               <span class="number">65536</span> bytes
  Total amount <span class="keyword">of</span> shared memory per block:       <span class="number">49152</span> bytes
  Total <span class="built_in">number</span> <span class="keyword">of</span> registers available per block: <span class="number">65536</span>
  Warp <span class="keyword">size</span>:                                     <span class="number">32</span>
  Maximum <span class="built_in">number</span> <span class="keyword">of</span> threads per multiprocessor:  <span class="number">2048</span>
  Maximum <span class="built_in">number</span> <span class="keyword">of</span> threads per block:           <span class="number">1024</span>
  <span class="keyword">Max</span> dimension <span class="keyword">size</span> <span class="keyword">of</span> a thread block (x,y,z): (<span class="number">1024</span>, <span class="number">1024</span>, <span class="number">64</span>)
  <span class="keyword">Max</span> dimension <span class="keyword">size</span> <span class="keyword">of</span> a grid <span class="keyword">size</span>    (x,y,z): (<span class="number">2147483647</span>, <span class="number">65535</span>, <span class="number">65535</span>)
  Maximum memory pitch:                          <span class="number">2147483647</span> bytes
  Texture alignment:                             <span class="number">512</span> bytes
  <span class="keyword">Concurrent</span> copy <span class="keyword">and</span> kernel execution:          Yes <span class="keyword">with</span> <span class="number">2</span> copy <span class="keyword">engine</span>(s)
  Run <span class="keyword">time</span> <span class="keyword">limit</span> <span class="keyword">on</span> kernels:                     Yes
  Integrated GPU sharing Host Memory:            <span class="keyword">No</span>
  Support host page-locked memory mapping:       Yes
  Alignment requirement <span class="keyword">for</span> Surfaces:            Yes
  Device has ECC support:                        Disabled
  Device supports Unified Addressing (UVA):      Yes
  Device PCI <span class="keyword">Domain</span> ID / Bus ID / location ID:   <span class="number">0</span> / <span class="number">1</span> / <span class="number">0</span>
  Compute <span class="keyword">Mode</span>:
     &lt; <span class="keyword">Default</span> (multiple host threads can <span class="keyword">use</span> ::cudaSetDevice() <span class="keyword">with</span> device simultaneously) &gt;

deviceQuery, CUDA Driver = CUDART, CUDA Driver <span class="keyword">Version</span> = <span class="number">8.0</span>, CUDA Runtime <span class="keyword">Version</span> = <span class="number">8.0</span>, NumDevs = <span class="number">1</span>, Device0 = GeForce GTX TITAN X
Result = PASS</span>
</code></pre><p>测试3：</p>
<pre><code>cd <span class="built_in">..</span><span class="subst">/</span><span class="built_in">..</span>/<span class="number">5</span>_Simulations/nbody<span class="subst">/</span>
make
<span class="attribute">...</span><span class="attribute">...</span><span class="attribute">...</span>
<span class="built_in">.</span>/nbody <span class="attribute">-benchmark</span> <span class="attribute">-numbodies</span><span class="subst">=</span><span class="number">256000</span> <span class="attribute">-device</span><span class="subst">=</span><span class="number">0</span>
</code></pre><p>输出：</p>
<pre><code>mark -numbodies=<span class="number">256000</span> -device=<span class="number">0</span>
Run <span class="string">"nbody -benchmark [-numbodies=&lt;numBodies&gt;]"</span> <span class="keyword">to</span> measure performance.
-fullscreen       (<span class="command">run</span> n-body simulation <span class="keyword">in</span> fullscreen mode)
-fp64             (use double precision floating point values <span class="keyword">for</span> simulation)
-hostmem          (stores simulation data <span class="keyword">in</span> host memory)
-benchmark        (<span class="command">run</span> benchmark <span class="keyword">to</span> measure performance) 
-numbodies=&lt;N&gt;    (<span class="type">number</span> <span class="keyword">of</span> bodies (&gt;= <span class="number">1</span>) <span class="keyword">to</span> <span class="command">run</span> <span class="keyword">in</span> simulation) 
-device=&lt;d&gt;       (<span class="keyword">where</span> d=<span class="number">0</span>,<span class="number">1</span>,<span class="number">2.</span>... <span class="keyword">for</span> <span class="keyword">the</span> CUDA device <span class="keyword">to</span> use)
-numdevices=&lt;i&gt;   (<span class="keyword">where</span> i=(<span class="type">number</span> <span class="keyword">of</span> CUDA devices &gt; <span class="number">0</span>) <span class="keyword">to</span> use <span class="keyword">for</span> simulation)
-compare          (compares simulation results <span class="property">running</span> once <span class="function_start"><span class="keyword">on</span></span> <span class="keyword">the</span> default GPU <span class="keyword">and</span> once <span class="function_start"><span class="keyword">on</span></span> <span class="keyword">the</span> CPU)
-cpu              (<span class="command">run</span> n-body simulation <span class="function_start"><span class="keyword">on</span></span> <span class="keyword">the</span> CPU)
-tipsy=&lt;<span class="type">file</span>.bin&gt; (load a tipsy model <span class="type">file</span> <span class="keyword">for</span> simulation)

NOTE: The CUDA Samples are <span class="keyword">not</span> meant <span class="keyword">for</span> performance measurements. Results may vary when GPU Boost <span class="keyword">is</span> enabled.

&gt; Windowed mode
&gt; Simulation data stored <span class="keyword">in</span> video memory
&gt; Single precision floating point simulation
&gt; <span class="number">1</span> Devices used <span class="keyword">for</span> simulation
gpuDeviceInit() CUDA Device [<span class="number">0</span>]: <span class="string">"GeForce GTX TITAN X
&gt; Compute 5.2 CUDA device: [GeForce GTX TITAN X]
number of bodies = 256000
256000 bodies, total time for 10 iterations: 3104.433 ms
= 211.105 billion interactions per second
= 4222.091 single-precision GFLOP/s at 20 flops per interaction</span>
</code></pre><p><strong>6.安装OpenCV 3.1.0</strong></p>
<p>从官网下载zip源代码，解压到根目录下。<br>安装依赖：</p>
<pre><code>sudo apt-<span class="built_in">get</span> -y remove ffmpeg x264 libx264-<span class="built_in">dev</span>
sudo apt-<span class="built_in">get</span> -y install libopencv-<span class="built_in">dev</span> build-essential checkinstall cmake pkg-config yasm  libjpeg-<span class="built_in">dev</span> libjasper-<span class="built_in">dev</span> libavcodec-<span class="built_in">dev</span> libavformat-<span class="built_in">dev</span> libswscale-<span class="built_in">dev</span> libdc1394-<span class="number">22</span>-<span class="built_in">dev</span>  libgstreamer0.10-<span class="built_in">dev</span> libgstreamer-plugins-base0.10-<span class="built_in">dev</span> libv4l-<span class="built_in">dev</span> python-<span class="built_in">dev</span> python-numpy libtbb-<span class="built_in">dev</span> libqt4-<span class="built_in">dev</span> libgtk2.0-<span class="built_in">dev</span> libfaac-<span class="built_in">dev</span> libmp3lame-<span class="built_in">dev</span> libopencore-amrnb-<span class="built_in">dev</span> libopencore-amrwb-<span class="built_in">dev</span> libtheora-<span class="built_in">dev</span> libvorbis-<span class="built_in">dev</span> libxvidcore-<span class="built_in">dev</span> x264 v4l-utils ffmpeg libgtk2.0-<span class="built_in">dev</span>

cd opencv-<span class="number">3.1</span>.0
mkdir build   
cd build/
cmake -D CMAKE_BUILD_TYPE=RELEASE -D CMAKE_INSTALL_PREFIX=/usr/local -D WITH_TBB=ON -D BUILD_NEW_PYTHON_SUPPORT=ON -D WITH_V4L=ON -D INSTALL_C_EXAMPLES=ON -D INSTALL_PYTHON_EXAMPLES=ON -D BUILD_EXAMPLES=ON -D WITH_QT=ON -D WITH_OPENGL=ON ..
make -j8
sudo make install
</code></pre><p>遇到的错误：Errors</p>
<pre><code><span class="keyword">error</span>: ‘NppiGraphcutState’ has <span class="keyword">not</span> been declared
<span class="keyword">error</span>: ‘NppiGraphcutState’ <span class="keyword">does</span> <span class="keyword">not</span> <span class="property">name</span> a type
...
</code></pre><p>解决方法：(由于CUDA版本高于8.0，所以需要做如下修改。在源文件中找到“graphcuts.cpp”)</p>
<p>将：</p>
<pre><code><span class="preprocessor">#<span class="keyword">include</span> "precomp.hpp"</span>
<span class="preprocessor">#<span class="keyword">if</span> !defined (HAVE_CUDA) || defined (CUDA_DISABLER)</span>
</code></pre><p>改为:</p>
<pre><code><span class="preprocessor">#<span class="keyword">include</span> "precomp.hpp"</span>
<span class="preprocessor">#<span class="keyword">if</span> !defined (HAVE_CUDA) || defined (CUDA_DISABLER)  || (CUDART_VERSION &gt;= 8000)</span>
</code></pre><p>because graphcuts is not supported directly with CUDA8 anymore.</p>
<p>安装成功后配置环境：</p>
<pre><code>sudo <span class="keyword">sh</span> -c 'echo <span class="string">"/usr/local/lib"</span> &gt; /etc/ld.<span class="keyword">so</span>.<span class="keyword">conf</span>.<span class="keyword">d</span>/opencv.<span class="keyword">conf</span>'
sudo ldconfig
</code></pre><p>测试OpenCV安装是否成功：</p>
<pre><code><span class="built_in">mkdir</span> DisplayImage  
<span class="built_in">cd</span> DisplayImage 
gedit DisplayImage.cpp 
</code></pre><p>添加代码：</p>
<pre><code><span class="preprocessor">#<span class="keyword">include</span> &lt;stdio.h&gt;  </span>
<span class="preprocessor">#<span class="keyword">include</span> &lt;opencv2/opencv.hpp&gt;  </span>
<span class="keyword">using</span> <span class="keyword">namespace</span> cv;  

<span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span>** argv)</span>  
</span>{  
     <span class="keyword">if</span>(argc!= <span class="number">2</span>)  
     {  
               <span class="built_in">printf</span>(<span class="string">"usage:DisplayImage.out &lt;Image_Path&gt;\n"</span>);  
               <span class="keyword">return</span> -<span class="number">1</span>;  
     }  

     Mat image;  
     image= imread(argv[<span class="number">1</span>], <span class="number">1</span>);  

    <span class="keyword">if</span>(!image.data)  
    {  
               <span class="built_in">printf</span>(<span class="string">"Noimage data\n"</span>);  
               <span class="keyword">return</span> -<span class="number">1</span>;  
     }  

     namedWindow(<span class="string">"DisplayImage"</span>,CV_WINDOW_AUTOSIZE);  
     imshow(<span class="string">"DisplayImage"</span>,image);  

     waitKey(<span class="number">0</span>);  
     <span class="keyword">return</span> <span class="number">0</span>;  
}  
</code></pre><p>创建CMake文件：</p>
<pre><code>gedit CMakeLists<span class="class">.txt</span>  
</code></pre><p>添加内容：</p>
<pre><code><span class="function"><span class="title">cmake_minimum_required</span><span class="params">(VERSION <span class="number">2.8</span>)</span></span>  
<span class="function"><span class="title">project</span><span class="params">(DisplayImage)</span></span>  
<span class="function"><span class="title">find_package</span><span class="params">(OpenCV REQUIRED)</span></span>  
<span class="function"><span class="title">add_executable</span><span class="params">(DisplayImage DisplayImage.cpp)</span></span>  
<span class="function"><span class="title">target_link_libraries</span><span class="params">(DisplayImage ${OpenCV_LIBS})</span></span> 
</code></pre><p>编译：</p>
<pre><code>cmake .  
<span class="built_in">make</span> 
</code></pre><p>执行：</p>
<pre><code>./DisplayImage lena<span class="class">.jpg</span>  
</code></pre><p><strong>7.安装cudnn 5.1</strong></p>
<p>从官网下载<a href="https://developer.nvidia.com/cudnn" target="_blank" rel="external">cudnn-8.0-linux-x64-v5.1.tgz</a> for CUDA 8.0. 解压到当前目录：</p>
<pre><code><span class="tag">tar</span> <span class="tag">-zxvf</span> <span class="tag">cudnn-8</span><span class="class">.0-linux-x64-v5</span><span class="class">.1</span><span class="class">.tgz</span>
</code></pre><p>解压后的文件如下：</p>
<pre><code>cuda/include/cudnn<span class="class">.h</span>
cuda/lib64/libcudnn<span class="class">.so</span>
cuda/lib64/libcudnn<span class="class">.so</span>.<span class="number">5</span>
cuda/lib64/libcudnn<span class="class">.so</span>.<span class="number">5.1</span>.<span class="number">5</span>
cuda/lib64/libcudnn_static.a
</code></pre><p>然后执行：</p>
<pre><code>sudo cp cuda<span class="regexp">/include/</span>cudnn.h <span class="regexp">/usr/</span>local<span class="regexp">/cuda/</span>include/
sudo cp cuda<span class="regexp">/lib64/</span>libcudnn* <span class="regexp">/usr/</span>local<span class="regexp">/cuda/</span>lib64/
sudo chmod a+r <span class="regexp">/usr/</span>local<span class="regexp">/cuda/</span>include/cudnn.h
sudo chmod a+r <span class="regexp">/usr/</span>local<span class="regexp">/cuda/</span>lib64/libcudnn*
</code></pre><p><strong>8.安装MATLAB 2014a</strong></p>
<p>需要注意的是Ubuntu16.04 LTS的gcc版本为5.4，而Matlab2014a支持的是gcc4.7。</p>
<p>降级安装gcc/g++版本为4.7.x</p>
<p>下载gcc/g++ 4.7.x</p>
<pre><code>sudo apt-get <span class="operator"><span class="keyword">install</span> -y gcc-<span class="number">4.7</span>

sudo apt-<span class="keyword">get</span> <span class="keyword">install</span> -y g++-<span class="number">4.7</span></span>
</code></pre><p>链接gcc/g++实现降级</p>
<pre><code><span class="keyword">cd</span> /usr/bin

sudo <span class="keyword">rm</span> gcc

sudo ln -s gcc-4.7 gcc

sudo <span class="keyword">rm</span> <span class="keyword">g</span>++

sudo ln -s <span class="keyword">g</span>++-4.7 <span class="keyword">g</span>++
</code></pre><hr>
<p>升级 gcc 到 gcc-5版本</p>
<p>首先添加ppa到库：</p>
<pre><code>sudo<span class="instruction"> add-apt-repository </span>ppa:ubuntu-toolchain-r/test
sudo apt-get update
</code></pre><p>如果提示未安装，还需要先安装它的包：</p>
<pre><code>sudo apt-get <span class="operator"><span class="keyword">install</span> software-properties-common

sudo apt-<span class="keyword">get</span> <span class="keyword">upgrade</span>
sudo apt-<span class="keyword">get</span> <span class="keyword">install</span> gcc-<span class="number">5</span> g++-<span class="number">5</span></span>
</code></pre><p>（非必须）现在可以考虑刷新一下，否则locate等命令是找不到的：</p>
<pre><code><span class="title">sudo</span> updatedb &amp;&amp; sudo ldconfig
locate gcc
</code></pre><p>你会发现  gcc -v 显示出来的版本还是gcc-4.7的，因此需要更新一下链接：</p>
<pre><code>update-alternatives --install <span class="regexp">/usr/</span>bin<span class="regexp">/gcc gcc /u</span>sr<span class="regexp">/bin/g</span>cc-<span class="number">5</span> <span class="number">53</span> \
--slave <span class="regexp">/usr/</span>bin<span class="regexp">/g++ g++ /u</span>sr<span class="regexp">/bin/g</span>++-<span class="number">5</span> \
--slave <span class="regexp">/usr/</span>bin<span class="regexp">/gcc-ar gcc-ar /u</span>sr<span class="regexp">/bin/g</span>cc-ar-<span class="number">5</span> \
--slave <span class="regexp">/usr/</span>bin<span class="regexp">/gcc-nm gcc-nm /u</span>sr<span class="regexp">/bin/g</span>cc-nm-<span class="number">5</span> \
--slave <span class="regexp">/usr/</span>bin<span class="regexp">/gcc-ranlib gcc-ranlib /u</span>sr<span class="regexp">/bin/g</span>cc-ranlib-<span class="number">5</span>
</code></pre><p>=======================================================</p>
<p>用Crack文件中的install替换matlab2014安装目录下/java/jar/下的install文件，然后执行install程序</p>
<pre><code><span class="built_in">cd</span> <span class="string">"MatlabFolder"</span>
sudo ./install
</code></pre><p>注意：选择“不联网安装”；当出现密钥时，随意输入20个数字12345-67890-12345-67890即可；需要激活时选择不要联网激活，用Crack目录下的“license_405329_R2014a.lic”文件激活。</p>
<p>安装完成之后，将Crack/Linux目录下的libmwservices.so文件拷贝到/usr/local/MATLAB/R2014a/bin/glnxa64。</p>
<pre><code>cd ..
cd Crack<span class="regexp">/Linux/</span>
sudo cp libmwservices.so <span class="regexp">/usr/</span>local<span class="regexp">/MATLAB/</span>R2014a<span class="regexp">/bin/g</span>lnxa64
</code></pre><p>打开Matlab并激活：</p>
<pre><code><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/MATLAB/R2014a/bin
sudo ./matlab <span class="comment"># sudo不可缺少，否则选择激活文件后报错</span>
</code></pre><p>Test GPUdevice in Matlab:</p>
<pre><code>&gt;&gt; gpuDevice

ans = 

  CUDADevice <span class="keyword">with</span> properties:

                  Name: <span class="string">'GeForce GTX TITAN X'</span>
                 <span class="keyword">Index</span>: <span class="number">1</span>
     ComputeCapability: <span class="string">'5.2'</span>
        SupportsDouble: <span class="number">1</span>
         DriverVersion: <span class="number">8</span>
        ToolkitVersion: <span class="number">5.5000</span>
    MaxThreadsPerBlock: <span class="number">1024</span>
      MaxShmemPerBlock: <span class="number">49152</span>
    MaxThreadBlockSize: [<span class="number">1024</span> <span class="number">1024</span> <span class="number">64</span>]
           MaxGridSize: [<span class="number">2.1475</span>e+<span class="number">09</span> <span class="number">65535</span> <span class="number">65535</span>]
             SIMDWidth: <span class="number">32</span>
           TotalMemory: <span class="number">1.2796</span>e+<span class="number">10</span>
            FreeMemory: <span class="number">1.2475</span>e+<span class="number">10</span>
       MultiprocessorCount: <span class="number">24</span>
          ClockRateKHz: <span class="number">1076000</span>
           ComputeMode: <span class="string">'Default'</span>
      GPUOverlapsTransfers: <span class="number">1</span>
    KernelExecutionTimeout: <span class="number">1</span>
      CanMapHostMemory: <span class="number">1</span>
       DeviceSupported: <span class="number">1</span>
        DeviceSelected: <span class="number">1</span>
</code></pre><p><strong>9.Python</strong></p>
<p>选用Ubuntu16.04默认的安装和配置，python版本2.7.12.</p>
<p><strong>10.BLAS安装与配置</strong></p>
<p>BLAS（基础线性代数集合）是一个应用程序接口的标准。caffe官网上推荐了三种实现：ATLAS, MKL, OpenBLAS。其中ATLAS可以直接通过命令行安装。MKL是微软开发的商业工具包，面向科研和学生免费开放。申请学生版的<a href="https://software.intel.com/en-us/qualify-for-free-software/student" target="_blank" rel="external">Parallel Studio XE Cluster Edition</a>，下载parallel_studio_xe_2017.tgz。注意接收邮件中的序列号(<em>2HWS-34Z7S69B</em>)。</p>
<pre><code>tar zxvf parallel_studio_xe_2017.tgz   <span class="comment">#解压下载文件</span>
 chmod <span class="number">777</span> parallel_studio_xe_2017 -R   <span class="comment">#获取文件权限</span>
<span class="built_in">cd</span> parallel_studio_xe_2017/
 sudo ./install_GUI.sh
</code></pre><p>安装完成之后，进行相关文件的链接：</p>
<pre><code>sudo gedit /etc/ld.<span class="keyword">so</span>.<span class="keyword">conf</span>.<span class="keyword">d</span>/intel_mkl.<span class="keyword">conf</span>
</code></pre><p>添加库文件:</p>
<pre><code><span class="regexp">/opt/i</span>ntel<span class="regexp">/lib/i</span>ntel64
<span class="regexp">/opt/i</span>ntel<span class="regexp">/mkl/</span>lib<span class="regexp">/intel64</span>
</code></pre><p>编译链接使lib文件生效：</p>
<pre><code><span class="title">sudo</span> ldconfig    
</code></pre><p>如果选择安装ATLAS，在终端输入<code>sudo apt-get install libatlas-base-dev</code>即可。</p>
<p><strong>11.Caffe的安装与配置</strong></p>
<p>Caffe是由BVLC开发的一个深度学习框架，主要由贾扬清在UC Berkeley攻读PhD期间完成。参考官网上的<a href="http://caffe.berkeleyvision.org/installation.html" target="_blank" rel="external">教程</a>以及Github上针对Ubuntu15.04和16.04的<a href="https://github.com/BVLC/caffe/wiki/Ubuntu-16.04-or-15.10-Installation-Guide" target="_blank" rel="external">教程</a>。从官方下载caffe源包<a href="https://github.com/BVLC/caffe" target="_blank" rel="external">caffe-master</a>。</p>
<p>安装库文件：</p>
<pre><code>sudo apt-<span class="built_in">get</span> install libprotobuf-<span class="built_in">dev</span> libleveldb-<span class="built_in">dev</span> libsnappy-<span class="built_in">dev</span> libboost-<span class="built_in">all</span>-<span class="built_in">dev</span> libhdf5-serial-<span class="built_in">dev</span> libgflags-<span class="built_in">dev</span> libgoogle-glog-<span class="built_in">dev</span> liblmdb-<span class="built_in">dev</span> protobuf-compiler
</code></pre><p>安装依赖：</p>
<pre><code>sudo apt-<span class="built_in">get</span> install -y build-essential cmake git pkg-config libprotobuf-<span class="built_in">dev</span> libleveldb-<span class="built_in">dev</span> libsnappy-<span class="built_in">dev</span> libopencv-<span class="built_in">dev</span> libhdf5-serial-<span class="built_in">dev</span> protobuf-compiler libatlas-base-<span class="built_in">dev</span> libgflags-<span class="built_in">dev</span> libgoogle-glog-<span class="built_in">dev</span> liblmdb-<span class="built_in">dev</span>
sudo apt-<span class="built_in">get</span> install --no-install-recommends libboost-<span class="built_in">all</span>-<span class="built_in">dev</span>
</code></pre><p>Python接口依赖：</p>
<pre><code>sudo apt-<span class="built_in">get</span> install <span class="keyword">python</span>-dev
sudo apt-<span class="built_in">get</span> install -<span class="keyword">y</span> <span class="keyword">python</span>-pip
sudo apt-<span class="built_in">get</span> install -<span class="keyword">y</span> <span class="keyword">python</span>-dev
sudo apt-<span class="built_in">get</span> install -<span class="keyword">y</span> <span class="keyword">python</span>-numpy <span class="keyword">python</span>-scipy # (Python <span class="number">2.7</span> development <span class="keyword">files</span>)
sudo apt-<span class="built_in">get</span> install -<span class="keyword">y</span> <span class="keyword">python3</span>-dev
sudo apt-<span class="built_in">get</span> install -<span class="keyword">y</span> <span class="keyword">python3</span>-numpy <span class="keyword">python3</span>-scipy # (Python <span class="number">3.5</span> development <span class="keyword">files</span>)
</code></pre><p>在python文件夹内，使用root执行依赖项的检查与安装：</p>
<pre><code>sudo <span class="keyword">su</span>
<span class="keyword">cd</span> caffe-master/python
<span class="keyword">for</span> req <span class="keyword">in</span> $(<span class="keyword">cat</span> requirements.txt); <span class="keyword">do</span> pip install <span class="label">$req</span>; done
</code></pre><p>Makefile.config：</p>
<pre><code>cd ~/caffe-master
cp Makefile<span class="class">.config</span><span class="class">.example</span> Makefile.config
</code></pre><p>配置如下：</p>
<pre><code><span class="preprocessor">## Refer to http://caffe.berkeleyvision.org/installation.html</span>
<span class="preprocessor"># Contributions simplifying and improving our build system are welcome!</span>

<span class="preprocessor"># cuDNN acceleration switch (uncomment to build with cuDNN).</span>
<span class="constant"> USE_CUDNN </span>:= <span class="number">1</span>

<span class="preprocessor"># CPU-only switch (uncomment to build without GPU support).</span>
<span class="preprocessor"># CPU_ONLY := 1</span>

<span class="preprocessor"># uncomment to disable IO dependencies and corresponding data layers</span>
 <span class="constant"> USE_OPENCV </span>:= <span class="number">1</span>
<span class="preprocessor"># USE_LEVELDB := 0</span>
<span class="preprocessor"># USE_LMDB := 0</span>

<span class="preprocessor"># uncomment to allow MDB_NOLOCK when reading LMDB files (only if necessary)</span>
<span class="preprocessor">#    You should not set this flag if you will be reading LMDBs with any</span>
<span class="preprocessor">#    possibility of simultaneous read and write</span>
<span class="preprocessor"># ALLOW_LMDB_NOLOCK := 1</span>

<span class="preprocessor"># Uncomment if you're using OpenCV 3</span>
<span class="constant"> OPENCV_VERSION </span>:= <span class="number">3</span>

<span class="preprocessor"># To customize your choice of compiler, uncomment and set the following.</span>
<span class="preprocessor"># N.B. the default for Linux is g++ and the default for OSX is clang++</span>
<span class="preprocessor"># CUSTOM_CXX := g++</span>

<span class="preprocessor"># CUDA directory contains bin/ and lib/ directories that we need.</span>
CUDA_DIR := /usr/local/cuda
<span class="preprocessor"># On Ubuntu 14.04, if cuda tools are installed via</span>
<span class="preprocessor"># "sudo apt-get install nvidia-cuda-toolkit" then use this instead:</span>
<span class="preprocessor"># CUDA_DIR := /usr</span>

<span class="preprocessor"># CUDA architecture setting: going with all of them.</span>
<span class="preprocessor"># For CUDA &lt; 6.0, comment the *_50 lines for compatibility.</span>
CUDA_ARCH := -gencode arch=compute_20,code=sm_20 \
        -gencode arch=compute_20,code=sm_21 \
        -gencode arch=compute_30,code=sm_30 \
        -gencode arch=compute_35,code=sm_35 \
        -gencode arch=compute_50,code=sm_50 \
        -gencode arch=compute_50,code=compute_50

<span class="preprocessor"># BLAS choice:</span>
<span class="preprocessor"># atlas for ATLAS (default)</span>
<span class="preprocessor"># mkl for MKL</span>
<span class="preprocessor"># open for OpenBlas</span>
BLAS := mkl
<span class="preprocessor"># Custom (MKL/ATLAS/OpenBLAS) include and lib directories.</span>
<span class="preprocessor"># Leave commented to accept the defaults for your choice of BLAS</span>
<span class="preprocessor"># (which should work)!</span>
<span class="preprocessor"># BLAS_INCLUDE := /path/to/your/blas</span>
<span class="preprocessor"># BLAS_LIB := /path/to/your/blas</span>

<span class="preprocessor"># Homebrew puts openblas in a directory that is not on the standard search path</span>
<span class="preprocessor"># BLAS_INCLUDE := $(shell brew --prefix openblas)/include</span>
<span class="preprocessor"># BLAS_LIB := $(shell brew --prefix openblas)/lib</span>

<span class="preprocessor"># This is required only if you will compile the matlab interface.</span>
<span class="preprocessor"># MATLAB directory should contain the mex binary in /bin.</span>
 <span class="constant"> MATLAB_DIR </span>:= /usr/local/MATLAB/R2014a
<span class="preprocessor"># MATLAB_DIR := /Applications/MATLAB_R2012b.app</span>

<span class="preprocessor"># NOTE: this is required only if you will compile the python interface.</span>
<span class="preprocessor"># We need to be able to find Python.h and numpy/arrayobject.h.</span>
PYTHON_INCLUDE := /usr/include/python2.7 \
        /usr/local/lib/python2.7/dist-packages/numpy/core/include
<span class="preprocessor"># Anaconda Python distribution is quite popular. Include path:</span>
<span class="preprocessor"># Verify anaconda location, sometimes it's in root.</span>
<span class="preprocessor"># ANACONDA_HOME := $(HOME)/anaconda</span>
<span class="preprocessor"># PYTHON_INCLUDE := $(ANACONDA_HOME)/include \</span>
        # $(ANACONDA_HOME)/include/python2.7 \
        # $(ANACONDA_HOME)/lib/python2.7/site-packages/numpy/core/include \

<span class="preprocessor"># Uncomment to use Python 3 (default is Python 2)</span>
<span class="preprocessor"># PYTHON_LIBRARIES := boost_python3 python3.5m</span>
<span class="preprocessor"># PYTHON_INCLUDE := /usr/include/python3.5m \</span>
<span class="preprocessor">#                 /usr/lib/python3.5/dist-packages/numpy/core/include</span>

<span class="preprocessor"># We need to be able to find libpythonX.X.so or .dylib.</span>
PYTHON_LIB := /usr/lib
<span class="preprocessor"># PYTHON_LIB := $(ANACONDA_HOME)/lib</span>

<span class="preprocessor"># Homebrew installs numpy in a non standard path (keg only)</span>
<span class="preprocessor"># PYTHON_INCLUDE += $(dir $(shell python -c 'import numpy.core; print(numpy.core.__file__)'))/include</span>
<span class="preprocessor"># PYTHON_LIB += $(shell brew --prefix numpy)/lib</span>

<span class="preprocessor"># Uncomment to support layers written in Python (will link against Python libs)</span>
 <span class="constant"> WITH_PYTHON_LAYER </span>:= <span class="number">1</span>

<span class="preprocessor"># Whatever else you find you need goes here.</span>
INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include  /usr/include/hdf5/serial
LIBRARY_DIRS := $(PYTHON_LIB) /usr/local/lib /usr/lib /usr/lib/x86_64-linux-gnu /usr/lib/x86_64-linux-gnu/hdf5/serial /usr/local/share/OpenCV/<span class="number">3</span>rdparty/lib/

<span class="preprocessor"># If Homebrew is installed at a non standard location (for example your home directory) and you use it for general dependencies</span>
<span class="preprocessor"># INCLUDE_DIRS += $(shell brew --prefix)/include</span>
<span class="preprocessor"># LIBRARY_DIRS += $(shell brew --prefix)/lib</span>

<span class="preprocessor"># Uncomment to use `pkg-config` to specify OpenCV library paths.</span>
<span class="preprocessor"># (Usually not necessary -- OpenCV libraries are normally installed in one of the above $LIBRARY_DIRS.)</span>
<span class="preprocessor"># USE_PKG_CONFIG := 1</span>

<span class="preprocessor"># N.B. both build and distribute dirs are cleared on `make clean`</span>
BUILD_DIR := build
DISTRIBUTE_DIR := distribute

<span class="preprocessor"># Uncomment for debugging. Does not work on OSX due to https://github.com/BVLC/caffe/issues/171</span>
<span class="preprocessor"># DEBUG := 1</span>

<span class="preprocessor"># The ID of the GPU that 'make runtest' will use to run unit tests.</span>
TEST_GPUID := <span class="number">0</span>

<span class="preprocessor"># enable pretty build (comment to see full commands)</span>
Q ?= @
</code></pre><p>在Makefile中配置：</p>
<pre><code><span class="label">LIBRARIES</span> += glog gflags protobuf <span class="keyword">boost_system </span><span class="keyword">boost_filesystem </span>m hdf5_hl hdf5 opencv_core opencv_highgui opencv_imgproc opencv_imgcodecs
</code></pre><p>hdf5的配置：官方说这对于Ubuntu 16.04是必须的。libhdf5的版本号需要根据实际来修改下。</p>
<pre><code>sudo find . -<span class="keyword">type</span> f -exec sed -i -<span class="keyword">e</span> 's^<span class="string">"hdf5.h"</span>^<span class="string">"hdf5/serial/hdf5.h"</span>^<span class="keyword">g</span>' -<span class="keyword">e</span> 's^<span class="string">"hdf5_hl.h"</span>^<span class="string">"hdf5/serial/hdf5_hl.h"</span>^<span class="keyword">g</span>' '{}' \;
<span class="keyword">cd</span> /usr/lib/x86_64-linux-gnu
sudo ln -s libhdf5_serial.<span class="keyword">so</span>.10.1.0 libhdf5.<span class="keyword">so</span>
sudo ln -s libhdf5_serial_hl.<span class="keyword">so</span>.10.0.2 libhdf5_hl.<span class="keyword">so</span>
</code></pre><p>编译：</p>
<pre><code><span class="keyword">cd</span> ~/caffe-master
<span class="keyword">make</span> clean
<span class="keyword">make</span> <span class="keyword">all</span> -j8
<span class="keyword">make</span> test -j8
<span class="keyword">make</span> runtest -j8
<span class="keyword">make</span> pycaffe -j8
<span class="keyword">make</span> matcaffe -j8
</code></pre><p>编译接口matcaffe时，有如下警告：</p>
<pre><code>Warning: You are <span class="keyword">using</span> gcc <span class="built_in">version</span> <span class="string">'5.4.0'</span>. The <span class="built_in">version</span> <span class="operator">of</span> gcc is <span class="operator">not</span> supported. The <span class="built_in">version</span> currently supported <span class="operator">with</span> MEX is <span class="string">'4.7.x'</span>. For <span class="operator">a</span> list <span class="operator">of</span> currently supported compilers see: <span class="keyword">http</span>://www.mathworks.com/support/compilers/current_release.
Warning: You are <span class="keyword">using</span> gcc <span class="built_in">version</span> <span class="string">'5.4.0-6ubuntu1~16.04.2)'</span>. The <span class="built_in">version</span> <span class="operator">of</span> gcc is <span class="operator">not</span> supported. The <span class="built_in">version</span> currently supported <span class="operator">with</span> MEX is <span class="string">'4.7.x'</span>. For <span class="operator">a</span> list <span class="operator">of</span> currently supported compilers see: <span class="keyword">http</span>://www.mathworks.com/support/compilers/current_release.
MEX completed successfully.
</code></pre><p>若OpenCV安装不正确则会在caffe编译过程中遇到如下错误：</p>
<pre><code><span class="regexp">/usr/</span>bin/<span class="string">ld:</span> cannot find -lopencv_imgcodecs
<span class="string">collect2:</span> <span class="string">error:</span> ld returned <span class="number">1</span> exit status
<span class="string">Makefile:</span><span class="number">566</span>: recipe <span class="keyword">for</span> target <span class="string">'.build_release/lib/libcaffe.so.1.0.0-rc3'</span> failed
<span class="string">make:</span> *** [.build_release<span class="regexp">/lib/</span>libcaffe.so.1.0.0-rc3] Error <span class="number">1</span>
</code></pre><p>MNIST测试：</p>
<pre><code>sh data/mnist/get_mnist<span class="class">.sh</span>  #数据预处理
sh examples/mnist/create_mnist<span class="class">.sh</span> #重建lmdb文件。Caffe支持多种数据格式: <span class="function"><span class="title">Image</span><span class="params">(.jpg, .png等)</span></span>,leveldb,lmdb,HDF5. 生成mnist-train-lmdb 和 mnist-train-lmdb文件夹，这里包含了lmdb格式的数据集
sh examples/mnist/train_lenet<span class="class">.sh</span> #训练mnist
</code></pre><p>输出：</p>
<pre><code>I<span class="number">1019 21:48</span>:<span class="number">30.078994</span> 20063 caffe.cpp:217] Using GPUs 0
I<span class="number">1019 21:48</span>:<span class="number">30.092034</span> 20063 caffe.cpp:222] GPU 0: GeForce GTX TITAN X
...
....
.....
I<span class="number">1019 21:48</span>:<span class="number">49.415398</span> 20063 solver.cpp:317] Iteration 10000, loss = <span class="number">0.00242468</span>
I<span class="number">1019 21:48</span>:<span class="number">49.415410</span> 20063 solver.cpp:337] Iteration 10000, Testing net (#0)
I<span class="number">1019 21:48</span>:<span class="number">49.479605</span> 20063 solver.cpp:404] Test net output #0: accuracy = 0.9914
I<span class="number">1019 21:48</span>:<span class="number">49.479625</span> 20063 solver.cpp:404] Test net output #1: loss = <span class="number">0.0284448</span> (* 1 = <span class="number">0.0284448</span> loss)
I<span class="number">1019 21:48</span>:<span class="number">49.479629</span> 20063 solver.cpp:322] Optimization Done.
I<span class="number">1019 21:48</span>:<span class="number">49.479632</span> 20063 caffe.cpp:254] Optimization Done.
</code></pre><p><strong>12.Caffe下Matlab接口Demo测试</strong></p>
<p>在使用Matlab运行caffe库时，即运行文件”caffe-master/matlab/demo/classification_demo.m”。遇到的错误信息如下：</p>
<pre><code>Invalid MEX-<span class="built_in">file</span> <span class="string">'caffe-master/matlab/+caffe/private/caffe_.mexa64'</span>: libcudart.so.8.0: cannot <span class="built_in">open</span> shared object <span class="built_in">file</span>: No such <span class="built_in">file</span> <span class="operator">or</span> <span class="built_in">directory</span>
</code></pre><p>错误原因是由于Matlab找不到caffe<em>.mexa64所依赖的所有库文件的路径，此时可以使用ldd命令来查看caffe\</em>.mexa64内库文件的地址：</p>
<p>//1. 在Ubuntu系统的命令终端</p>
<pre><code><span class="keyword">ldd</span> *caffe_.mexa64
</code></pre><p>结果输出的是库文件对应的地址，与下文相对的缺失的库文件的地址可在此找到：</p>
<pre><code>libcudart<span class="class">.so</span>.<span class="number">8.0</span> =&gt; /usr/local/cuda-<span class="number">8.0</span>/lib64/libcudart<span class="class">.so</span>.<span class="number">8.0</span>
libcublas<span class="class">.so</span>.<span class="number">8.0</span> =&gt; /usr/local/cuda-<span class="number">8.0</span>/lib64/libcublas<span class="class">.so</span>.<span class="number">8.0</span>
libcurand<span class="class">.so</span>.<span class="number">8.0</span> =&gt; /usr/local/cuda-<span class="number">8.0</span>/lib64/libcurand<span class="class">.so</span>.<span class="number">8.0</span>
libcudnn<span class="class">.so</span>.<span class="number">5</span> =&gt; /usr/local/cuda-<span class="number">8.0</span>/lib64/libcudnn<span class="class">.so</span>.<span class="number">5</span>
</code></pre><p>//2. 在Matlab命令窗口输入</p>
<pre><code>!<span class="keyword">ldd</span> *caffe_.mexa64
</code></pre><p>结果在Matlab窗口的输出信息中发现：</p>
<pre><code>libcudart<span class="class">.so</span>.<span class="number">8.0</span> =&gt; not found
libcublas<span class="class">.so</span>.<span class="number">8.0</span> =&gt; not found
libcurand<span class="class">.so</span>.<span class="number">8.0</span> =&gt; not found 
libcudnn<span class="class">.so</span>.<span class="number">5</span> =&gt; not found
</code></pre><p>解决方法：通过如下命令将默认路径链接到真实路径下：</p>
<pre><code>sudo ln -s <span class="regexp">/usr/</span>local<span class="regexp">/cuda-8.0/</span>lib64<span class="regexp">/libcudart.so.8.0 /</span>usr<span class="regexp">/local/</span>MATLAB<span class="regexp">/R2014a/</span>sys<span class="regexp">/os/</span>glnxa64/libcudart.so.8.0
sudo ln -s <span class="regexp">/usr/</span>local<span class="regexp">/cuda-8.0/</span>lib64<span class="regexp">/libcublas.so.8.0 /</span>usr<span class="regexp">/local/</span>MATLAB<span class="regexp">/R2014a/</span>sys<span class="regexp">/os/</span>glnxa64/libcublas.so.8.0
sudo ln -s <span class="regexp">/usr/</span>local<span class="regexp">/cuda-8.0/</span>lib64<span class="regexp">/libcurand.so.8.0 /</span>usr<span class="regexp">/local/</span>MATLAB<span class="regexp">/R2014a/</span>sys<span class="regexp">/os/</span>glnxa64/libcurand.so.8.0
sudo ln -s <span class="regexp">/usr/</span>local<span class="regexp">/cuda-8.0/</span>lib64<span class="regexp">/libcudnn.so.5 /</span>usr<span class="regexp">/local/</span>MATLAB<span class="regexp">/R2014a/</span>sys<span class="regexp">/os/</span>glnxa64/libcudnn.so.5
</code></pre><p>重新启动Matlab使之生效。</p>
<p>另外，运行此例需要下载CaffeNet模型（Please download CaffeNet from Model Zoo before you run this demo.）<a href="https://github.com/BVLC/caffe/wiki/Model-Zoo" target="_blank" rel="external">https://github.com/BVLC/caffe/wiki/Model-Zoo</a> </p>
<p>|| <em>name: BVLC CaffeNet Model</em></p>
<p>|| <em>caffemodel: bvlc_reference_caffenet.caffemodel</em></p>
<p>|| <em>caffemodel_url: <a href="https://dl.caffe.berkeleyvision.org/bvlc_reference_caffenet.caffemodel" target="_blank" rel="external">download</a></em></p>
<p>|| <em>license: unrestricted</em></p>
<p>详细说明可参见”caffe-master/models/bvlc_reference_caffenet”…</p>
<p><strong>参考：</strong></p>
<p><a href="http://www.2cto.com/os/201607/528798.html" target="_blank" rel="external">ubuntu14.04+cuda8.0（GTX1080）+caffe安装</a></p>
<p><a href="http://www.52nlp.cn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%BB%E6%9C%BA%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE-ubuntu-16-04-nvidia-gtx-1080-cuda-8" target="_blank" rel="external">深度学习主机环境配置: Ubuntu16.04+Nvidia GTX 1080+CUDA8.0</a></p>
<p><a href="http://www.jianshu.com/p/74e9c8697372" target="_blank" rel="external">深度学习框架torch/caffe/tensor/mxnet安装</a></p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/DeepLearning/">DeepLearning</a></li></ul>
	</div>

      
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/Research/">Research</a>
	</div>


      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-Ubuntu配置——Chrome XX-Net Sogou Nodejs Hexo" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/12/30/Ubuntu配置——Chrome XX-Net Sogou Nodejs Hexo/" class="article-date">
  	<time datetime="2016-12-30T01:59:46.000Z" itemprop="datePublished">2016-12-30</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Ubuntu 配置——Chrome，XX-Net，Sogou，Nodejs，Hexo</p>
<p>1.安装Chrome</p>
<pre><code>sudo wget https://repo.fdzh<span class="preprocessor">.org</span>/chrome/google-chrome<span class="preprocessor">.list</span> -P /etc/apt/sources<span class="preprocessor">.list</span>.d/
</code></pre><p>然后导入谷歌软件的公钥，用于下面步骤中对下载软件进行验证。命令将返回“OK”。</p>
<pre><code>wget -<span class="keyword">q</span> -O - http<span class="variable">s:</span>//<span class="keyword">dl</span>.google.<span class="keyword">com</span>/linux/linux_signing_key.pub  | sudo apt-key <span class="built_in">add</span> -
</code></pre><p>然后执行如下命令：</p>
<pre><code>sudo apt-<span class="built_in">get</span> <span class="keyword">update</span>
sudo apt-<span class="built_in">get</span> install google-chrome-stable
</code></pre><p>2.配置XX-Net</p>
<p>按照<a href="https://github.com/XX-net/XX-Net/wiki/%E4%BD%BF%E7%94%A8Chrome%E6%B5%8F%E8%A7%88%E5%99%A8" target="_blank" rel="external">说明文档</a>进行下载配置.</p>
<p>3.搜狗输入法</p>
<p>下载地址：<a href="http://pinyin.sogou.com/linux/" target="_blank" rel="external">http://pinyin.sogou.com/linux/</a></p>
<p>安装：</p>
<pre><code><span class="tag">sudo</span> <span class="tag">dpkg</span> <span class="tag">-i</span> <span class="tag">sogoupinyin_2</span><span class="class">.1</span><span class="class">.0</span><span class="class">.0082_amd64</span><span class="class">.deb</span>
</code></pre><p>若出现问题安装错误时，或是由于缺少依赖，因此可执行如下语句：</p>
<pre><code>sudo apt-<span class="keyword">get</span> install -f
</code></pre><p>然后再次执行安装命令即可：</p>
<pre><code><span class="tag">sudo</span> <span class="tag">dpkg</span> <span class="tag">-i</span> <span class="tag">sogoupinyin_2</span><span class="class">.1</span><span class="class">.0</span><span class="class">.0082_amd64</span><span class="class">.deb</span>
</code></pre><p>4.搭建hexo</p>
<p>4.1安装nodejs</p>
<p>一个是通过ubuntu自带的包管理进行安装。不过它自带的版本可能过低，所以需要添加源：</p>
<pre><code>sudo<span class="instruction"> add-apt-repository </span>ppa:chris-lea/node.js
sudo apt-get update
sudo apt-get install nodejs
</code></pre><p>创建一个nodejs到node的软链接:</p>
<pre><code>sudo ln -s <span class="regexp">/usr/</span>bin<span class="regexp">/nodejs /u</span>sr<span class="regexp">/bin/</span>node
</code></pre><p>4.2安装Git</p>
<pre><code>sudo apt-<span class="keyword">get</span> install git
</code></pre><p>4.3安装hexo</p>
<pre><code><span class="preprocessor"># 创建目录</span>
mkdir hexo
<span class="preprocessor"># 切换目录</span>
cd hexo
<span class="preprocessor"># 全局安装 Hexo，需要最高权限，记得输入root密码</span>
sudo apt-<span class="keyword">get</span> install npm
sudo npm install -g hexo-cli
<span class="preprocessor"># 初始化 Hexo</span>
hexo init
</code></pre><p>安装插件</p>
<pre><code>npm <span class="operator"><span class="keyword">install</span> hexo-generator-<span class="keyword">index</span> <span class="comment">--save</span>
npm <span class="keyword">install</span> hexo-generator-archive <span class="comment">--save</span>
npm <span class="keyword">install</span> hexo-generator-category <span class="comment">--save</span>
npm <span class="keyword">install</span> hexo-generator-tag <span class="comment">--save</span>
npm <span class="keyword">install</span> hexo-<span class="keyword">server</span> <span class="comment">--save</span>
npm <span class="keyword">install</span> hexo-deployer-git <span class="comment">--save</span>
npm <span class="keyword">install</span> hexo-deployer-heroku <span class="comment">--save</span>
npm <span class="keyword">install</span> hexo-deployer-rsync <span class="comment">--save</span>
npm <span class="keyword">install</span> hexo-deployer-openshift <span class="comment">--save</span>
npm <span class="keyword">install</span> hexo-renderer-marked <span class="comment">--save</span>
npm <span class="keyword">install</span> hexo-renderer-stylus <span class="comment">--save</span>
npm <span class="keyword">install</span> hexo-generator-feed <span class="comment">--save</span>
npm <span class="keyword">install</span> hexo-generator-sitemap <span class="comment">--save</span></span>
</code></pre><p>测试安装成功</p>
<pre><code>hexo <span class="keyword">server</span>
</code></pre><p>4.4配置本机全局git环境<br>首先请使用邮箱注册github账号，否则会影响下面操作，记住你注册的邮箱。</p>
<pre><code>git config --global user<span class="class">.email</span> <span class="string">"you@example.com"</span>
git config --global user<span class="class">.name</span> <span class="string">"Your Name"</span>
</code></pre><p>生成SSH秘钥</p>
<pre><code><span class="comment"># -C后面跟住你在github的用户名邮箱，这样公钥才会被github认可</span>
 ssh-keygen -t rsa -C you<span class="property">@example</span>.com
 <span class="comment"># 回车后，输入一个文件夹名字，存储新的SSH 秘钥</span>
<span class="regexp">/home/username/</span>.ssh/id_rsa
<span class="comment"># 查看 公钥内容 稍后加入Github 账户的 sshkey中</span>
 less ~/.ssh/id_rsa.pub
</code></pre><p>将id_rsa.pub中的文本拷贝到github设置SSh。</p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
      

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-Ubuntu backup" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/12/28/Ubuntu backup/" class="article-date">
  	<time datetime="2016-12-28T12:41:49.000Z" itemprop="datePublished">2016-12-28</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Ubuntu Backup</p>
<ol>
<li>backup</li>
</ol>
<p>然后打开终端，输入以下命令：</p>
<pre><code>sudo su
<span class="built_in">cd</span> /  <span class="comment">##转到根目录</span>
</code></pre><p>然後，下面就是我用来备份我的系统的完整的命令：</p>
<pre><code>tar -cvpzf /media/gwang/<span class="type">Work</span>/backup.tgz --exclude=/<span class="keyword">proc</span> --exclude=/lost+found --exclude=/mnt --exclude=/sys --exclude=/media --exclude=/tmp /
</code></pre><p>PS:</p>
<p>tar 是用来备份的程序</p>
<p>c - 新建一个备份文档</p>
<p>v - 详细模式， tar程序将在屏幕上实时输出所有信息。</p>
<p>p - 保存权限，并应用到所有文件。</p>
<p>z - 采用‘gzip’压缩备份文件，以减小备份文件体积。</p>
<p>f - 说明备份文件存放的路径， /media/sda7/backup.tgz 是本例子中备份文件名。这个备份文件备份的位置是其它分区，也就是原来的WIN分区中。因为我的根目录的空间不足，所以只有备份在其它的地方了。</p>
<p>—excloude - 排除指定目录,使其不被备份</p>
<ol>
<li><p>Linux 中美妙的事情之一就是在系统正在运行的情况下可以进行还原操作，而不需要启动光盘或者其他任何乱七八糟的东西。当然，如果您的系统已经崩溃，那您必须选择使用live CD，但是结果还是一样。</p>
<p> tar -xvpzf /media/gwang/Work/backup.tgz -C /</p>
</li>
</ol>
<p>如果您使用的是bz2压缩的：</p>
<pre><code>tar -xvpjf /media/gwang/Work/backup<span class="class">.tar</span><span class="class">.bz2</span> -C /
</code></pre><p>如果系统已经崩溃可以使用Live usb登录，然后</p>
<pre><code>mkdir <span class="regexp">/tmp/</span>root
mount <span class="regexp">/dev/</span>sdaX <span class="regexp">/tmp/</span>root

tar -xvpjf <span class="regexp">/media/g</span>wang<span class="regexp">/Work/</span>backup.tar.bz2 -C <span class="regexp">/tmp/</span>root
</code></pre><p>当然，恢复前可以先</p>
<pre><code>rm -rf <span class="regexp">/tmp/root/</span>* 
</code></pre><p>这样就删除根目录下的所有文件.</p>
<p>这个只是在本机上还原，如果是还原到别的机子上记得修改fstab文件。（可能还需要安装grub）</p>
<p>恢复命令结束时，别忘了重新创建那些在备份时被排除在外的目录：</p>
<pre><code><span class="preprocessor"># mkdir proc</span>
<span class="preprocessor"># mkdir lost+found</span>
<span class="preprocessor"># mkdir mnt</span>
<span class="preprocessor"># mkdir sys</span>
<span class="preprocessor"># mkdir media</span>
</code></pre>
      
    </div>
    
    <div class="article-info article-info-index">
      
      
      

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-数据挖掘界领军人物谢邦昌" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/11/29/数据挖掘界领军人物谢邦昌/" class="article-date">
  	<time datetime="2016-11-29T10:08:05.000Z" itemprop="datePublished">2016-11-29</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>好文丨数据挖掘界领军人物谢邦昌：深度剖析Data Mining </p>
<p>谢邦昌</p>
<p>深度剖析Data Mining</p>
<p><strong>简介</strong><br>谢邦昌教授，是台北医学大学医务管理学系研究所暨大数据研究中心及管理学院主任，也是数据挖掘界领军人物及世界知名统计学家，他对数据挖掘的定义是：Data Mining是从巨大数据仓储中找出有用信息的一种过程与技术。</p>
<p><strong>Data Mining主要功能</strong></p>
<p>Data Mining实际应用功能可分为三大类六分项来说明：Classification和Clustering属于分类区隔类；Regression和Time-series属于推算预测类；Association和Sequence则属于序列规则类。</p>
<p>Classification是根据一些变量的数值做计算，再依照结果作分类。（计算的结果最后会被分类为几个少数的离散数值，例如将一组数据分为 “可能会响应” 或是 “可能不会响应” 两类）。</p>
<p>Classification常被用来处理如前所述之邮寄对象筛选的问题。我们会用一些根据历史经验已经分类好的数据来研究它们的特征，然后再根据这些特征对其他未经分类或是新的数据做预测。</p>
<p>这些我们用来寻找特征的已分类数据可能是来自我们的现有的客户数据，或是将一个完整数据库做部份取样，再经由实际的运作来测试；譬如利用一个大型邮寄对象数据库的部份取样来建立一个Classification Model，再利用这个Model来对数据库的其它数据或是新的数据作分类预测。</p>
<p>Clustering用在将数据分群，其目的在于将群间的差异找出来，同时也将群内成员的相似性找出来。Clustering与Classification不同的是，在分析前并不知道会以何种方式或根据来分类。所以必须要配合专业领域知识来解读这些分群的意义。</p>
<p>Regression是使用一系列的现有数值来预测一个连续数值的可能值。若将范围扩大亦可利用Logistic Regression来预测类别变量，特别在广泛运用现代分析技术如类神经网络或决策树理论等分析工具，推估预测的模式已不在止于传统线性的局限，在预测的功能上大大增加了选择工具的弹性与应用范围的广度。</p>
<p>Time-Series Forecasting与Regression功能类似，只是它是用现有的数值来预测未来的数值。两者最大差异在于Time-Series所分析的数值都与时间有关。Time-Series Forecasting的工具可以处理有关时间的一些特性，譬如时间的周期性、阶层性、季节性以及其它的一些特别因素（如过去与未来的关连性）。</p>
<p>Association是要找出在某一事件或是数据中会同时出现的东西。举例而言，如果A是某一事件的一种选择，则B也出现在该事件中的机率有多少。（例如：如果顾客买了火腿和柳橙汁，那么这个顾客同时也会买牛奶的机率是85%。）</p>
<p>Sequence Discovery与Association关系很密切，所不同的是Sequence Discovery中事件的相关是以时间因素来作区隔（例如：如果A股票在某一天上涨12%，而且当天股市加权指数下降，则B股票在两天之内上涨的机率是 68%） 。</p>
<p><strong>目前业界最常用的Data Mining分析工具</strong></p>
<p>Data Mining工具市场大致可分为三类：</p>
<ol>
<li><p>一般分析目的用的软件包：<br>SAS Enterprise Miner<br>Microsoft SQL Server 2005 – 2008<br>IBM Intelligent Miner<br>Unica PRW<br>SPSS Clementine<br>SGI MineSet<br>Oracle Darwin<br>Angoss KnowledgeSeeker<br>Statistica</p>
</li>
<li><p>针对特定功能或产业而研发的软件：<br>KD1（针对零售业）<br>Options &amp; Choices（针对保险业）<br>HNC（针对信用卡诈欺或呆帐侦测）<br>Unica Model 1（针对营销业）</p>
</li>
<li><p>整合DSS（Decision Support Systems）/OLAP/Data Mining的大型分析系统：<br>Cognos Scenario and Business Objects</p>
</li>
</ol>
<p><strong>对于刚刚接触Data Mining的人来说，怎样把它学好？</strong></p>
<p>先从问题着手，Domain Knowledge 是很重要的具体应重视三方面的问题：</p>
<ol>
<li><p>强调需求，重视过程和结果。虽然统计学和数据挖掘一样，都是在寻求实际数据解决方案的过程中成长起来的，然而统计学家更关注模型，运用数据仅仅是为了发现新的模型，而数据挖掘则更强调知识的价值，模型是用来发现知识的工具。强调需求，重视过程和结果才能实现统计创新。</p>
</li>
<li><p>借鉴机器学习的特点，提炼方法，以算法的形式体现方法。统计学早已脱离正态的传统框架发展方法。但是，由于统计最新的可以被直接使用的成果太少，不仅阻碍了人们对统计方法的运用，甚至造成对先进统计方法的不甚了解。数据挖掘的兴起，为统计学与信息技术的结合带来了发展的契机。计算机技术将成为继数学之后，又一推动统计学发展的强大工具。</p>
</li>
<li><p>发挥统计软件的优势。许多“傻瓜”统计软件的设计，更适合统计学家研究使用，任何一个初通统计的数据分析员要想通过软件来进行数据分析，都极有可能由于对数据涵义的不求甚解，导致脱离实际的统计模型的滥用，数据挖掘软件也是如此；Clementine、SQL Server 2005及SAS和S-plus被设计为可以通过编程来调节软件的默认属性，用这样的软件工作可以增强统计研究者的算法意识；最后，统计软件为统计研究的目的，在图形和可视化方面的互动操作，应该在数据挖掘的软件中体现这一思想，因为它可以帮助数据分析员理解高维数据复杂的结构。</p>
</li>
</ol>
<p>从数据挖掘在国际上的发展来看，数据挖掘的研究重点已从提出概念和发现方法，转向系统应用和方法创新上，研究注重多种发现策略和技术的集成，以及多种学科之间的相互渗透，数据挖掘技术迫切需要系统、科学的理论体系作为其发展的有力支撑。</p>
<p>最近，由经验统计方法和人工智能相结合而产生的衍生技术，如分类回归树（Classification And Regression Tree, 简称CART），卡方自动交互探测法（Chi-square Automatic Interaction Detector，简称CHAID）等前沿方法，以算法的形式展示了统计和信息技术结合发展的新方向。这些都预示着数据挖掘技术与统计学的集成已成为必然的趋势。</p>
<p>我们坚信，随着统计学与现代信息技术的融合，在方法上不断进行新的探索，一定会为统计学和数据挖掘未来的发展开辟一片新的天地。</p>
<p><strong>Web Mining 和Data Mining的区别</strong></p>
<p>如果将Web视为CRM的一个新的Channel，则Web Mining便可单纯看做Data Mining应用在网络数据的泛称。</p>
<p>该如何测量一个网站是否成功？哪些内容、优惠、广告是人气最旺的？主要访客是哪些人？什么原因吸引他们前来？如何从堆积如山之大量由网络所得数据中找出让网站运作更有效率的操作因素？以上种种皆属Web Mining 分析之范畴。</p>
<p>Web Mining 不仅只限于一般较为人所知的log file分析，除了计算网页浏览率以及访客人次外，举凡网络上的零售、财务服务、通讯服务、政府机关、医疗咨询、远距教学等等，只要由网络连结出的数据库够大够完整，所有Off-Line可进行的分析，Web Mining都可以做，甚或更可整合Off-Line及On-Line的数据库，实施更大规模的模型预测与推估，毕竟凭借因特网的便利性与渗透力再配合网络行为的可追踪性与高互动特质，一对一营销的理念是最有机会在网络世界里完全落实的。</p>
<p><strong>整体而言，Web Mining具有以下特性</strong></p>
<ol>
<li><p>资料收集容易且不引人注意，所谓凡走过必留下痕迹，当访客进入网站后的一切浏览行为与历程都是可以立即被纪录的；</p>
</li>
<li><p>以交互式个人化服务为终极目标，除了因应不同访客呈现专属设计的网页之外，不同的访客也会有不同的服务；</p>
</li>
<li><p>可整合外部来源数据让分析功能发挥地更深更广，除了log file、cookies、会员填表数据、在线调查数据、在线交易数据等由网络直接取得的资源外，结合实体世界累积时间更久、范围更广的资源，将使分析的结果更准确也更深入。</p>
</li>
<li><p>利用Data Mining技术建立更深入的访客数据剖析，并赖以架构精准的预测模式，以期呈现真正智能型个人化的网络服务，是Web Mining努力的方向。</p>
</li>
<li><p>Data Warehousing（资料仓储） 和Data Mining 之间的关系若将Data Warehousing比喻作矿坑，Data Mining就是深入矿坑采矿的工作。毕竟Data Mining不是一种无中生有的魔术，也不是点石成金的炼金术，若没有够丰富完整的数据，是很难期待Data Mining能挖掘出什么有意义的信息的。</p>
</li>
</ol>
<p>要将庞大的数据转换成为有用的信息，必须先有效率地收集信息。随着科技的进步，功能完善的数据库系统就成了最好的收集资料的工具。「数据仓储」，简单地说，就是搜集来自其它系统的有用数据，存放在一整合的储存区内。所以其实就是一个经过处理整合，且容量特别大的关系型数据库，用以储存决策支持系统（Design Support System）所需的数据，供决策支持或数据分析使用。从信息技术的角度来看，数据仓储的目标是在组织中，在正确的时间，将正确的数据交给正确的人。</p>
<p>许多人对于Data Warehousing和Data Mining时常混淆，不知如何分辨。其实，数据仓储是数据库技术的一个新主题，在数据科技日渐普及下，利用计算机系统帮助我们操作、计算和思考，让作业方式改变，决策方式也跟着改变。数据仓储本身是一个非常大的数据库，它储存着由组织作业数据库中整合而来的数据，特别是指从在线交易系统OLTP（On-Line Transactional Processing）所得来的数据。</p>
<p>将这些整合过的数据置放于数据仓储中，而公司的决策者则利用这些数据作决策；但是，这个转换及整合数据的过程，是建立一个数据仓储最大的挑战。因为将作业中的数据转换成有用的的策略性信息是整个数据仓储的重点。综上所述，数据仓储应该具有这些数据：整合性数据（integrated data）、详细和汇总性的数据(detailed and summarized data)、历史数据、解释数据的数据。</p>
<p>从数据仓储挖掘出对决策有用的信息与知识，是建立数据仓储与使用Data Mining的最大目的，两者的本质与过程是两码子事。</p>
<p>换句话说，数据仓储应先行建立完成，Data Mining才能有效率的进行，因为数据仓储本身所含数据是干净(不会有错误的数据参杂其中）、完备，且经过整合的。因此两者关系或许可解读为「 Data Mining是从巨大数据仓储中找出有用信息的一种过程与技术」。</p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
      

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-初探计算机视觉的三个源头、兼谈人工智能｜正本清源" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/11/22/初探计算机视觉的三个源头、兼谈人工智能｜正本清源/" class="article-date">
  	<time datetime="2016-11-22T13:09:59.000Z" itemprop="datePublished">2016-11-22</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>初探计算机视觉的三个源头、兼谈人工智能｜正本清源</p>
<p>2016-11-22 视觉求索</p>
<p>谈话人：</p>
<p>杨志宏   视觉求索公众号编辑</p>
<p>朱松纯   加州大学洛杉矶分校UCLA统计学和计算机科学教授</p>
<p>Song-Chun Zhu<br>　<br>www.stat.ucla.edu/~sczhu</p>
<p>时间: 2016年10月 </p>
<p>杨: 朱教授，你在计算机视觉领域耕耘20余年，获得很多奖项， 是很资深的研究人员。近年来你又涉足认知科学、机器人和人工智能。受 《视觉求索公众号》编辑部委托，我想与你探讨一下计算机视觉的起源，这个学科是什么时候创建的， 有哪些创始和代表人物。兼谈一下目前热门的人工智能。</p>
<p>朱: 好， 我们首先谈一下为什么需要讨论这个问题。 然后， 再来探讨一下计算机视觉的三个重要人物David Marr， King-Sun Fu， Ulf Grenander以及他们的学术思想。我认为他们是这个领域的主要创始人、或者叫有重要贡献的奠基人物。</p>
<p>第一节： 为什么要追溯计算机视觉的源头， 这有什么现实意义?</p>
<p>中国有句很有名的话：“一个民族如果忘记了历史,她也注定将失去未来。”  我认为这句话对一个学科来讲，同样发人深省。我们先来看看现实的状况吧。</p>
<p>首先，假设你当前是一个刚刚进入计算机视觉领域的研究生，很快你会有一种错觉，觉得这个领域好像就是5年前诞生的。 跟踪最新发表的视觉的论文，很少有文章能够引用到5年之前的文献，大部分文献只是2-3年前的，甚至是1年之内的。现在的信息交换比较快，大家都在比一些 Benchmarks,把结果挂到arXiv 网上发布。 很少有一些认真的讨论追溯到10年前，20年前， 或30年前的一些论文，提及当时的一些思想和框架性的东西。现在大家都用同样的方法，只是比拼，你昨天是18.3%的记录（错误率），我今天搞到17.9%了。大家都相当短视，那么研究生毕业以后变成了博士，可能也会带学生做研究，他只知道这几年的历史和流行的方法的话，怎么可能去传承这个学科，让其长期健康发展呢？特别是等当前这一波方法退潮之后，这批人就慢慢失去了根基和源创力。这是一个客观的现象。</p>
<p>其次，还有一个现象是，随着视觉与机器学习结合，再混合到人工智能的这么一个社会关注度很高的领域去以后，目前各种工业界，资本、投资界都往这里面来炒作。所以，你可以在互联网上看到各种推送的文字，什么这个大师，那个什么牛人、达人说得有声有色，一大堆封号。中国是有出“大师”的肥沃的土壤的，特别是在这个万众创新、浮躁的年代。 这些文字在混淆公众的视听。也有的是一些中国的研究人员、研究生， 半懂不懂，写出来一些， 某某梳理机器学习、神经网络和人工智能的历史大事。说得神乎其神。我的大学同学把这种帖子转发给我，让我担忧。</p>
<p>杨：这大多是以学术的名义写的软文，看起来像学术文章，实际上就是带广告性质的，一般都是说创投、创业公司里的人，带着资本的目的，带商业推广性质的。</p>
<p>朱: 我甚至不排除有些教授，比如与硅谷结合很紧密的、在IT公司或者风投公司兼职的，有意识地参与、引领这种炒作。</p>
<p>这对我们的年轻学生其实是很致命的，因为他们不了解这背后的动机， 缺乏免疫力。而且现在年轻人和公众都依赖短平快的社交媒体，很少去读专业文献。当公众的思想被这些文字占领了，得出错误的社会性的共识，变成了 false common sense， 对整个社会， 甚至对学术界，都会产生长久的负面冲击。</p>
<p>这就形成了新时代的皇帝的新装。我们需要对这种现象发声， 做一些严肃的探讨。所以，正本清源有着重要的现实意义。</p>
<p>第二节：计算机视觉和人工智能、机器学习的关系</p>
<p>杨：谈到这里，我想先问一下计算机视觉和人工智能是什么关系？还有机器学习这三个东西。</p>
<p>朱：人工智能是在60年代中后期起步的。一直到80年代，翻开它的教科书，就是一些启发式搜索，研究最多的是下棋， 从国际象棋一直到最近的围棋，都是比较抽象的表达。棋盘的位置是有限的、下棋的动作也是有限的， 没有感知和动作执行的不确定性。 所有的问题都变成一个图搜索的问题，教科书上甚至出现了一个通用图搜索算法号称可以解决任何人工智能问题。当时视觉问题还没引起大家重视。我这里有一份1966  年7月 的  MIT AI 实验室的第100号报告（备忘录memo 100），很短，题目叫做“The Summer Vision Project”。这个备忘录的基本意思就是暑假的时候找几个学生构造一个视觉系统。他们当时可能就觉得这个问题基本上是不需要做什么研究的。所以你就一个暑假，几个人一起写个程序，就把它干掉算了。现在说起来，当然是个笑话。</p>
<p>人的大脑皮层的活动， 大约70%是在处理视觉相关信息。视觉就相当于人脑的大门，其它如听觉、触觉、味觉那都是带宽较窄的通道。视觉相当于八车道的高速， 其它感觉是两旁的人行道。如果不能处理视觉信息的话，整个人工智能系统是个空架子，只能做符号推理，比如下棋、定理证明， 没法进入现实世界。所以你刚才问到的人工智能和计算机视觉的关系，视觉，它相当于说芝麻开门。大门就在这里面，这个门打不开, 就没法研究真实世界的人工智能。</p>
<p>到80年代，人工智能， 连带机器人研究就跌入了低谷， 所谓的冬天。那个时候，很多实验室都改名字了， 因为拿不到经费了。 客观来说，80年代， 一个微型计算机的它的内存只有640K字节，还不到一兆（1MB一百万字节），我们现在一张图像，随便就是几个兆的大小，它根本无法读入一张图像，还谈什么理解呢？等到我做博士论文的时候（1992-1996），我导师把当时哈佛机器人实验室最好的SUN工作站给我用，也就是32兆字节。我们实验室花了25万美元构建了一个图像采集系统，因为当时没有数字照相机。可以这么说，一直到90年代中期的时候，我们基本上不具备研究视觉这个问题的硬件条件和数据基础。只能用一些特征点的对应关系做射影几何，用一些线条做形状分析。因为图像做不了，所以80年代计算机视觉的研究，很大部分是做几何。</p>
<p>杨：90 年代后，就是数字照相机大量生产了。</p>
<p>朱：在90年代的末期的时候，发生了一个叫做感知器的革命。带动了大数据和机器学习的蓬勃发展。</p>
<p>杨：那机器学习与计算机视觉的关系呢？</p>
<p>朱：计算机视觉是一个domain， 它有很多问题要研究， 就像物理学。 而机器学习基本是一个方法和工具，就像数学和统计学。 这个名词的兴起应该还是最近的事情， 在我看来，是来自于两股人马。 80年代人工智能走入低谷后，迎来了人工神经网络的一个高潮， 所谓的从符号主义到连接主义的过渡。在中国80年代与气功、人体科学一起走红，但这基本是昙花一现。到了90年代初， 退潮之后，就开始搞 NIPS这个会议， 引入统计的方法来做。还有一股就是做模式识别的一些工程人员EECS 背景的。 按道理来说， 这个领域应该叫做 统计学习 （Statistical Learning），因为它的方法都是由概率统计领域拿来的。这些人中的领军人物很有商业头脑， 把统计和物理的数理模型， 改名叫做机器， 比如<strong>模型（model）就叫</strong>机（machine），把一些层次模型（hierarchical model）说成是“网”（net）。这样，搞出了几个“机”和“网”之后， 这个领域就有了地盘。另一方面，我的那些做统计的同事们也都老实、图个清静，不与他们去争论， 也大多无力去争。当然，统计学领域也有不少人参与了机器学习的浪潮。简单说，机器学习中的 “机器”就是统计模型，“学习”就是用数据来拟合模型。 是由做计算机的人抢占了统计人的理论和方法，然后，应用到视觉、语音语言等 domains。 我在计算机和统计两个系当教授， 看得一清二楚。 这个问题我以后可以专门讨论。</p>
<p>这个机器学习的群体在2000年之后，加上大量数据的到来，很快就成长了， 商业上取得很大的成功。机器学习和计算机视觉大概有百分之六七十是重合的。顺便说一句，2019年我们两个领域会在一起在洛杉矶开CVPR 和 ICML年会， 我是CVPR19的大会主席。因为学习搞来搞去，最丰富的数据是在视觉（图像和视频）。现在这次机器学习的一些大的动作和工程上的推广工作，还是从计算机视觉这边开始的。</p>
<p>杨：谢谢你讲述人工智能,计算机视觉和机器学习的关系。下面我们回到本次访谈的主题。刚才说了这个感知器革命是90年代以后，出了很多的数据要处理了。那么为什么马尔（Marr）在70年代末思考的问题，在面对我们当今处理这个数据的时候, 还有意义？就是说马尔用了什么方法？什么思路框架？使它有生命力？</p>
<p>朱：好，就回到1975-1980年这个时间段。我们今天的主题是想初步探讨一下计算机视觉的起源。我们这个领域也没有一个统一的教科书来谈这个事情。我认为视觉的起源，可以追溯到三个人，David Marr, King-Sun Fu 和Ulf Grenander。这三个人代表三个完全不同的方面，为计算机视觉这个领域奠定了基础。</p>
<p>杨：好， 我们逐个来介绍吧。</p>
<p>第三节：视觉的开创者之一：David Marr 的学术思想</p>
<p>朱： David Marr 【1945-1980】，中文音译为马尔， 他奠定了这个领域叫做Computational Vision计算视觉，这包含了两个领域： 一个就是计算机视觉（Computer Vision），一个是计算神经学（Computational Neuroscience）。他的工作对认知科学（CognitiveScience）也产生了很深远的影响。</p>
<p>我们计算机视觉CV，第一届国际会议ICCV 1987年就以David Marr的名字来命名最佳论文奖， 而且一直到2007年之前的20年间， 是CV唯一的奖项和最高的荣誉，两年一次。认知科学年会 （CogSci）也设有一个 Marr Prize给最佳的学生论文。这三个领域在80-90年代走得很近， 最近十多年交叉越来越少了。就是说，原来都是亲戚，表兄弟， 现在很少有人在之间走动了。</p>
<p>Marr 1972年从剑桥大学毕业，博士论文是从理论的角度研究大脑功能，具体来说，是研究的小脑， 主管运动的Cerebellum。1973年受MIT 人工智能实验室主任Minsky的邀请， 开始是做访问学者（博士后）。 1977年转为教职。 可是， 1978年冬诊断得了急性白血病。1980年转为正教授不久就去世了， 时年35岁。他在得知来日无多后，就赶紧整理了一本书，就叫 “Vision：A Computational Investigation into the HumanRepresentation and Processing of Visual Information”, 《视觉：从计算的视角研究人的视觉信息表达与处理》。他去世后由学生和同事修订，1982年出版。</p>
<p>杨：“Vision”2010年再版了，再版了以后在亚马逊仍然是卖得很好。</p>
<p>朱：它是个经典的东西。我是1989年冬天本科三年级从中科大认知科学实验室的老师那里，读到这本书的中文译本。因为缺乏背景知识，我当时基本读不懂。因为是中文，每句话都明白，但是一段话就不知道是什么意思了。在过去的20多年中， 我每隔1-2年都会再翻一翻这本书。后来我和同事花了大约8年时间，将他的一些思路转化成数理模型，比如primal sketch。</p>
<p>杨：这个人生故事是可以拍电影的。</p>
<p>朱：的确。 很多年前我与他的大弟子 Shimon Ullman饭桌上谈到这段历史， 他说当时大家到处找药，就是救不过来。当年这是一个30多岁正值科学顶峰的、交叉学科的领军人物。顺便说一句， 当年中日友好，1984播放日本电视剧《血疑》， 那是万人空巷， 感人至深。里面的大岛幸子（三口百惠饰）得的就是同样的病。</p>
<p>可惜， 目前计算机视觉这个领域，你如果去问学生的话，他们很多人都没听说过David Marr。“喔，想起来了，好像有个Marr奖吧”。可是你去问认知科学、神经科学的人，他们基本上对Marr非常的清楚。这也是我所担心的， 计算机视觉的发展太工程化、功利化了，逐步脱离了科学的范畴。这是短视和危险的。最近又受到机器学习来的冲击。</p>
<p>我这里顺便说一句， Marr 对我的另外一个间接的影响。他1973年来到MIT， 就租住在JayantShah的房子里， Shah 与 Minsky很熟， 他当时是研究代数几何（Algebraic geometry）的。 而我导师Mumford也是研究代数几何的， 并获得1974年的菲尔兹奖。他们两人很熟，后来在Shah的影响下，Mumford转入计算机视觉， 他们从提取物体边缘开始 （boundarydetection），也就是产生了著名的 Mumford-Shah 模型，搞图像处理的应用数学人员基本都是从这个模型开始做。这是后话。关于这段历史，我们以后可以展开谈。</p>
<p>杨：好， 那么 Marr的学术贡献是什么呢？</p>
<p>朱：在我看来，David Marr对我们这个学科最主要的贡献有三条。从而基本上可以说，定义了这个学科的格局。</p>
<p>第一条，就是说在那个时代，60年代开始的时候大家已经很多人研究视觉神经生理学、心理学问题。也有人做一些边缘检测的工作。但是，视觉到底要解决哪些问题？是怎么实现的？大家莫衷一是，谈不清楚，那么David Marr的第一个贡献就是分出了三个层次。他说， 要解决这个问题，可以把它分成计算（其实应该说成是表达）、算法、和实现三层次。首先，在表达的层次，我们问一下这是个什么问题呢？如何把它写成一个数学问题。任务是什么？输出是什么？这是独立于解决问题的方法的。其次，对这个数学问题去求解时，可以选择不同的算法， 可以并行或者串行。再次，一个算法如何在硬件上实现，可以用CPU，DSP， 或者神经网络来实现。 很多观察到的心理学和神经科学的现象都是跟系统硬件有关的东西，比如说人的一些注意机制，记忆力。这些应该从表达层面剔除。这样， 视觉就可以从纯粹的理论、计算的角度来研究了。我们可以参考心理学和神经科学的结论， 但这不是主要的。 打个比方，要造飞机， 可以参考鸟类的结构， 但关键还是建立空气动力学，才能从根本上解释这个现象， 并创造各种飞行器， 走得更远。</p>
<p>杨：他这么一说，今天看来好像很自然的可以理解了，但是在当时，可能没有多少人，是把问题这样分解的。</p>
<p>朱：当时分不开。因为当时站在像神经科学和认知科学角度，是拿一些实验现象来说事，但是不知道这个现象是在哪一层出现的。</p>
<p>比如神经网络和目前的深度神经网络的学习，他们的模型（表达）、算法、和实现的结构三层 是混在一起的。就变成一个特用的计算设备， 算法就是由这个结构来实现的。当它性能不好的时候，到底是因为表达不对，还是算法不对，还是实现不对？ 这个不好分析了，目前的神经网络，或者是机器学习，深度学习，它的本源存在这个问题。</p>
<p>以前我们审稿的时候，会追问论文贡献是提出了一个新的模型？还是一个新的算法？在哪一个层级上你有贡献，必须说得清清楚楚。2012年，我作为国际计算机视觉和模式识别年会（CVPR）的大会主席， 就发生一个事件。收到神经网络和机器学习学派的一个领军人物 LeCun的抱怨信，他的论文报告了很好的实验结果， 但是审稿的三个人都认为论文说不清楚到底为什么有这个结果， 就拒稿。他一气之下就说再也不给CVPR投稿了，把审稿意见挂在网上以示抗议。2012 年是个转折点。</p>
<p>现在呢？随着深度学习的红火， 这三层就又混在一块去了。 一般论文直接就报告结果， 一堆表格、曲线图。我就是这么做，然后再这么做，我在某些个数据集上提高了两个百分点，那就行了。你审稿人也别问我这个东西里面有什么贡献，哪个节点代表是什么意思，你别问，我也不知道。那算法收敛了吗？是全局收敛还是一个局部收敛？我也不知道，但是我就提高了两个百分点。</p>
<p>杨：或者要用多少数据来训练材料才能够呢？</p>
<p>朱：对，这个也不用管，而且说不清。反正我这个数据集就提高是吧？所以从这个角度来讲，它就很难是一个科学的方法。可以认为它就是一个工程或者是一个经验的，有点像中医。那么要往前再发展的时候，你必须要理清楚这三层的事情。</p>
<p>杨：对。</p>
<p>朱：那么他第二个贡献的话，是理清视觉到底要计算什么。Marr提出了一个系列的表达，从primal sketch（首要简约图）， 到2 ½ D sketch（深度简约图）， 到3D sketch。 这里面还包含了纹理、立体视觉、运动分析、表面形状、等等。比如说我要估计一个物体的深度和形状，我就估计它的光照，和物理材料特性；还有，三维几何形状怎么去表达？ 他试图去建立一个完整的体系。</p>
<p>现在的视觉就基本上被很多人错误地看成一个分类问题，你给我一张图像，我说这个图像里有一只狗或者没有狗，狗在哪儿都不知道。头在哪？脚在哪？不知道。Marr框架是有秩序的，现在的秩序在做深度学习的人眼中还不存在，或者没有忙过来。各人做各人的分类问题，比如说有人算这个动物分类，有的人算这个家具的分类。各种分类以后，他们之间怎么样的关系呢？要对这个图像或者场景要产生一个整体的语义解释。</p>
<p>第三个贡献，Marr提出了一个非常重要的概念，到现在一直还没有一个完整的解答。他说，计算视觉是一个计算的“过程”。这是什么意思？ 我们以前用贝叶斯方法（以及现在的深度网络）认为视觉就是表达成为一个后验概率，寻求一个最优解。这个解就是图像的解释。这个求解过程就会终止。可是Marr说的这个事情，它不是单纯去求一个解，而是一个连续不断的计算过程。我给你一张图像，你越看、越琢磨，你可能看到的东西会越多。</p>
<p>我给你一秒钟，你可能看到某些东西。我给你一分钟，你可能有另外一种理解，这两个理解可能是不一样的。还有一个重要的概念是你的任务决定了你怎么去看这个图像，比如说我在慌忙之中在做饭，那么我对这个场景，只看其中的很小一部分，足够来完成我的任务就行了。里面好多东西改变你根本没注意到。</p>
<p>杨：好像有些魔术就利用了这一点。</p>
<p>朱：就是， 很多心理学实验表明，你眼睛盯着这个图片看的时候，眼睛不眨，我告诉你这个图片在改变。你盯着看，结果它改了你都没看见。在让你看这个图片的时候，把你的注意力引到某个任务所需要计算的关键要素上，其它部分你就视而不见。视觉是受任务驱动的。而任务是时刻在改变之中。 比方说， 视觉求解不是打一个固定的靶子， 而是打一个运动目标。 </p>
<p>杨：这听起来是一个耳目一新的概念。</p>
<p>朱：回到人工智能这个问题，视觉，它最后的用途，要给机器人用，机器人目前面临一个什么任务，来决定它要计算什么。这第三个贡献是在算法的层面。就是说我根据我们目前面临的任务，我才决定要计算什么。而且人的任务是在不断变化的，在此时此刻我任务都在变化，那么计算的过程中是没完没了地在改变。这个理念到目前，我们目前在研究这个事情，还没有完全实现。就是说，这将是人工智能和机器人视觉的一个关键。</p>
<p>杨：明白。</p>
<p>朱：我们现在很多人研究这个智能，比如说分类问题。他都是从谷歌的一些应用，比如搜索图片、广告投放，变成分类问题。 从而忽视了更大的本质问题。如果说人工智能往前发展机器人，要从机器人的角度来用视觉的话，那么它就有很多不同的任务。我现在做饭，我在打球，我在欣赏风景，这个时候我看到的东西是完全不一样的。我怎么样通过这千千万万的任务，而不是简单一个分类，来驱动我的计算的过程，来找到我的需求，来支持我目前的任务，这是一个巨大的研究的方向。David Marr的思想，到今天，反而意义非常重大，因为大家现在一窝蜂的去搞深度学习，把这些基本东西给忘掉了。但是这才是人工智能和机器人视觉的长远发展方向。</p>
<p>我前两年给过几个谈话，说研究视觉要从一个agent（执行者）的角度，带着任务进来的这么一个人或机器人，主动地去激发视觉。</p>
<p>目前的计算机视觉的研究还有一大部分是由视频监控的应用来驱动的，比如说我检测一些异常现象，看这个人是男还是女？那这也是一种被动的，就是说它只是在看，没有去做。要去做的话，就涉及到因果关系和更多的不确定性。所以现在的研究生觉得，他整天在做机器学习， 就在调参数，就在跟别人比拼百分之几的性能。 一些公司的研究所就报道， 他们在某某问题（数据集）上国际领先了，排名第一了。他们自己也觉得这个研究没多少意思。那是因为他们没有接触到这些基本的问题上来。 </p>
<p>杨：他们可能还没有发现这个问题本身是多么有趣。</p>
<p>朱：因为作为一个科学来发展的话，那它就是要认认真真的来做，把这个理清楚。当前的火热来源于工业界， 工业界没有多少耐心资助他们的研究人员去做科学研究，大家很现实。 那么，David Marr先谈这么多好不好？以后我们可能还会继续深入谈的。</p>
<p>杨：好。那我们第二个人就谈一下傅京孫。</p>
<p>第四节：视觉的开创者之二：傅京孫（King-Sun Fu）的学术思想</p>
<p>朱： David Marr是从这个神经科学和脑科学这个方向来的。傅京孫【1930-1985】，他当时代表的是计算机科学，搞人工智能的人。他是一个有领导才能的人物。他和其他人于1973年组织了第一届国际模式识别会议（ICPR），并担任主席。会议后来演变成国际模式识别学会IAPR，在1976年成立，并被选为其主席。他重组了另外一个IEEE学会下面的模式识别委员会，并于1974年成为其第一任主席，创办了IEEE模式分析和机器智能（PAMI）会刊，并于1978年担任第一任总编。这是目前计算机视觉和相关领域最权威的一本期刊了。很多中国学生现在不知道，这个领域的老大本来是华人。目前， 国际模式识别学会IAPR设立了一个傅京孫奖， 作为终身成就奖， 是模式识别的最高荣誉。</p>
<p>杨：可惜他1985年去世了。听说去世前他每年都在中国举办讲座，并于1978年担任台湾的中央研究院院士。</p>
<p>朱：我正要说的这一点。他去世的时候55岁，在普渡大学，据说他的实验室是一个Chinatown。1978年中国打开国门，中国最早的一批中科院的计算机人员都到他那里进修，在普渡。所以他对中国计算机的发展，可以说是一个贡献非常巨大的人。我也是受到他的恩惠，我大学一二年级就开始跟着科大陈国良老师学习，他之前去普度进修。周末我有时就到陈老师家听他讲外面的一些研究人员和工作。你想想，计算机界那时候华人在美国站住脚的可能没几个人。</p>
<p>杨：对，他对中国计算机发展真的是有历史性的贡献的。我在科学院上研究生的时候，我们那些老师是说他过世太早了，要不然对中国的研究还会更好，他多活10来年就会好很多。</p>
<p>朱：他1985年拿到一个很大的国家项目，好像是开宴会的时候心脏病突发了。 他要是活着，华人在这个领域的话，不止是现在这个样子。不过在他之后， 稍晚一点我们有另外一个杰出华人，黄煦涛（Tom Huang）。他当时也在普渡任教，培养了大量华人研究人员。 我们以后会专门介绍。</p>
<p>杨：傅京孫的故事也可以拍电影。</p>
<p>朱：这是我们这个领域的不幸，两个奠基人很快就走了。他们刚刚把这个地基打起来，人就没了。</p>
<p>杨：那傅的主要贡献是什么呢？</p>
<p>朱：傅京孫的贡献， 我也谈三点。第一个贡献应该就是对这个学科和学会的建设，以及工程师的培养上面，他起到了开创性的作用。一般公认他是模式识别的开山鼻祖，模式识别与计算机视觉分不开的。第二个作用，就是关于他的这个句法结构性的表达与计算，就是句法模式识别，Syntactic Pattern Recognition这个词，这个词其实非常深刻。他在走之前，他那个时候也没有多少数据，那么他只是画一些图，图表性的东西，来表达他的概念，他从计算机这边来的，你想很自然就会用到形式语言，因为计算机里面的几个基础之一是形式语言。逻辑、形式语言，对吧？</p>
<p>杨：这好像是在编译原理里面学到过，因为编译的基础是形式语言。</p>
<p>朱：我们这个世界的模式， 一个最基本的组织原则是composition。一张图像就像语言、句子符合语法结构， 视频中的一个事件也有语法结构。寻找一个层次化、结构化的解释是计算视觉的核心问题。从傅京孫1985年丢下来这个摊子后，基本很少有人去碰。差不多18年以后，我和我第一个博士生继续做图像解译Image Parsing这个方向，于2003年得了Marr马尔奖。然后我和我导师专门于2006年写了一本小书，总结了图像的随机语法。我刚才谈到了，在做识别，做分类的时候，只是单独在分类某一个东西，怎么去把各个识别器和分类器给它整合在一起，变成一个统一的表达？就必须产生一个结构上的表达。现在机器学习界把它换了另外名字，叫做结构化的输出，其实是一个东西。他们提出一个新的名词，把原创的图像解译名称覆盖住，这事现在经常发生。所以我说机器学习领域经常到别人那里偷概念，改头换面。数学界不允许这样做的。我还是坚持把它叫做解译、语法。</p>
<p>因为语法，它就是一些规则，其实语法并不见得是一个确定性的，它可以跟统计连在一块，它也可以跟目前的一些神经网络结合，这个都没问题。它表达了一个骨架或者支柱，形成一个统一表达。</p>
<p>第三点，从算法的角度来讲，有一个层次化的表达以后，意义就不一样了，比如自底向上或自顶向下的计算的过程就可以在上面体现出来，就是马尔说的计算的过程，就可以在这里面体现出来。视觉的计算过程应该是由大量的自底向上（bottom-up）和 自顶向下（top-down）过程交互和同时进行的。顺便再说一句，当前的深度神经网络就是一个feedforward的自底向上的计算， 缺乏自顶向下的过程。而在人脑计算中，自顶向下的计算占据很大一部分。</p>
<p>杨：那就是说， 这个语法结构对计算过程有了规范和表达的途路。</p>
<p>朱：对，你的搜索的过程，这个计算的过程是什么？马尔他提出了第二个概念，说视觉是个计算的过程，那么这个计算过程你什么时候算哪个，这是个调度的问题，就像操作系统。那么David Marr计算的过程，没完没了的，随着你的任务不断改变，那么它就有一个调度的问题。所以说我现在要去做饭，或者我要欣赏风景，或者说我要去走路，开车，那么它的不同的任务产生了不同的进程。这个进程，要在层次化的表达里面的统一起来调度。从这个意义看，感知是计算一个解译图（parse graph）， 认知是对这个parse graph进一步推理扩大， 而机器人的任务规划（task planning）也是一个同样结构的parse graph， 那就更别说语言是用parse graph来表达的。所以，人工智能的一个核心表达就是随机的语法和解译图。   </p>
<p>杨：对。</p>
<p>朱：这个是绕不掉的，不管谁来做，都要做这个事情。当然，现在有人千方百计想绕过去，重新发明一套名词， 让新来的学生忘记历史， 这样他们就可以变成社会公认的大师。有些教授、研究人员在学术上没什么原创贡献， 却在网上、社会上成了当红明星, 学科代言人。用社会上的知名度再给学术界施压。</p>
<p>总结一下，傅京孫三点主要贡献：一是学科的人才和组织基础，二是他提出这么一个的语法表达方法， 三是这个表达支撑了自底向上或自顶向下的计算的过程。他去世后， 这个方向一直处于一种休眠状态，我的研究有一条线是跟着这个方向做。2011年马里兰大学周少华他的导师有一个演讲，题目叫：语法模式识别—从傅到朱 （From Fu to Zhu）。我们在继承他的框架往前走。</p>
<p>杨：真好！那么咱们下面就谈第三个人Ulf Grenander。</p>
<p>朱：这个人的话，知道的人非常少。</p>
<p>杨：我翻看了网上资料，他是这个领域里头真正的是大神了，但绝对是个小众人物。</p>
<p>第五节：视觉的开创者之三：Ulf Grenander的学术思想</p>
<p>朱：Ulf Grenander 【1923-2016】是很少有人知道的。感觉有点像金庸小说《天龙八部》里的在藏经阁扫地的灰衣老僧。武功和思想都出神入化，但是，他基本是世外高人，不参与江湖争斗， 金庸也没有交代他的名字。所以江湖上的人大多没听说过他。 这样也好， 他自自在在活了93岁， 今年刚刚去世的。国际应用数学季刊邀请我和其他人写纪念文章，正准备出版专刊呢。</p>
<p>杨：对，我读他的生平，他这个人简直就是把欧洲美洲的，还有俄国的所有的精华的人物都接触过。</p>
<p>朱：那是，他出身在瑞典，他的导师叫Harald Cramér。概率论里面的一个重要的定理，还有数论里的一个猜想是用他命名的。然后，他也跟 Bohr（波尔），Kolmogorov（科尔莫戈罗夫）他们走得比较近。他的起点就是做概率统计， 时间序列， 随机过程，因为你现在想概率论和统计学的一些重要应用，就是那个时候发力了。</p>
<p>杨：从保险业开始了，北欧那边因为航海，保险业非常发达，所以这也有点道理。</p>
<p>朱：关于概率和统计学对于科学、视觉、以及人工智能的重要意义， Mumford 1999年写了一篇论文，是在一个大会的发言，叫做《随机性时代的曙光》（Dawning of the Age of Stochasticity）。</p>
<p>杨：对，那是你们老师写的， 网上能找到。</p>
<p>朱：他总结说，过去两千多年的西方科学的发展是建立在亚里士多德以来的数理逻辑基础之上的。但是，后面一千年包括人工智能、人的思维这些东西是随机性过程。人的思维应该是建立在概率推理基础之上。其实， 我们看到现在的机器学习， 人工智能完全就是从这个方向走了。</p>
<p>杨：你的导师说，整个世界的数学可以用概率的这套思想重新写一遍，就像罗素和怀特海的写这个数学原理似的，可以把数学重新建立起来，用概率的这种思想。</p>
<p>朱：这个工作已经有人做了。E. T. Jaynes就是发明最大熵原理的那个人，他写了一本很厚的书，《Probability Theory: The Logic of Science》， 他就是用这个原理去写。这也是一篇遗作。他没写完就过世了。这也是以后可以谈的话题。</p>
<p>朱： Ulf Grenander就诞生在这么一个概率发源的中心的地带，跟几个大师学习，博士毕业后出来游历，做概率论随机过程的这些东西。到六、七十年代的时候，他就开始提出来，想用数学来把这个模式识别与智能的现象的问题定义清楚。我们前面谈到的David Marr 是从神经科学、认知科学来的。傅京孫是一个计算机科学与工程的人。这两者基本没有多少严格的数学定义，提出的框架是漂浮的。Ulf是从数学的角度，奠定基础。他提出来一个应用数学的分支， 叫做 Pattern Theory。他的出发点完全不同， 就是要给世界上的各种模式、现象， 建立一个数学的框架来研究。 格局就很宏伟。而不是急于去解决某种实际问题， 后者叫做模式识别 （pattern recognition）。 他在90岁高龄出版了最后一本书， 想用数学来研究人的思想是从哪里来的。 你看我们脑袋里的念头、主意也往往是随机产生，像冒泡一样， 所谓思如泉涌。到底怎么来的？</p>
<p>杨：那太了不起了。这个事说起来，我想到当时我的老师是让我读Geman and Geman 1984年的吉布斯采样算法，那就已经了不起了。</p>
<p>朱：Grenander最后落脚在布朗大学应用数学系，Geman是他当年（70年代末80年代初）招到组里的年轻教员之一。这个吉布斯采样（Gibbs Sampler）的算法是一个里程碑的东西，在80年代初引起轰动。但那只是这个学派的诸多贡献的一个片段。</p>
<p>Grenander的理论解释起来的确有点费劲，既然谈历史，我先从我个人的经历谈一下。</p>
<p>他1994年出了一部总结性的书，900多页，叫做《General Pattern Theory》，广义模式理论。有点爱因斯坦做广义相对论的意思。但这本书很抽象， 没多少人读。我1995年在哈佛研究纹理模型（texture models），因为我用的学习算法就是吉布斯采样，在训练的时候，跑一遍要等两个星期才收敛，机器被占了，我就有时间，也是耐着性子把这本书读完了。我估计世界上不超过20人，能有耐心完整地读他的书。然后，我1996年1月答辩论文，我导师和我每周开车去布朗大学参加讨论。波士顿的冬天很冷， 哈佛到布朗1个小时左右，漫天大雪， 我们有时在高速上车被陷住， 下来铲雪。到了6月， 我导师从哈佛提前退休，带着我一起加入布朗的应用数学系。那在当时是一个学术思想的中心。组会里有Grenander，Mumford， Geman 还有其他20来人， 一坐就是2个多小时。这些人都明察秋毫， 做报告的人无法含混过去的， 一步一步都必须理清楚，说不清楚你就下去想， 下次再来。</p>
<p>我一直认为计算机视觉和模式识别领域亏欠Grenander, 因为统计建模和随机计算逐渐成为我们领域的核心理论基础，而大家并不知道，很多思想、算法都源于这个人或者他的学派。所以，2012年， 我主持CVPR（国际计算机视觉和模式识别）大会， 特意放到布朗大学附近召开，我和另外两个主席一说，大家立即就同意了。并特制了一个银质的大奖章， 在大会上颁给他，表达我们的敬意。这里发生很多故事，我们以后再谈吧。</p>
<p>杨：那你能简短总结一下Grenander对计算机视觉、甚至人工智能的主要贡献吗。</p>
<p>朱：还是谈三点主要的吧。 首先，他提出了一个思想， 叫做 analysis-by-synthesis， 这是所谓 产生式建模的核心理念。当你要去识别、分析一个模式，比如一个动物，人脸， 一个事件， 你首先要建立一个数理模型， 这个模型通过数据来拟合， 也就是当前的机器学习。 那么， 判断这个模型好坏， 或者模型是否充分，的一个依据是什么呢？产生式建模的方法就是对这个模型随机抽样，也就是，合成（synthesis）。 我把这个过程直观叫做“计算机之梦”。计算机模型一开始初始化为空（完全随机）， 那它做的梦就是白噪声， 或者一张白纸。通俗来说， 这个模型就是一个“白痴”。人脑有这个功能，我们把眼睛一闭，没有外界输入了，就能做梦， 白日梦就是想象力的体现。一个好的模型采样产生的图片（模式）， 与真实观察的图片（模式）， 就应该是真假难辨。如果你能分辨，那说明这个模型不到位。  现在很多机器学习的方法是没法去随机合成图片的。  举个例子来说，我要检验你是不是真的听懂和理解中文，就看你能不能说流利的中文。如果你说话语法有错，词汇量不够，或者有口音，那就揭示你在哪方面还需要提高。 </p>
<p>杨：这个要求好像比光是听懂 要更严格。</p>
<p>朱：的确。我们当年考英语， 多半是读，说和写都不行。我们考TOEFL， GRE Verbal的时候， 就算没搞懂， 也能蒙个60%-70%。 新东方的题海战术也很奏效。当你做了大量考题， 就算不懂， 也能考好。当前大数据、机器学习就用题海战术。 这个方法强调在实战中检验，考什么就拼命复习什么，不考的东西就不学，这也很有道理，很直接， 来得快。 但是， 因为你的模型没有真正理解， 没有“真懂”，考试大纲外面的东西更不懂， 那么后遗症就是， 遇到新考题， 缺乏泛化能力，遇到新问题，缺乏创造力。</p>
<p>想一想， 如果我的学生一步步考试都是靠题海战术这么学过来的， 那多可怕，要让他们去搞研究、创新，那就基本不可能。很遗憾的是，现在中国学生从幼儿园开始，就是在题海中泡大的。机器人、人工智能，靠题海战术是可以演示不少功能的， 但是， 那还离真正的智能比较遥远。 </p>
<p>杨：好， 我明白这个analysis-by-synthesis 的意义了。他的第二贡献呢？</p>
<p>朱：他提出了一整套建模的理论和方法。把代数、几何、概率整合起来。 代数指的是一些结构，比如群论， 记得在科大本科我学过 群、环、域这些概念吧？也就是说我有一些基本元素，叫 generator，连接成为图graph，然后是群group，在上面进行操作, 产生了各种各样的变化。还有很多几何， 变换， 在连续情况就产生形变。通过组合，语法、产生丰富的图模式。然后，再在这个图模式的空间上定义距离（测度）和概率。</p>
<p>朱：比如一个概率模型， 是定义在一个什么样的结构上，它是个什么样的解空间？这个数理上你必须交代清楚，否则你的论文写不下去了。现在它的一个很大的应用在医疗图像上面，比如说一个病人，他的肝变形了，那么他的肝的形状和正常人的肝的形状之间怎么定义一个合理的距离？两张人脸，怎么定义这个距离的呢？这个距离定义在一个流型上，数学的流型（manifold）。</p>
<p>杨：这些东西真用上了吗？ </p>
<p>朱：他有个Postdoc，名叫Michael Miller， 现在是Johns Hopkins 大学图像中心主任， 就用这一套方法来做医疗图像、脑科学（Brain Mapping）等方面的应用。</p>
<p>杨：他的第三方面的贡献呢？</p>
<p>朱：第三个方面主要是算法上面。当我们去做求解的时候，在一个解空间，这个求解空间肯定是一个非凸的，他有千千万万的局部最优解local minimum 在里面。</p>
<p>杨：对。这是当时八十年代的时候提出来一个很尖锐的问题，好像有什么模拟煺火方法。</p>
<p>朱：很多蒙特卡洛算法都是他和这个学派的人提出来的。这个解空间是一个异构空间，空间里面非常复杂的，包含有很多子空间，子空间里面又包含又子空间，每个子空间维度又不一样，他们之间，从一个解跳到另外一个解的时候，这跳转必须是可逆的。在计算机里面就叫可以回溯。从这个学派走出来的人，他们设计算法每一个步骤都是有章法的，要做到合规合矩。包括上面提到的吉布斯采样算法、可逆蒙特卡洛跳转法，还有变分法（variational methods）和偏微分方程式， 还有一些随机下降法（stochastic gradient）， 这后者是目前训练深度学习模型的主要办法。他也开创了非参数模型的学习方法。这里面东西太多，先谈到这里吧。</p>
<p>正因为很多人没有接触过Grenander的理论， 缺乏这方面的理论素养， 造成我们学科发展的一个巨大的问题：很多教授、博士、研究生就是用别人的模型（机），拿来调试，基本缺乏自己发明新模型、新算法的能力。我们这个领域，很多美国名牌大学助理教授、副教授、教授， 他们的论文中的公式错误百出。现在干脆大家在论文中都不写公式了， 直接报告最后的实验结果，提高了几个百分点。这就“一俊掩百丑”了。 英文有个类似的说法叫做 “sweep the dirt under the carpet把污垢扫到地毯下”。 这些人在大量培养博士、他们出来的人评审论文。 这样一来，学科的发展堪忧！  </p>
<p>第六节：结束语</p>
<p>杨：听了你番谈话，我明白很多。记得我当时念研究生，包括念博士生的时候，实际上是很糊涂的。就是对这个领域到底做多少东西，没有信心。觉得很多研究像画鬼一样，原理不清楚。我觉得那样的话，与其那样做事情, 那不如干脆到工业界那更快乐。</p>
<p>朱：正因为我们这个领域很多历史、框架性的东西，没有搞清楚，培养出来的博士，缺乏分析能力。大家被一些工程的任务和数据驱动，被一些性能的指标牵制，对科学的发展比较迷茫。</p>
<p>杨：好， 谈了很多， 我们做个总结吧。</p>
<p>朱：那我就说两点。 </p>
<p>首先， 我在开场白中提到 “一个民族如果忘记了历史, 她也注定将失去未来。”一个学科要健康发展，需要研究人员、研究生们理解自己领域的历史和大的发展方向，建立文化的认同。否则，自己家的东西，被别人偷取，浑然不知。就像日本打入中国，想把我们的地名改掉，大家开始说日语，把名字都改做山本太郎之类，感觉很酷吗？  或者是韩国人把中国的文化拿去申报世界文化遗产，这都是要制止的。否则，过了一代人，还真说不清楚了。我记得刚来美国的时候，美国同事把汉字叫做“Kang-ji”，说是日本字。  我们领域很多人对保护这个领域的文化和传统缺乏清醒认识。皮之不存，毛将焉附？</p>
<p>其次，一个学科内部，大家互相不够了解，各自为政。特别现在会议审稿人很多是研究生，以自己的狭窄的眼光和标准去评判别人的方法，造成很多混乱。搞工程的看不到理论的重要性，反之亦然。大家又都疏远心理学和认知科学的研究。我提倡我们的研究人员、学生要提高理论修养、培养长远眼光，向相关学科取经，取长补短。</p>
<p>我希望这个微信公众号，能够帮助大家正视问题，让计算机视觉这个领域健康、稳健、可持续地发展。</p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
      

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-文本挖掘" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/11/22/文本挖掘/" class="article-date">
  	<time datetime="2016-11-22T13:04:33.000Z" itemprop="datePublished">2016-11-22</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <h4 id="文本挖掘">文本挖掘</h4><hr>
<p><strong>1.背景</strong></p>
<p>随着互联网的大规模普及和企业信息化程度的提高,文本信息的快速积累使公司、政府和科研机构在信息处理和使用中面临前所未有的挑战。一方面,互联网和企业信息系统每天都不断产生大量文本数据,这些文本资源中蕴含着许多有价值的信息;而另一方面因为技术手段的落后,从大量数据资源中获取需要的信息十分困难。人们迫切需要研究出方便有效的工具去从大规模文本信息资源中提取符合需要的简洁、精炼、可理解的知识,文本挖掘就是为解决这个问题而产生的研究方向。</p>
<p>传统的自然语言理解是对文本进行较低层次的理解,主要进行基于词、语法和语义信息的分析,并通过词在句子中出现的次序发现有意义的信息。在这一层次遇到的问题多与句法和语义歧义性相关。对文本较高层次的理解主要集中在研究如何从各种形式的文本和文本集中抽取隐含的模式和知识。文本高层次理解的对象可以是仅包含简单句子的单个文本也可以是多个文本组成的文本集,但是现有的技术手段虽然基本上解决了单个句子的分析问题,但是还很难覆盖所有的语言现象,特别是对整个段落<br>或篇章的理解还无从下手。</p>
<p>在19世纪早期发展起来的以统计技术为基础的数据挖掘技术已经发展的较为成熟,并在大规模结构化关系数据库上应用取得成功。将数据挖掘的成果用于分析以自然语言描述的文本,这种方法被称为文本挖掘(Text Mining, TM)或文本知识发现(Knowledge Discovery in Text, KDT)。与传统自然语言处理(Natural Lnaguage Proeessing, NLP)关注词语和句子的理解不同,文本挖掘的主要目标是在大规模文本集中发现隐藏的有意义的知识,即对文本集的理解和文本间关系的理解。因此,文本挖掘是自然语言处理和数据挖掘技术发展到一定阶段的产物。</p>
<p>在现实世界中,可获取的大部信息是以文本形式存储在文本数据库中的,由来自各种数据源的大量文档组成,如新闻文档、研究论文、书籍、数字图书馆、电子邮件和Web页面。由于电子形式的文本信息飞速增涨,文本挖掘已经成为信息领域的研究热点。</p>
<p><strong>2.定义</strong></p>
<p>文本数据库中存储的数据可能是高度非结构化的,如Web网页;也可能是半结构化的,如Email消息和一些XML网页;而其它的则可能是良结构化的。良结构化文本数据的典型代表是图书馆数据库中的文档,这些文档可能包含结构字段,如标题、作者、出版日期、长度、分类等等,也可能包含大量非结构化文本成分,如摘要和内容。通常,具有较好结构的文本数据库可以使用关系数据库系统实现,而对非结构化的文本成分需要采用特殊的处理方法对其进行转化。</p>
<p>文本挖掘是一个交叉的研究领域,它涉及到数据挖掘、信息检索、自然语言处理、机器学习等多个领域的内容,不同的研究者从各自的研究领域出发,对文本挖掘的含义有不同的理解,不同应用目的文本挖掘项目也各有其侧重点。因此,对文本挖掘的定义也有多种,其中被普遍认可的文本挖掘定义如下:</p>
<p>定义: 文本挖掘是指从大量文本数据中抽取事先未知的、可理解的、最终可用的知识的过程,同时运用这些知识更好地组织信息以便将来参考。</p>
<p>直观的说,当数据挖掘的对象完全由文本这种数据类型组成时,这个过程就称为文本挖掘。</p>
<p>文本挖掘也称为文本数据挖掘[Hearst97]或文本知识发现[Fedlmna95],文本挖掘的主要目的是从非结构化文本文档中提取有趣的、重要的模式和知识。可以看成是基于数据库的数据挖掘或知识发现的扩展F[ayyda96,Simoudis96]。</p>
<p>文本挖掘是从数据挖掘发展而来,因此其定义与我们熟知的数据挖掘定义相类似。但与传统的数据挖掘相比,文本挖掘有其独特之处,主要表现在:<strong>文档本身是半结构化或非结构化的,无确定形式并且缺乏机器可理解的语义</strong>;而数据挖掘的对象以数据库中的结构化数据为主,并利用关系表等存储结构来发现知识。因此,<strong>有些数据挖掘技术并不适用于文本挖掘,即使可用,也需要建立在对文本集预处理的基础之上。</strong></p>
<p><strong>3.文本挖掘过程</strong></p>
<p>文本知识发现主要由以下步骤组成：</p>
<pre><code><span class="comment">文档集合</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="title">[</span><span class="comment">文本预处理</span><span class="title">]</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span>&gt;<span class="comment">文档中间形式</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="title">[</span><span class="comment">文本挖掘</span><span class="title">]</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span>&gt;<span class="comment">模式</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="title">[</span><span class="comment">评估与表示</span><span class="title">]</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span>&gt;<span class="comment">知识</span>
</code></pre><p>1)文本预处理:</p>
<p>选取任务相关的文本并将其转化成文本挖掘工具可以处理的中间形式。</p>
<pre><code><span class="comment">文本集</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span>&gt;<span class="comment">特征抽取</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span>&gt;<span class="comment">特征选择</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span>&gt;<span class="comment">文本特征矩阵</span>
</code></pre><p>通常包括两个主要步骤:</p>
<p>(a)特征抽取:建立文档集的特征表示,将文本转化成一种类似关系数据且能表现文本内容的结构化形式,如信息检索领域经常采用的向量空间模型就是这样一种结构化模型。</p>
<p>(b)特征选择:一般说来结构化文本的特征空间维数较高,需要对其进行缩减,只保留对表达文本内容作用较大的一些特征。</p>
<p>2)文本挖掘:</p>
<p>在完成文本预处理后,可以利用机器学习、数据挖掘以及模式识别等方法提取面向特定应用目标的知识或模式。</p>
<p>3)模式评估与表示<br>最后一个环节是利用已经定义好的评估指标对获取的知识或模式进行评价。如果评价结果符合要求,就存储该模式以备用户使用;否则返回到前面的某个环节重新调整和改进,然后再进行新一轮的发现。</p>
<p><strong>4.研究现状</strong></p>
<p>在文本挖掘过程中,文本的特征表示是整个挖掘过程的基础;而<strong>关联分析、文本分类、文本聚类</strong>是三种最主要也是最基本的功能。</p>
<p><strong>4.1文本特征表示</strong></p>
<p>传统数据挖掘所处理的数据是结构化的,其特征通常不超过几百个;而非结构化或半结构化的文本数据转换成特征向量后,特征数可能高达几万甚至几十万。所以,文本挖掘面临的首要问题是如何在计算机中合理的表示文本。这种表示法既要包含足够的信息以反映文本的特征,又不至于太过庞大使学习算法无法处理。这就涉及到文本特征的抽取和选择。</p>
<p>文本特征指的是关于文本的元数据,可以分为描述性特征,如文本的名称、日期、大小、类型以及语义性特征,如文本的作者、标题、机构、内容。描述性特征易于获得,而语义特征较难获得。在文本特征表示方面,内容特征是被研究得最多的问题。</p>
<p>当文本内容被简单地看成由它所包含的基本语言单位(字、词、词组或短语等)组成的集合时,这些基本的语言单位被称为<strong>项(Term)</strong>。如果用出现在文本中的<br>项表示文本,那么这些项就是文本的特征。</p>
<p>对文本内容的特征表示主要有布尔模型、向量空间模型、概率模型和基于知识的表示模型。因为<strong>布尔模型和向量空间模型</strong>易于理解且计算复杂度较低,所以成为文本表示的主要工具。</p>
<p><strong>(1)特征抽取</strong></p>
<p>中文文档中的词与词之间不像英文文档那样具有分隔符,因此中、英文文档内容特征的提取步骤略有不同。</p>
<pre><code><span class="comment">英文文档集合</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span>&gt;<span class="comment">消除停词</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span>&gt;<span class="comment">词干抽取</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span>&gt;<span class="comment">特征词集合</span>
<span class="comment">中文文档集合</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span>&gt;<span class="comment">消除停词</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span>&gt;<span class="comment">词语切分</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span>&gt;<span class="comment">特征词集合</span>
</code></pre><p><strong>消除停词</strong>:<br>文本集有时包含一些没有意义但使用频率极高的词。这些词在所有文本中的频率分布相近,从而增加了文本之间的相似程度,给文本挖掘带来一定困难。解决这个问题的方法是用这些词构造一个停词表或禁用词表(stop word list)[Ricardo1991],在特征抽取过程中删去停词表中出现的特征词。</p>
<p>常用的停词包括虚词和实词两种,如</p>
<p>(i)虚词:英文中的”a,the,of,for,with,in,at,…”<br>中文中的”的,地,得,把,被,就…”</p>
<p>(ii)实词:数据库会议上的论文中的“数据库”一词,可视为停词。</p>
<p><strong>词干抽取</strong>:</p>
<p>定义: 令V(s)是由彼此互为语法变形的词组成的非空词集,V(s)的规范形式称为词干(stem)。</p>
<p>例如,如果V(s)={connected,connecting,connection,connections},那么s=connect 是V(s)的词干。</p>
<p><strong>词干抽取(stemming)有四种不同的策略:词缀排除(affix rermoval)、词干表查询(table lookup)、后继变化(successor variety)和n-gram</strong>。其中词缀排除最直观、简单且易于实现。多数词的变形是因添加后缀引起的,所以在基于词缀排除策略的抽取算法中后缀排除最为重要,Porter算法[Porter80]是后缀排除算法中最常用的一种。</p>
<p>词干抽取将具有不同词缀的词合并成一个词,降低文本挖掘系统中特征词的总数,从而提高了挖掘系统的性能。</p>
<p>当然,也有两点需要注意:</p>
<p>(1)词干抽取对文本挖掘性能的提高仅在基于统计原理的各种分析和挖掘技术下有效。在进行涉及语义和语法的自然语言处理时,不适宜采用词干抽取技术。</p>
<p>(2)词干抽取对文本挖掘或信息检索准确性的影响至今没有令人信服的结论,因此许多搜索引擎和文本挖掘系统不使用任何词干抽取算法。</p>
<p><strong>汉语切分</strong>:</p>
<p>汉语的分词问题己经基本解决,并出现了多种分词方法。这些分词方法可以分为两类:一类是理解式分词法,即利用汉语的语法知识、语义知识及心理学知识进行分词;另一类是机械式分词法,一般以分词词典为依据,通过文本中的汉字串和词表中的词逐一匹配完成词语切分。第一类分词方法算法复杂,实际应用中经常采用的是第二类分词方法。机械式分词法主要有正向最大匹配法,逆向最<br>大匹配法,逐词遍历法。</p>
<p>由于词典的容量有限,在大规模真实文本处理中,会遇到许多词典中未出现的词,即未登录词。未登录现象是影响分词准确率的重要原因。为解决这个问题,人们提出利用N-gram语言模型进行词项划分[周01a,01b],从而摆脱基于词典的分词方法对词典的依赖。与基于词典的分词方法不同,基于N-gram技术得到的词项不一定具有实际意义。</p>
<p>例如:“文本挖掘”的所有N-gram项为:</p>
<pre><code><span class="number">1</span>-<span class="string">gram:</span>文,本,挖,掘
<span class="number">2</span>-<span class="string">gram:</span>文本,本挖,挖掘
<span class="number">3</span>-<span class="string">gram:</span>文本挖,本挖掘
<span class="number">4</span>-<span class="string">gram:</span>文本挖掘
</code></pre><p>其中除1-gram是单字外,2-gram中的“本挖”,3-gram中的“文本挖”,“本挖掘”都不具有实际意义。</p>
<p><strong>(2)特征选择</strong></p>
<p>特征选择也称特征子集选择或特征集缩减。经过特征抽取获得的特征词数量很多,有时达数万个特征。如此多的特征对许多文本挖掘方法,如文本分类、聚类、文本关联分析来说未必都是有意义的;而过大的特征空间还会严重影响文本挖掘的效率,因此选择适当的特征子集十分必要。</p>
<p>通常采用机器学习的方法进行文本特征选择。虽然机器学习中有许多选取特征子集的算法,但有些算法复杂且效率低下,不适于处理庞大的文本特征集。</p>
<p>国外对特征选择的研究较多[Mladenic99,Mladenic03,Lewis92,Liu96],特别是已有专门针对文本分类特征选择方法的比较研究[Yang97]。国内对这一问题的研究以跟踪研究为主,集中在将国外现有特征评估函数用于中文文本特征选择[周<br>02]及对其进行改进[李99]。</p>
<p><strong>4.2基于关键字的关联分析</strong></p>
<p>文本数据一旦被转化成结构化中间形式后,这种中间形式就作为文本挖掘过程的基础。</p>
<p>与关系数据库中关联规则的挖掘方法类似,基于关键词的关联规则产生过程包括两个阶段:</p>
<p><em>关联挖掘阶段</em>:<br>这一阶段产生所有的支持度大等于最小支持度闭值的关键词集,即频繁项集。</p>
<p><em>规则生成阶段</em>:<br>利用前一阶段产生的频繁项集构造满足最小置信度约束的关联规则。</p>
<p>Feldman等人实现了基于上述思想的文本知识发现系统KDT[Feldman96]、FACT[Feldman97],KDT系统在Reuter22173语料集中发现的关联规则示例:</p>
<pre><code>[<span class="constant">Iran,Nicaragua,Usa]</span>-&gt;<span class="constant">Reagan </span><span class="number">6</span>/<span class="number">1.00</span>
[gold,copper]-&gt;<span class="constant">Canada </span><span class="number">5</span>/<span class="number">0</span>.<span class="number">556</span>
[gold,silver]-&gt;<span class="constant">USA </span><span class="number">19</span>/<span class="number">0</span>.<span class="number">692</span>
</code></pre><p>根据不同的挖掘需要,可以利用不同的挖掘方法,如关联挖掘、最大模式挖掘或层次关联挖掘,完成相应的文本分析任务。</p>
<p><strong>4.3文本分类</strong></p>
<p>文本分类是文本挖掘中一项非常重要的任务,也是国内外研究较多的一种挖掘技术。在机器学习中分类称作有监督学习或有教师归纳,其目的是提出一个分类函数或分类模型(也称作分类器),该模型能把数据库中的数据项映射到给定类别中的一个。</p>
<p>一般来讲,文本分类需要四个步骤:</p>
<p>(1)获取训练文本集:训练文本集由一组经过预处理的文本特征向量组成,每个训练文本(或称训练样本)有一个类别标号;</p>
<p>(2)选择分类方法并训练分类模型:文本分类方法有统计方法、机器学习方法、神经网络方法等等。在对待分类样本进行分类前,要根据所选择的分类方法,利用训练集进行训练并得出分类模型;</p>
<p>(3)用导出的分类模型对其它待分类文本进行分类;</p>
<p>(4)根据分类结果评估分类模型。</p>
<p>另外需要注意的是,文本分类的效果一般和数据集本身的特点有关。有的数据集包含噪声,有的存在缺失值,有的分布稀疏,有的字段或属性间相关性强。目前,普遍认为不存在某种方法能适合于各种特点的数据[Yang99a,Yang99b]。</p>
<p>随着nIetmet技术的发展和普及,在线文本信息迅速增加,文本分类成为处理和组织大量文本数据的关键技术。而近二十多年来计算机软、硬件技术的发展和自然语言处理、人工智能等领域的研究进展为文本自动分类提供了技术条件和理论基础。迄今为止,文本分类研究已经取得了很大的进展,提出了一系列有效的方法,其中分类质量较好的有k最近邻(k-Nearest Neighbor,KNN),[Iwayama95,Yang97,Yang99a]、支持向量机(Support Vector Machine,SVM)[Joachims98]、朴素贝叶斯(Naive Bayes,NB)[Lewis94,Chakra97,Lewis98]。1998年文献[Liu98]提出了基于关联规则的分类方法CBA,此后陆续有人进行这方面的研究,如CAEP[Dong99]、JEP[Li00a,Li00c]、DeEPs[Li0Ob]、CMAR[Li01]和用于文本分类的ARC[Zaiane02]。</p>
<p>国内对中文文本自动分类的研究起步较晚,尽管己有一些研究成果[李04,姚03,邹99,周01a],但由于尚没有通用的标准语料和评价方法,很难对这些成果进行比较。而对基于关联规则的文本分类的研究在国内还未见到。</p>
<p><strong>4.4文本聚类</strong></p>
<p>文本聚类是根据文本数据的不同特征,将其划分为不同数据类的过程。其目的是要使同一类别的文本间的距离尽可能小,而不同类别的文本间的距离尽可能的大。主要的聚类方法有统计方法、机器学习方法、神经网络方法和面向数据库的方法。在统计方法中,聚类也称聚类分析,主要研究基于几何距离的聚类。在机器学习中聚类称作无监督学习或无教师归纳。聚类学习和分类学习的不同主要在于:分类学习的训练文本或对象具有类标号,而用于聚类的文本没有类标号,由聚类学习算法自动确定。</p>
<p>传统的聚类方法在处理高维和海量文本数据时的效率不很理想,原因是:<br>(1)传统的聚类方法对样本空间的搜索具有一定的盲目性;<br>(2)在高维很难找到适宜的相似度度量标准。</p>
<p>虽然,文本聚类用于海量文本数据时存在不足。但与文本分类相比,文本聚类可以直接用于不带类标号的文本集,避免了为获得训练文本的类标号所花费的代价。根据聚类算法无需带有类标号样本这一优势,Nigam等人提出从带有和不带有类标号的混合文本中学习分类模型的方法[Ngiam98]。其思想是利用聚类技术减少分类方法对有标号训练样本的需求,减轻手工标记样本类别所需的工作<br>量,这种方法也称为半监督学习。</p>
<p>文本聚类包括以下四个步骤:</p>
<p>(1)获取结构化的文本集。</p>
<p>结构化的文本集由一组经过预处理的文本特征向量组成。从文本集中选取的特征好坏直接影响到聚类的质量。如果选取的特征与聚类目标无关,那么就难以得到良好的聚类结果。对于聚类任务,合理的特征选择策略应是使同类文本在特征空间中相距较近,异类文本相距较远。</p>
<p>(2)执行聚类算法,获得聚类谱系图。聚类算法的目的是获取能够反映特征空间样本点之间的“抱团”性质。</p>
<p>(3)选取合适的聚类阈值。在得到聚类谱系图后,领域专家凭借经验,并结合具体的应用场合确定阈值。阈值确定后,就可以直接从谱系图中得到聚类结果。</p>
<p>目前,常见的聚类算法可以分成以下几类[Han01]:</p>
<p>(1)平面划分法:对包含n个样本的样本集构造样本集的k个划分,每个划分表示一个聚簇。常见的划分聚类算法有k-均值算法,k-中心点算法,CLARANS算法。</p>
<p>(2)层次聚类法:层次聚类法对给定的样本集进行层次分解。根据层次分解方向的不同可分为凝聚层次聚类和分裂层次聚类。凝聚法也称为自底向上的方法,如AGNES;分裂法也称自顶向下的方法,如DIANA、CURE、BIRCH、Chameleon。</p>
<p>(3)基于密度的方法:多数平面划分法使用距离度量样本间的相似程度,因此只能发现球状簇,难以发现任意形状簇。基于密度的聚类法根据样本点临近区域的密度进行聚类,使在给定区域内至少包含一定数据的样本点。DBSCAN就是一个具有代表性的基于密度的聚类算法。</p>
<p>(4)基于网格的方法:采用多分辨率的网格数据结构,将样本空间量化为数量有限的网格单元,所有聚类操作都在网格上进行,如STING算法。</p>
<p>(5)基于模型的方法:为每个簇假定一个模型,然后通过寻找样本对给定模型的最佳拟合进行聚类。</p>
<p>有些聚类算法集成多种算法的思想,因此难以将其划归到上述类别中的一类,如CLIQUE综合了密度和网格两种聚类方法。</p>
<p>文本聚类有着广泛的应用,比如可以用来:</p>
<p>(1)改进信息检索系统的查全率和查准率[Ricardo99];</p>
<p>(2)用于文本集浏览[Cutting92];</p>
<p>(3)搜索引擎返回的相关文本的组织[Zamir97];</p>
<p>(4)自动产生文本集的类层次结构[Koller97]。在带有类标号的文本集上发现自然聚类[Aggarwal99],然后利用自然聚类改进文本分类器。</p>
<p><strong>5.文本挖掘与相近领域的关系</strong></p>
<p><strong>5.1自然语言处理与文本挖掘的区别</strong></p>
<p>文本挖掘与自然语言处理有着千丝万缕的联系,但也存在明显的不同:</p>
<p>(1)<strong>文本挖掘通过归纳推理</strong>发现知识,而传统的自然语言处理多采用<strong>演绎推理</strong>的方法,很少使用归纳推理方法。</p>
<p>(2)文本挖掘在大规模文本集而不是少数文本中发现知识,其目的不在于改善对文本的理解而是发现文本中的关系。虽然自然语言处理的两个新兴领域:信息检索(Information Retrieval,IR)和信息提取(Information Extraction,IE)也是以大规模文本集为对象,但只要使用严格的演绎推理,那么就不能称作文本挖掘。主要原因是它们没有发现任何知识,只是发现符合某种约束条件的文本而不是知识本身。</p>
<pre><code>[<span class="link_label">比较</span>][<span class="link_reference">方法不同</span>][<span class="link_label">目标不同</span>][<span class="link_reference">对象范围不同</span>]
自然语言处理：[<span class="link_label">演绎推理方法</span>][<span class="link_reference">更好的理解文本</span>][<span class="link_label">以一篇或少数文本为研究对象，发现表示文本特点的关系</span>]
文本挖掘：[<span class="link_label">归纳推理方法</span>][<span class="link_reference">更好的使用文本</span>][<span class="link_label">以大量文本组成的文本集为研究对象，在文本集中发现文本间或文本集中词与词之间的关系</span>]
</code></pre><p>1)信息检索与文本挖掘</p>
<p>信息检索是与数据库技术并行发展多年的领域,其中以文本为对象的文本信息检索以非结构或半结构化数据为处理对象,研究大量文本的信息组织和检索问题。</p>
<p>文本信息检索主要发现与用户检索要求(如关键词)相关的文本。例如,基于关键词的文本检索使用相关度量计算文本与用户查询间的相关性并按相关程度高低排序获得的文档。</p>
<p>近年来,基于自然语言处理技术发展起来的智能检索技术包含了对歧义信息的检索处理,如“苹果”,究竟是指水果还是电脑品牌;“华人”与“中华人民共和国”的区分,这类检索通过歧义知识描述库、全文索引、上下文分析以及用户相关反馈等技术实现文本信息检索的智能化。与文本挖掘不同,智能信息检索仍然只是关注从文本集中更有效地识别和提取相关文档,而不发现任何新的信息或知识。</p>
<p>2)信息提取与文本挖掘</p>
<p>信息提取(IE)是指提取文本集中预定义的事件或任务信息的过程,例如关于恐怖事件信息的提取,可以包括事件时间,地点,恐怖分子,受害者,恐怖分子采用的手段等等。其目的在于发现文本中的结构模式。主要过程是先根据需要确定结构模式,然后从文本中提取相应的知识填进该结构模式。文本挖掘任务则与之正好相反,它需要自动发现那些IE中给定的模式。</p>
<p><strong>5.2文本挖掘与相关领域的交叉</strong></p>
<p>虽然以上介绍的研究领域与文本挖掘存在明显的不同,但它们在某种程度上也存在交叉。最典型的交叉就是通过技术和方法的互相借鉴为各自领域提供新的有效的方法,如许多文本挖掘系统中采用的预处理方法就是最先在信息检索领域中提出并使用的。除此之外,还有其它的例子,如:</p>
<p>(1)基于文本挖掘的汉语词性自动标注</p>
<p>利用文本挖掘研究词及词性的序列模式对词性的影响是非常有新意的研究,这与人在根据上下文对词性进行判断的方法是一致的,不但根据上下文的词、词性,而且可以根据二者的组合来判断某个词的词性。</p>
<p>国内从数据挖掘的角度对汉语文本词性标注规则的获取进行了研究[李01]。其方法是在统计语料规模较大的情况下,利用关联规则发现算法发现词性标注规则。只要规则的置信度足够高,获得的规则就可以用来处理兼类词的情况。该过程完全是自动的,而获取的规则在表达上是明确的,同时又是隐含在数据中、用户不易发现的。</p>
<p>(2)基于信息抽取的文本挖掘</p>
<p>为将非结构化的自然语言文档表示成结构化形式以便直接利用传统的数据挖掘技术来进行文本挖掘。已有多种结构化方法被提出,如前面提到的文本特征表示方法就是最典型的一种。此外,随着信息抽取技术的不断发展[Freitag98,Clifton99],它在文本挖掘领域扮演着日益重要的角色。信息抽取的主要任务是从自然语言文本集中查找特别的数据段,然后将非结构化文档转化为结构化的数据库,以便更容易地理解文本。基于信息抽取<br>的文本挖掘系统框架[Nahm01]:</p>
<pre><code>Text-&gt;{Information Extraction-&gt;DB-&gt;KDD}-&gt;<span class="keyword">Rule</span> Base
</code></pre><p>在这个系统中,IE模块负责在原始文本中捕获特别的数据段,并生成数据库提供给知识发现模块进一步挖掘。</p>
<p><strong>5.3文本挖掘技术在Email处理方面的应用</strong></p>
<p>由于Email文档和普通文档之间有许多相似之处,所以可以将挖掘普通文档涉及的技术和方法用于Email信息挖掘。目前,有许多关于利用文本挖掘技术有效地组织和分析Email信息的研究。例如,通过分析Email的语言和作者性别群进行计算机取证[Rajman97];将Email信息的结构特征和语言学特征与SVM结合进行作者身份鉴别。</p>
<p>文本挖掘技术除了用于组织Email信息外,还可以用于对Email消息进行分类。如:利用朴素贝叶斯算法[Rennie00]、Rocchio算法、SVM方法和Bayesian方法[sahami98,Andr00,Sakkis01]对Email信息进行分类和过滤。此外,文献[Cohen96]和[Lewis94]则提出两个基于规则的系统,这两个系统都是利用文本挖掘技术来分类Email信息。</p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
      

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-天下第一铭[汤晓鸥]" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/11/08/天下第一铭[汤晓鸥]/" class="article-date">
  	<time datetime="2016-11-08T07:36:00.000Z" itemprop="datePublished">2016-11-08</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/11/08/天下第一铭[汤晓鸥]/">天下第一铭--汤晓鸥【转载】</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>天下第一铭</strong></p>
<p>作者：汤晓鸥</p>
<p>  2003年3月8日，陪秋梅过了最后一个属于我们二人世界的妇女节（一直觉得妇女节比情人节重要），第二天，我们安静的二人世界就变成了吵闹的三口之家。新来的第三者白白胖胖，叫铭铭，是在香港威尔士亲王医院10层楼的产科病房出生的。铭铭出生的那天，11层楼住进了一个特殊的病人，说是肺病。可是我们那几天太高兴了，根本没注意。过了两天医生叫我们去他办公室问我们要不要提前出院，因为楼上有个传染病人。我们觉得还有很多东西要和护士学，肺炎也没什么可怕的，不想早出院。等我们回到病房，发现一个层楼的新任妈妈都在收拾行李,已经走的差不多了。我们才明白问题很严重。回家后的两个多月，再没敢带铭铭出门一步。后来才知道11层的病人是香港第一例SARS.</p>
<p> 铭铭的全名叫汤之铭，是佛教大师南怀瑾先生起的名字。一直觉得是老先生取的名字保佑了铭铭。名字是老先生根据2000多年前的一部畅销书《大学》里面的典故起的。经历了SARS的苦其心志，又有老先生的保佑, 我一直觉得天将降大任于铭铭，常和秋梅讲，铭铭将来很可能成就“天下第一铭”。真是想什么来什么，果然四个月大时，就显灵了。</p>
<p> 那时我父母第一次从国内来看铭铭，第二天就要到了，可是我们一直在为一件很头疼的事伤脑筋，铭铭已经14天没大便了，看了几次医生，都说孩子活蹦乱跳的没问题，可能消化太好，听医生讲14 天可能是香港地区的纪录了，不知是不是华南地区纪录。不管怎样说，我儿子有了他自己的第一个地区级纪录了，可惜后来再没能破此纪录，最多一次才四天，可能上次太难受了，看来铭铭也不傻，不愿为虚名太苦了自己。好在我父母来的头一天，问题解决了。父母来了后抱着铭铭说，这孩子没照片上看着胖了，怎么这么轻，我当时后悔不已，不该逼铭铭做他不愿意做的事，否则铭铭至少比头一天重一倍。这孩子其实用心良苦。</p>
<p> 铭铭六个月大的时候，妈妈的假期结束了，不得不回北京工作了。铭铭当然毫不犹豫地决定跟妈妈走（主要是从他的哭声中判断的），这样我又开始了对微软亚洲研究院的经久不息的访问。可能是访问实在太频了，结果我访问的媒体计算组的主任，时任研究院副院长的张宏江问我愿不愿意接管他的媒体计算组，还没等我们开始谈条件，没过多久，研究院重组，宏江成了新成立的工程院院长，另一位副院长Harry(沈向洋)成了研究院新院长。Harry好像觉得我来管媒体计算组不大合适。我也没问为啥。过了没多久，一个周三的下午，Harry突然来电邮说想和我谈谈。原来Harry想找我接管他自己的视觉计算组，又觉得对不起媒体计算组，所以干脆将两个组合并成一个，问我愿不愿带。我第二天就答应了，Harry也怕夜长梦多，隔天我们就把很多细节敲定了，没有经过任何面试，我就在几天之内成了研究院的人了。周六，我就买了房子。那一周，感觉上像两个恋人生怕对方反悔而匆匆领了结婚证。</p>
<p>我当然不会反悔，我对研究院其实爱慕已久，研究院在我心里很像铭铭，大有天下第一铭的气势。我一直觉得Bill一生中做了两个了不起的决定，第一是和IBM签了DOS协议，第二就是建立了微软亚洲研究院。当然，有些同学可能不同意这种说法，我有时也想，和世界上最大的计算机公司签约怎么能和同世界上最大的国家签约相比呢，所以也许建立了亚洲研究院应该更重要。</p>
<p> 北京的学校差不多集中了中国十几亿人中最优秀的人才。研究院是中国唯一的一所由跨国公司成立的从事基础研究的地方。和国外一流研究机构相比，研究院近水楼台；和国内的一流研究院比，亚洲研究院具有国际一流的理念和管理模式；和IBM 及Google 在中国的研究院比，亚洲研究院从事基础研究而不是产品开发。这样独树一帜的地位，天下无双。</p>
<p> 其后果自然是人才的高度集中。其程度让我想起了中国科大和麻省理工学院(MIT)。三个地方的人都挺好，却不太一样。说起来上世纪80年代的科大最难进，因为她只看高考成绩，没什么别的好说的。这样的后果是人才比较同质化，大家的长处都差不多，学生都很像运动员，会比赛，但缺少解决实际问题的能力。MIT就好申请多了，允许书面申请，这样即使某一方面较弱也可以申诉，强调自己的强项。课外活动有超常的地方也可以加分不少。微软亚洲研究院就更好进了，不但有书面申请，还可以当面申诉（面试），有机会全面表现自己。当然，全面表现的后果也很严重，就是进去以后要全面兑现。研究能力，编程能力，写作能力，吹牛能力，缺一不可。</p>
<p>  视觉计算组的同事就具有这样的特性，感觉和他们在一起，没有什么题目做不出来的。所以我又想起了铭铭，总感觉和铭铭在一起的时间太少，想把每一分钟都记录下来，结果照了大量照片。于是很自私地号召大家做照片管理方面的研究，就有了我们在SIGCHI注1上的第一篇长论文。接着为了更方便地把照片中的人像一次从多张照片中分割出来，又做了多图分割的题目。为了快速方便地查找图像，我们做了实时图像检索技术。为了找到更多有趣的应用，又用人脸检测和照片管理技术做了一个将真人头像植入卡通图片的技术，于是很容易的用铭铭的照片将“小兵张嘎”动画图片系列变成了“小兵汤嘎”。我在研究院和一些高校做报告时经常把我们的研究课题总结为“下一代”图象处理技术，因为我们的技术多是应用在我们“下一代”儿童的照片上。</p>
<p>铭铭的照片经常用在视觉计算组的各种实验数据里，成了组里最受欢迎的形象模特</p>
<p>  我们做的一些好玩的技术已经开始影响微软的图像管理和搜索产品开发。在计算机研究领域有个矛盾，要想在实际产品中应用，一项技术必需简单实用，要想发表文章，这项技术又必需显得复杂深奥。要想既像Google那样做出实用产品，又像MIT那样在顶级会议发表文章，就要付出更多辛苦。作为一个做基础研究的地方，我们对在顶级会议发表文章的重视程度和MIT没有什么区别。在过去三年中，我们在一流的计算机视觉会议（ICCV注2, CVPR注3, ECCV注4）发表了60多篇论文。至少在数量上已差不多“天下第一铭”。我常讲做研究就像比武论剑一样,要论剑就要到华山论剑,如果你一定要去太行山论剑, 去挺进大别山，那别人只能当你是游击队, 永远也别想成正规军。在计算机视觉领域，农村是永远也包围不了城市的。华山以外，很难论出好剑。</p>
<p> 发这些论文的另外一个好处是吸引了很多好学生，这些年我见过很多非常优秀的学生，有些已不能用优秀来形容，只能说是天才。晓刚注5是我见到的第一个天才学生，在硕士阶段就发表了五篇CVPR/ICCV。他的才华和人品如此出众，以至于我毫不犹豫地将妹妹嫁给了他。后来我的另一个天才级学生达华注6发表了更多的文章，可是我已经没有妹妹可以再嫁了。好在最近的一个天才级学生靖宇注7，来的时候就有女朋友了。靖宇编程打字的速度是如此之快，以至于我看不清他在键盘上快速移动的手。这三个学生共同特点是都收到MIT 和斯坦福的全额奖学金。晓刚和达华去了MIT, 靖宇选择了斯坦福。我有种感觉，将来他们都会非常成功，成为各自领域的“天下第一铭”。我有种感觉，他们会越来越多。我更有种感觉，铭铭不属于他们。</p>
<p>  铭铭让我自豪的地方也很多。比如铭铭长的很漂亮。这不是我一个人说了算，你可以去问晓晓，桃桃，月月，同同，扬扬，希希……我家院里每个四五岁大的小女孩儿都认为铭铭是她最好的朋友。铭铭四岁前所结交的女朋友（在幼儿园结识的不算）已超过他爸爸四十年艰苦努力的成果（在研究院结识的不算）。</p>
<p>可惜铭铭对学习的态度就像功夫熊猫阿波对面条的感觉，毫无兴趣。铭铭对面条的感觉倒像阿波对功夫的感觉，兴趣盎然。铭铭的人生理想和同龄孩子很不一样，不是做医生，警察，或宇航员，而是“吃饭，睡觉，做佳菲猫”。而且说到做到，铭铭唯一喜欢的课程是厨艺课。厨艺课老师Mariana也觉得铭铭是五岁孩子中厨艺最精湛的了。可惜和同龄孩子一起的时候，极少有比厨艺的时候，反倒是认字，背诗经常被拿出来做表演项目。为了培养铭铭对体育的兴趣，对艺术的热爱，及对中华民族的自豪感，秋梅和我一起带铭铭去看了奥运会开幕式。对于这场人类历史上最精彩最完美最盛大的演出，铭铭印象最深刻的是我在现场餐厅为他买的两根烤香肠。想起来那一定是这世界上代价最高的两根香肠了。</p>
<p> 也许铭铭的血液里真的是流淌着面条汤？希望铭铭长大时，可以选择的已不只华山这一条路，总不能人人都上华山，太挤了，希望有更多的山可以上，有更多的路可以走。总得给铭铭这样不爱学习又厨艺精湛的孩子一条出路吧，但愿那条路不像面条一样弯延曲折。</p>
<p> 秋梅近来常怪我乱讲天下第一铭，给讲坏了。我只好苦笑，怪自己当初求上帝的时候忘了说是正着数还是倒着数了。我就安慰秋梅说“在认字，背诗，音乐，数学，中文，英文，这几个小的方面，铭铭是比别人差一点，好吧，不只一点，差一节，一大节，我们可能也不用太担心，或许铭铭是想后发制人。”</p>
<p>   秋梅温柔地看了我一眼，冷冷地说，“制谁呀！你看后面还有人么？”</p>
<hr>
<p><strong>作者介绍</strong> </p>
<p>汤晓鸥教授，是汤之铭的爸爸。1990年于中国科学技术大学获学士学位，1996年于麻省理工学院(MIT)获博士学位。现于香港中文大学信息工程系任终身教授。2005到2007年，于微软亚洲研究院担任视觉计算组主任。现任IEEE ICCV’09程序委员会主席 (Program Chair)及IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI)编委 (Associate Editor)。他的研究领域包括计算机视觉、模式识别、及视频处理。</p>
<p>晓鸥在亚洲研究院期间，被一致推选为研究院文工团团长，兼团委书记，连续三年出任研究院年度文艺晚会主持人，他的演艺生涯开始于研究院，也是在研究院达到顶峰，为此，他为自己起了个艺名叫“小o”。小o的名言是：“看事物要一分为二，任何事物都有两个方面，有可笑的一面，同时也有更可笑的一面”。他就是这样看着铭铭一天天长大。</p>
<hr>
<p>注1，SIGCHI: Special Interest Group for Computer Human Interaction，是世界上人机交互领域最大的专业组织，这是一个多学科交叉的学术组织，包括计算机科学家、软件工程师、心理学家、交互设计人员、图形设计人员、社会学家和人类学家等等。大家共同理念是”设计有用且可用的技术是一个多学科交叉的过程，这一过程的恰当实施可以改变人们的生活”。<br>注2，ICCV: International Conference on Computer Vision，由IEEE主办的国际计算机视觉大会。作为世界顶级的学术会议，首届国际计算机视觉大会于1987年在伦敦揭幕，其后两年举办一届。2005年第10届ICCV在北京举行。<br>注3，CVPR: Computer Vision and Pattern Recognition, 由IEEE主办的国际计算机视觉与模式识别大会，它是计算机视觉领域最顶级的三大学术会议之一。<br>注4，ECCV: European Conference on Computer Vision，两年举办一次，是计算机视觉领域三大顶级学术会议之一。<br>注5，王晓刚：中国科大本科毕业，少年班第一名，郭沫若奖学金获得者，于香港中文大学取得硕士学位，现于麻省理工学院攻读博士学位。<br>注6，林达华：中国科大本科毕业，于香港中文大学取得硕士学位，获香港中文大学工程院优秀硕士论文奖（每年度全院只选一人），现于麻省理工学院攻读博士学位。<br>注7，崔靖宇：清华大学本科及硕士毕业，随汤晓鸥在研究院做了一年半的实习生，获微软学者奖学金，现于斯坦福大学攻读博士学位。</p>
<p>转载自：<a href="http://blog.sina.com.cn/s/blog_4caedc7a0100bgu9.html" target="_blank" rel="external">http://blog.sina.com.cn/s/blog_4caedc7a0100bgu9.html</a></p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Researcher/">Researcher</a></li></ul>
	</div>

      
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/Researcher/">Researcher</a>
	</div>


      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-安装lpsolve库 for MATLAB" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/11/03/安装lpsolve库 for MATLAB/" class="article-date">
  	<time datetime="2016-11-03T02:29:57.000Z" itemprop="datePublished">2016-11-03</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/11/03/安装lpsolve库 for MATLAB/">安装lpsolve库 for MATLAB</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>lpsolve是sourceforge下的一个开源项目，它的介绍如下： </p>
<p><em>Mixed Integer Linear Programming (MILP) solver lp_solve solves pure linear, (mixed) integer/binary, semi-cont and special ordered sets (SOS) models.lp_solve is written in ANSI C and can be compiled on many different platforms like Linux and WINDOWS </em>.</p>
<p>lpsolve是一个混合整数线性规划求解器，可以求解纯线性、（混合）整数/二值、半连续和特殊有序集模型。并且经过实际验证，有极高的求解效率。 </p>
<p><a href="http://sourceforge.net/projects/lpsolve/?source=directory" target="_blank" rel="external">sourceforge主页</a></p>
<p>1.在Windows x64和Matlab环境下使用lpsolve</p>
<p>需要在网址<a href="https://sourceforge.net/projects/lpsolve/files/lpsolve/5.5.2.5/" target="_blank" rel="external">lpsolve_5.5.2.5</a> 提供的文件列表中下载文件lp_solve_5.5.2.5_MATLAB_exe_win64.zip。或者下载文件lp_solve_5.5.2.5_source.tar.gz自行编译dll。</p>
<p>注：在Matlab下运行示例报错：</p>
<pre><code>Error <span class="keyword">using</span> mxlpsolve
Failed <span class="keyword">to</span> initialise lpsolve <span class="keyword">library</span>.
</code></pre><p>参考Using lpsolve from MATLAB: <a href="http://web.mit.edu/lpsolve/doc/MATLAB.htm" target="_blank" rel="external">http://web.mit.edu/lpsolve/doc/MATLAB.htm</a>给出的说明，需要将编译得到的mxlpsolve.dll拷贝到 WINDOWS\system32文件夹下。</p>
<p>2.在MacOS下使用lpsolve</p>
<p>参考<a href="https://diegoresearch.wordpress.com/2008/07/10/using-lp_solve-in-java-with-mac-os-x/" target="_blank" rel="external">Using lp_solve in Java with Mac OS X</a>的配置说明，下载源文件lp_solve_5.5.2.5_source.tar.gz，然后跳转到lp_solve_5.5/lpsolve55文件夹内，并执行ccc.osx：</p>
<pre><code><span class="keyword">cd</span> lp_solve_5.5/lpsolve55
<span class="keyword">sh</span> ccc.osx
</code></pre><p>生成的文件所在的文件夹：lpsolve55/bin/osx64/，将此文件夹内生成的两个文件liblpsolve55.dylib，liblpsolve55.a拷贝到/usr/local/lib文件夹内即可：</p>
<pre><code>sudo cp liblpsolve55<span class="class">.a</span> liblpsolve55<span class="class">.dylib</span> /usr/local/lib
</code></pre><p>测试demo：</p>
<pre><code><span class="keyword">cd</span> lp_solve_5.5/demo
<span class="keyword">sh</span> ccc
./demo
</code></pre><p>3.在MacOS的Matlab中需要文件mxlpsolve.mexmaci64</p>
<p>需要从lpsolve主页下载源文件lp_solve_5.5.2.5_MATLAB_source.tar.gz，解压缩后，在Matlab中执行文件Makefile.m，期间需要添加各种头文件：</p>
<pre><code>lp_Hash<span class="class">.h</span>
lp_lib<span class="class">.h</span>
lp_matrix<span class="class">.h</span>
lp_mipbb<span class="class">.h</span>
lp_SOS<span class="class">.h</span>
lp_types<span class="class">.h</span>
lp_utils.h
</code></pre><p>可下载lp_solve_5.5.2.5_dev_ux64.tar.gz并从中获取即可。</p>
<p>4.举例</p>
<p>mxlpsove.m是建模的核心函数，一个线性规划模型的所有配置和求解都是通过这个函数完成的。lp_maker.m和lp_solve.m是对mxlpsolve.m的高层包装，简化了模型建立和求解的过程。例如用lpsolve求解数学规划问题：</p>
<p>$$ \max 4x_1+2x_2+x_3\\<br>s.t.~ 2x_1+x_2\le 1\\<br>x_1+2x_3\le 2\\<br>x_1+x_2+x_3=1\\<br>0\le x_1\le1\\<br>0\le x_2\le1\\<br>0\le x_3\le2$$</p>
<p>相应的Matlab语句为：</p>
<pre><code>f = [<span class="number">4</span> <span class="number">2</span> <span class="number">1</span>];
A = [<span class="number">2</span> <span class="number">1</span> <span class="number">0</span>; <span class="number">1</span> <span class="number">0</span> <span class="number">2</span>; <span class="number">1</span> <span class="number">1</span> <span class="number">1</span>];
b = [<span class="number">1</span>; <span class="number">2</span>; <span class="number">1</span>];
l = [ <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>];
u = [ <span class="number">1</span> <span class="number">1</span> <span class="number">2</span>];
lp=mxlpsolve<span class="comment">('make_lp', 1, 3)</span>;
mxlpsolve<span class="comment">('set_verbose', lp, 3)</span>;
mxlpsolve<span class="comment">('set_obj_fn', lp, f)</span>;
mxlpsolve<span class="comment">('add_constraint', lp, A(1, :)</span>, <span class="number">1</span>, b<span class="comment">(1)</span>); 
mxlpsolve<span class="comment">('add_constraint', lp, A(2, :)</span>, <span class="number">1</span>, b<span class="comment">(2)</span>); 
mxlpsolve<span class="comment">('add_constraint', lp, A(3, :)</span>, <span class="number">0</span>, b<span class="comment">(3)</span>; 
mxlpsolve<span class="comment">('set_lowbo', lp, l)</span>; 
mxlpsolve<span class="comment">('set_upbo', lp, u)</span>; 
mxlpsolve<span class="comment">('write_lp', lp, 'a.lp')</span>; 
mxlpsolve<span class="comment">('get_mat', lp, 1, 2)</span> 
mxlpsolve<span class="comment">('solve', lp)</span> 
mxlpsolve<span class="comment">('get_objective', lp)</span> 
mxlpsolve<span class="comment">('get_variables', lp)</span> 
mxlpsolve<span class="comment">('get_constraints', lp)</span> 
mxlpsolve<span class="comment">('delete_lp', lp)</span>
</code></pre><p>重要函数说明：</p>
<p><strong>lp_solve</strong></p>
<pre><code>LP_SOLVE  Solves mixed <span class="built_in">integer</span> linear programming problems.

SYNOPSIS: [obj,x,duals] = lp_solve(f,a,b,e,vlb,vub,xint,scalemode,keep)

  solves the MILP problem

          max v = f<span class="comment">'*x</span>
            a*x &lt;&gt; b
              vlb &lt;= x &lt;= vub
              x(int) are <span class="built_in">integer</span>

ARGUMENTS: The first four arguments are required:

        f: n vector <span class="keyword">of</span> coefficients <span class="keyword">for</span> a linear objective <span class="keyword">function</span>.
        a: m <span class="keyword">by</span> n matrix representing linear constraints.
        b: m vector <span class="keyword">of</span> right sides <span class="keyword">for</span> the inequality constraints.
        e: m vector that determines the sense <span class="keyword">of</span> the inequalities:
                  e(i) = -<span class="number">1</span>  ==&gt; Less Than
                  e(i) =  <span class="number">0</span>  ==&gt; <span class="keyword">Equals</span>
                  e(i) =  <span class="number">1</span>  ==&gt; Greater Than
      vlb: n vector <span class="keyword">of</span> lower bounds. <span class="keyword">If</span> empty <span class="keyword">or</span> omitted,
           <span class="keyword">then</span> the lower bounds are <span class="keyword">set</span> <span class="keyword">to</span> zero.
      vub: n vector <span class="keyword">of</span> upper bounds. May be omitted <span class="keyword">or</span> empty.
     xint: vector <span class="keyword">of</span> <span class="built_in">integer</span> variables. May be omitted <span class="keyword">or</span> empty.
scalemode: scale flag. <span class="keyword">Off</span> <span class="keyword">when</span> <span class="number">0</span> <span class="keyword">or</span> omitted.
     keep: Flag <span class="keyword">for</span> keeping the lp problem after it<span class="comment">'s been solved.</span>
           <span class="keyword">If</span> omitted, the lp will be deleted <span class="keyword">when</span> solved.

   OUTPUT: A nonempty output <span class="keyword">is</span> returned <span class="keyword">if</span> a solution <span class="keyword">is</span> found:

      obj: Optimal value <span class="keyword">of</span> the objective <span class="keyword">function</span>.
        x: Optimal value <span class="keyword">of</span> the decision variables.
    duals: solution <span class="keyword">of</span> the dual problem.

    Example <span class="keyword">of</span> usage. <span class="keyword">To</span> create <span class="keyword">and</span> solve following lp-model:

max: -x1 + <span class="number">2</span> x2;
C1: <span class="number">2</span>x1 + x2 &lt; <span class="number">5</span>;
-<span class="number">4</span> x1 + <span class="number">4</span> x2 &lt;<span class="number">5</span>;

int x2,x1;
The following command can be used:

&gt;&gt; [obj, x]=lp_solve([-<span class="number">1</span>, <span class="number">2</span>], [<span class="number">2</span>, <span class="number">1</span>; -<span class="number">4</span>, <span class="number">4</span>], [<span class="number">5</span>, <span class="number">5</span>], [-<span class="number">1</span>, -<span class="number">1</span>], [], [], [<span class="number">1</span>, <span class="number">2</span>])

obj =

         <span class="number">3</span>

x =

        <span class="number">1</span>
         <span class="number">2</span>
</code></pre><p><strong>lp_maker</strong>　　
　　</p>
<pre><code>LP_MAKER  Makes mixed <span class="built_in">integer</span> linear programming problems.
SYNOPSIS: lp_handle = lp_maker(f,a,b,e,vlb,vub,xint,scalemode,setminim)
      make the MILP problem
        max v = f<span class="comment">'*x</span>
          a*x &lt;&gt; b
            vlb &lt;= x &lt;= vub
            x(int) are <span class="built_in">integer</span>

   ARGUMENTS: The first four arguments are required:
            f: n vector <span class="keyword">of</span> coefficients <span class="keyword">for</span> a linear objective <span class="keyword">function</span>.
            a: m <span class="keyword">by</span> n matrix representing linear constraints.
            b: m vector <span class="keyword">of</span> right sides <span class="keyword">for</span> the inequality constraints.
            e: m vector that determines the sense <span class="keyword">of</span> the inequalities:
                      e(i) &lt; <span class="number">0</span>  ==&gt; Less Than
                      e(i) = <span class="number">0</span>  ==&gt; <span class="keyword">Equals</span>
                      e(i) &gt; <span class="number">0</span>  ==&gt; Greater Than
          vlb: n vector <span class="keyword">of</span> non-negative lower bounds. <span class="keyword">If</span> empty <span class="keyword">or</span> omitted,
               <span class="keyword">then</span> the lower bounds are <span class="keyword">set</span> <span class="keyword">to</span> zero.
          vub: n vector <span class="keyword">of</span> upper bounds. May be omitted <span class="keyword">or</span> empty.
         xint: vector <span class="keyword">of</span> <span class="built_in">integer</span> variables. May be omitted <span class="keyword">or</span> empty.
    scalemode: Autoscale flag. <span class="keyword">Off</span> <span class="keyword">when</span> <span class="number">0</span> <span class="keyword">or</span> omitted.
     setminim: <span class="keyword">Set</span> maximum lp <span class="keyword">when</span> this flag <span class="keyword">equals</span> <span class="number">0</span> <span class="keyword">or</span> omitted.

   OUTPUT: lp_handle <span class="keyword">is</span> an <span class="built_in">integer</span> handle <span class="keyword">to</span> the lp created.
Example <span class="keyword">of</span> usage. <span class="keyword">To</span> create following lp-model:

max: -x1 + <span class="number">2</span> x2;
C1: <span class="number">2</span>x1 + x2 &lt; <span class="number">5</span>;
-<span class="number">4</span> x1 + <span class="number">4</span> x2 &lt;<span class="number">5</span>;

int x2,x1;
The following command can be used:

&gt;&gt; lp=lp_maker([-<span class="number">1</span>, <span class="number">2</span>], [<span class="number">2</span>, <span class="number">1</span>; -<span class="number">4</span>, <span class="number">4</span>], [<span class="number">5</span>, <span class="number">5</span>], [-<span class="number">1</span>, -<span class="number">1</span>], [], [], [<span class="number">1</span>, <span class="number">2</span>])

lp =

     <span class="number">0</span>
<span class="keyword">To</span> solve the model <span class="keyword">and</span> <span class="keyword">get</span> the solution:

&gt;&gt; mxlpsolve(<span class="comment">'solve', lp)</span>

ans =

     <span class="number">0</span>

&gt;&gt; mxlpsolve(<span class="comment">'get_objective', lp)</span>

ans =

     <span class="number">3</span>

&gt;&gt; mxlpsolve(<span class="comment">'get_variables', lp)</span>

ans =

     <span class="number">1</span>
     <span class="number">2</span>
</code></pre><p>注意：Don’t forget to free the handle and its associated memory when you are done:</p>
<pre><code><span class="prompt">&gt;&gt;</span> mxlpsolve(<span class="string">'delete_lp'</span>, lp);
</code></pre><p>5.参考</p>
<p><a href="https://diegoresearch.wordpress.com/2008/07/10/using-lp_solve-in-java-with-mac-os-x/" target="_blank" rel="external">https://diegoresearch.wordpress.com/2008/07/10/using-lp_solve-in-java-with-mac-os-x/</a></p>
<p><a href="http://web.mit.edu/lpsolve/doc/MATLAB.htm" target="_blank" rel="external">http://web.mit.edu/lpsolve/doc/MATLAB.htm</a></p>
<p><a href="http://www.cnblogs.com/kane1990/p/3428129.html" target="_blank" rel="external">http://www.cnblogs.com/kane1990/p/3428129.html</a></p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Matlab/">Matlab</a></li></ul>
	</div>

      
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/Research/">Research</a>
	</div>


      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-Clarifai API体验" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/11/02/Clarifai API体验/" class="article-date">
  	<time datetime="2016-11-02T07:37:27.000Z" itemprop="datePublished">2016-11-02</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/11/02/Clarifai API体验/">Clarifai API体验</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>参考官方给出的文档：<a href="https://developer.clarifai.com/guide/tag#guide-tag-responses" target="_blank" rel="external">https://developer.clarifai.com/guide/tag#guide-tag-responses</a>，在本机进行简单的体验。</p>
<p>首先注册账户，然后创建Application，获取ID及Secret，并在Application页面下生成“Access Token”码：XXx2QXEzmXXfj1eXkXXXUFLYXXX7DX</p>
<p>〇、客户端API参考：<a href="https://github.com/Clarifai/clarifai-python" target="_blank" rel="external">https://github.com/Clarifai/clarifai-python</a></p>
<pre><code>pip install clarifai==<span class="number">2.0</span>.10
clarifai config
<span class="label">CLARIFAI_APP_ID:</span>
<span class="label">CLARIFAI_APP_SECRET:</span>
</code></pre><p>在python中实现测试：</p>
<pre><code><span class="keyword">from</span> clarifai.rest <span class="keyword">import</span> ClarifaiApp
app = ClarifaiApp()
model = app.models.get(<span class="string">'general-v1.3'</span>)
<span class="built_in">print</span> model.predict_by_url(<span class="string">'https://samples.clarifai.com/metro-north.jpg'</span>)
<span class="comment"># or local image</span>
<span class="built_in">print</span> model.predict_by_filename(<span class="string">'/Users/USER/my_image.jpeg'</span>)
</code></pre><p>一、打开MAC终端，输入Request命令：</p>
<ol>
<li><p>测试在线图片</p>
<pre><code>curl "https://api.clarifai.com/v1/tag/" \
      -<span class="ruby"><span class="constant">X</span> <span class="constant">POST</span> --data-urlencode <span class="string">"url=https://samples.clarifai.com/metro-north.jpg"</span> \
</span>      -<span class="ruby"><span class="constant">H</span> <span class="string">"Authorization: Bearer XXx2QXEzmXXfj1eXkXXXUFLYXXX7DX"</span></span>
</code></pre></li>
<li><p>测试本地图片</p>
<pre><code>curl "https://api.clarifai.com/v1/tag/" \
      -<span class="ruby"><span class="constant">X</span> <span class="constant">POST</span> -<span class="constant">F</span> <span class="string">"encoded_data=@/Users/USER/my_image.jpeg"</span> \
</span>      -<span class="ruby"><span class="constant">H</span> <span class="string">"Authorization: Bearer XXx2QXEzmXXfj1eXkXXXUFLYXXX7DX"</span></span>
</code></pre></li>
<li><p>测试多幅图像</p>
<pre><code>curl "https://api.clarifai.com/v1/tag/" \
      -<span class="ruby"><span class="constant">X</span> <span class="constant">POST</span> -<span class="constant">F</span> <span class="string">"encoded_data=@/Users/USER/my_image1.jpeg"</span> \
</span>      -<span class="ruby"><span class="constant">F</span> <span class="string">"encoded_data=@/Users/USER/my_image2.jpeg"</span> \
</span>      -<span class="ruby"><span class="constant">F</span> <span class="string">"encoded_data=@/Users/USER/my_image3.jpeg"</span> \
</span>      -<span class="ruby"><span class="constant">F</span> <span class="string">"encoded_data=@/Users/USER/my_image4.jpeg"</span> \
</span>      -<span class="ruby"><span class="constant">H</span> <span class="string">"Authorization: Bearer XXx2QXEzmXXfj1eXkXXXUFLYXXX7DX"</span></span>
</code></pre></li>
</ol>
<p>二、读取Response结果</p>
<p>在python中使用json来解析文本结果：</p>
<pre><code># -*- coding: utf-<span class="number">8</span> -*-
<span class="keyword">import</span> json
<span class="keyword">for</span> <span class="built_in">line</span> in <span class="built_in">open</span>(<span class="string">"response.txt"</span>):
    <span class="built_in">print</span> <span class="built_in">line</span>
<span class="built_in">str</span>=json.loads(<span class="built_in">line</span>)
results=<span class="built_in">str</span>[<span class="string">'results'</span>]
strNum=len(<span class="built_in">str</span>[<span class="string">'results'</span>])
<span class="keyword">for</span> ind in range(<span class="number">0</span>,strNum):
    <span class="built_in">print</span> ind
    <span class="built_in">print</span> results[ind][<span class="string">'result'</span>][<span class="string">'tag'</span>][<span class="string">'classes'</span>]
</code></pre><p>输出解析结果（图像的tag类别）：</p>
<pre><code><span class="number">0</span>
[<span class="string">u'sketch'</span>, <span class="string">u'illustration'</span>, <span class="string">u'cute'</span>, <span class="string">u'man'</span>, <span class="string">u'no person'</span>, <span class="string">u'funny'</span>, <span class="string">u'fun'</span>, <span class="string">u'vector'</span>, <span class="string">u'character'</span>, <span class="string">u'graphic design'</span>, <span class="string">u'business'</span>, <span class="string">u'child'</span>, <span class="string">u'art'</span>, <span class="string">u'retro'</span>, <span class="string">u'love'</span>, <span class="string">u'moon'</span>, <span class="string">u'Halloween'</span>, <span class="string">u'graphic'</span>, <span class="string">u'design'</span>, <span class="string">u'isolated'</span>]
<span class="number">1</span>
[<span class="string">u'illustration'</span>, <span class="string">u'vector'</span>, <span class="string">u'sketch'</span>, <span class="string">u'retro'</span>, <span class="string">u'design'</span>, <span class="string">u'sketch'</span>, <span class="string">u'business'</span>, <span class="string">u'symbol'</span>, <span class="string">u'man'</span>, <span class="string">u'family'</span>, <span class="string">u'no person'</span>, <span class="string">u'graphic'</span>, <span class="string">u'humor'</span>, <span class="string">u'people'</span>, <span class="string">u'outdoors'</span>, <span class="string">u'image'</span>, <span class="string">u'art'</span>, <span class="string">u'nature'</span>, <span class="string">u'house'</span>, <span class="string">u'animal'</span>]
<span class="number">2</span>
[<span class="string">u'vector'</span>, <span class="string">u'vector'</span>, <span class="string">u'illustration'</span>, <span class="string">u'no person'</span>, <span class="string">u'internet'</span>, <span class="string">u'technology'</span>, <span class="string">u'design'</span>, <span class="string">u'symbol'</span>, <span class="string">u'graphic design'</span>, <span class="string">u'data'</span>, <span class="string">u'flat'</span>, <span class="string">u'data'</span>, <span class="string">u'business'</span>, <span class="string">u'stripe'</span>, <span class="string">u'set'</span>, <span class="string">u'design'</span>, <span class="string">u'square'</span>, <span class="string">u'science'</span>, <span class="string">u'education'</span>, <span class="string">u'creativity'</span>]
<span class="number">3</span>
[<span class="string">u'sleeve'</span>, <span class="string">u'illustration'</span>, <span class="string">u'isolated'</span>, <span class="string">u'polo'</span>, <span class="string">u'shirt'</span>, <span class="string">u'vector'</span>, <span class="string">u'design'</span>, <span class="string">u'image'</span>, <span class="string">u'wear'</span>, <span class="string">u'garment'</span>, <span class="string">u'sale'</span>, <span class="string">u'man'</span>, <span class="string">u'fashion'</span>, <span class="string">u'shopping'</span>, <span class="string">u'casual'</span>, <span class="string">u'front'</span>, <span class="string">u'shop'</span>, <span class="string">u'apparel'</span>, <span class="string">u'graphic'</span>, <span class="string">u'flat'</span>]
<span class="number">4</span>
[<span class="string">u'illustration'</span>, <span class="string">u'vector'</span>, <span class="string">u'sketch'</span>, <span class="string">u'Halloween'</span>, <span class="string">u'cute'</span>, <span class="string">u'animal'</span>, <span class="string">u'skittish'</span>, <span class="string">u'funny'</span>, <span class="string">u'design'</span>, <span class="string">u'art'</span>, <span class="string">u'graphic'</span>, <span class="string">u'fun'</span>, <span class="string">u'ghost'</span>, <span class="string">u'scary'</span>, <span class="string">u'no person'</span>, <span class="string">u'vicious'</span>, <span class="string">u'desktop'</span>, <span class="string">u'retro'</span>, <span class="string">u'image'</span>, <span class="string">u'business'</span>]
</code></pre>
      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/DeepLearning/">DeepLearning</a></li></ul>
	</div>

      
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/Research/">Research</a>
	</div>


      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
  
    <nav id="page-nav">
      <a class="extend prev" rel="prev" href="/">&laquo; Prev</a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><a class="page-number" href="/page/5/">5</a><a class="extend next" rel="next" href="/page/3/">Next &raquo;</a>
    </nav>
  
</div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
    	<div class="footer-left">
    		&copy; 2017 Gang Wang
    	</div>
      	<div class="footer-right">
      		<a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/litten/hexo-theme-yilia" target="_blank">Yilia</a> by Litten
      	</div>
    </div>
  </div>
</footer>
    </div>
    
  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">


<script>
	var yiliaConfig = {
		fancybox: true,
		mathjax: true,
		animate: true,
		isHome: true,
		isPost: false,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: false
	}
</script>
<script src="http://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js"></script>
<script src="/js/main.js"></script>






<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


  </div>
</body>
</html>