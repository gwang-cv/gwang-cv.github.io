<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <meta http-equiv="X-UA-Compatible" content="IE=edge" >
  <title>Hello World</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Hello World">
<meta property="og:url" content="http://gwang-cv.github.io/index.html">
<meta property="og:site_name" content="Hello World">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Hello World">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link rel="stylesheet" href="/css/style.css">
</head>

<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			
			<img lazy-src="https://sites.google.com/site/2013gwang/logss.jpg" class="js-avatar">
			
		</a>

		<hgroup>
		  <h1 class="header-author"><a href="/">Gang Wang</a></h1>
		</hgroup>

		
		<p class="header-subtitle">a computer vision researchGO</p>
		

		
			<div class="switch-btn">
				<div class="icon">
					<div class="icon-ctn">
						<div class="icon-wrap icon-house" data-idx="0">
							<div class="birdhouse"></div>
							<div class="birdhouse_holes"></div>
						</div>
						<div class="icon-wrap icon-ribbon hide" data-idx="1">
							<div class="ribbon"></div>
						</div>
						
						
						<div class="icon-wrap icon-me hide" data-idx="3">
							<div class="user"></div>
							<div class="shoulder"></div>
						</div>
						
					</div>
					
				</div>
				<div class="tips-box hide">
					<div class="tips-arrow"></div>
					<ul class="tips-inner">
						<li>Menu</li>
						<li>Tags</li>
						
						
						<li>Über</li>
						
					</ul>
				</div>
			</div>
		

		<div class="switch-area">
			<div class="switch-wrap">
				<section class="switch-part switch-part1">
					<nav class="header-menu">
						<ul>
						
							<li><a href="/">Home</a></li>
				        
							<li><a href="/archives">Archives</a></li>
				        
						</ul>
					</nav>
					<nav class="header-nav">
						<div class="social">
							
								<a class="github" target="_blank" href="https://github.com/gwang-cv" title="github">github</a>
					        
								<a class="weibo" target="_blank" href="http://weibo.com/messiwang" title="weibo">weibo</a>
					        
								<a class="google" target="_blank" href="https://sites.google.com/site/2013gwang/" title="google">google</a>
					        
						</div>
					</nav>
				</section>
				
				
				<section class="switch-part switch-part2">
					<div class="widget tagcloud" id="js-tagcloud">
						<a href="/tags/DeepLearning/" style="font-size: 20px;">DeepLearning</a> <a href="/tags/ML/" style="font-size: 10px;">ML</a> <a href="/tags/Mac/" style="font-size: 16.67px;">Mac</a> <a href="/tags/Math/" style="font-size: 10px;">Math</a> <a href="/tags/Matlab/" style="font-size: 10px;">Matlab</a> <a href="/tags/Python/" style="font-size: 13.33px;">Python</a> <a href="/tags/Researcher/" style="font-size: 10px;">Researcher</a> <a href="/tags/python/" style="font-size: 10px;">python</a>
					</div>
				</section>
				
				
				

				
				
				<section class="switch-part switch-part3">
				
					<div id="js-aboutme">Hello, I&#39;m Gang Wang. This is my blog, enjoy it.</div>
				</section>
				
			</div>
		</div>
	</header>				
</div>

    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
  	<div class="overlay">
  		<div class="slider-trigger"></div>
  		<h1 class="header-author js-mobile-header hide">Gang Wang</h1>
  	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
			
				<img lazy-src="https://sites.google.com/site/2013gwang/logss.jpg" class="js-avatar">
			
			</div>
			<hgroup>
			  <h1 class="header-author">Gang Wang</h1>
			</hgroup>
			
			<p class="header-subtitle">a computer vision researchGO</p>
			
			<nav class="header-menu">
				<ul>
				
					<li><a href="/">Home</a></li>
		        
					<li><a href="/archives">Archives</a></li>
		        
		        <div class="clearfix"></div>
				</ul>
			</nav>
			<nav class="header-nav">
				<div class="social">
					
						<a class="github" target="_blank" href="https://github.com/gwang-cv" title="github">github</a>
			        
						<a class="weibo" target="_blank" href="http://weibo.com/messiwang" title="weibo">weibo</a>
			        
						<a class="google" target="_blank" href="https://sites.google.com/site/2013gwang/" title="google">google</a>
			        
				</div>
			</nav>
		</header>				
	</div>
</nav>

      <div class="body-wrap">
  
    <article id="post-TextBoxes文本检测" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2017/08/02/TextBoxes文本检测/" class="article-date">
  	<time datetime="2017-08-02T08:03:20.000Z" itemprop="datePublished">2017-08-02</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/08/02/TextBoxes文本检测/">TextBoxes文本检测</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>安装环境：Ubuntu16.04, Nvidia Titan x, cuda 8.0, cudnn 5.0, protobuf 2.6, python 2.7, OpenCV 3.2</p>
<p>下载TextBoxes：<a href="https://github.com/MhLiao/TextBoxes" target="_blank" rel="external">https://github.com/MhLiao/TextBoxes</a></p>
<pre><code># 修改Makefile.config文件：use cuda，use opencv, mkl

git clone http<span class="variable">s:</span>//github.<span class="keyword">com</span>/MhLiao/TextBoxes.git

<span class="keyword">cd</span> TextBoxes

<span class="keyword">make</span> -j64

<span class="keyword">make</span> <span class="keyword">py</span>
</code></pre><p>测试demo</p>
<p>下载训练好的模型<a href="http://pan.baidu.com/s/1qY73XHq" target="_blank" rel="external">Models trained on ICDAR 2013</a>，拷贝到文件夹examples/TextBoxes/下。</p>
<pre><code><span class="comment"># 测试demo.jpg的文本区域检测</span>

<span class="title">python</span> examples/TextBoxes/demo.py
</code></pre><hr>
<p>报错1：<code>No module named shapely</code><br>安装shapely：</p>
<pre><code>sudo apt-<span class="built_in">get</span> install <span class="keyword">python</span>-shapely
</code></pre><p>报错2：<code>Could not find lib geos_c or load any of its variants</code><br>安装shapely的依赖库GEOS：</p>
<pre><code>sudo apt-<span class="built_in">get</span> install libgeos-<span class="built_in">dev</span>
</code></pre>
      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/DeepLearning/">DeepLearning</a></li></ul>
	</div>

      
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/Research/">Research</a>
	</div>


      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-py-R-FCN-MultiGPU安装" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2017/07/29/py-R-FCN-MultiGPU安装/" class="article-date">
  	<time datetime="2017-07-29T09:00:26.000Z" itemprop="datePublished">2017-07-29</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/07/29/py-R-FCN-MultiGPU安装/">py-R-FCN-MultiGPU安装</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>下载R-FCN</strong></p>
<p>master</p>
<pre><code>git clone --recursive http<span class="variable">s:</span>//github.<span class="keyword">com</span>/bharatsingh430/<span class="keyword">py</span>-R-FCN-multiGPU/
</code></pre><p>coco branch</p>
<pre><code>git clone --recursive http<span class="variable">s:</span>//github.<span class="keyword">com</span>/bharatsingh430/<span class="keyword">py</span>-R-FCN-multiGPU/
</code></pre><p><strong>编译Cython模块</strong></p>
<pre><code><span class="keyword">cd</span> <span class="keyword">py</span>-R-FCN-MultiGPU-coco/lib
<span class="keyword">make</span>
</code></pre><p><strong>安装依赖</strong></p>
<pre><code>cython, <span class="keyword">python</span>-opencv, easydict
</code></pre><p><strong>修改Makefile.config</strong></p>
<pre><code><span class="comment"># In your Makefile.config, make sure to have this line uncommented</span>
<span class="constant">WITH_PYTHON_LAYER</span> := 1
<span class="comment"># Unrelatedly, it's also recommended that you use CUDNN</span>
<span class="constant">USE_CUDNN</span> := 1
<span class="constant">USE_NCCL</span> := 1
</code></pre><p><strong>安装NCCL</strong></p>
<pre><code>#Nvidia's NCCL library <span class="keyword">which</span> is used <span class="keyword">for</span> multi-GPU training
#nccl.hpp:5:18: fatal <span class="keyword">error</span>: nccl.<span class="keyword">h</span>: <span class="keyword">No</span> such <span class="keyword">file</span> or directory    # 在多个 GPU 上运行 Caffe 需要使用 NVIDIA NCCL
git clone https:<span class="comment">//github.com/NVIDIA/nccl.git</span>
<span class="keyword">cd</span> nccl
sudo make install -j32
# NCCL 库和文件头将安装在 /usr/<span class="keyword">local</span>/lib 和 /usr/<span class="keyword">local</span>/<span class="keyword">include</span> 中
sudo  ldconfig 
# 该命令不执行会出现错误： <span class="keyword">error</span> <span class="keyword">while</span> loading shared libraries: libnccl.<span class="keyword">so</span>.1: cannot <span class="keyword">open</span> shared object <span class="keyword">file</span>: <span class="keyword">No</span> such <span class="keyword">file</span> or directory 
</code></pre><p><strong>Build Caffe and pycaffe</strong></p>
<pre><code><span class="keyword">cd</span> <span class="keyword">py</span>-R-FCN-MultiGPU-coco/caffe
<span class="keyword">make</span> -j8 &amp;&amp; <span class="keyword">make</span> pycaffe
</code></pre><hr>
<p>若编译过程报错：fatal error: caffe/proto/caffe.pb.h: No such file or directory<br><a href="https://github.com/NVIDIA/DIGITS/issues/105" target="_blank" rel="external">https://github.com/NVIDIA/DIGITS/issues/105</a></p>
<p>可通过如下方式将编译通过（首先需要进入 caffe 根目录）：</p>
<pre><code>protoc src/caffe/<span class="keyword">proto</span>/caffe.<span class="keyword">proto</span> --cpp_out=.
sudo mkdir include/caffe/<span class="keyword">proto</span>
sudo mv src/caffe/<span class="keyword">proto</span>/caffe.pb.h include/caffe/<span class="keyword">proto</span>
</code></pre><hr>
<p>尝试</p>
<p>下载训练好的模型<a href="https://1drv.ms/u/s!AoN7vygOjLIQqUWHpY67oaC7mopf" target="_blank" rel="external">https://1drv.ms/u/s!AoN7vygOjLIQqUWHpY67oaC7mopf</a></p>
<p>解压并拷贝到目录：</p>
<pre><code><span class="title">py</span>-<span class="type">R</span>-<span class="type">FCN</span>-<span class="type">MultiGPU</span>-coco/<span class="typedef"><span class="keyword">data</span>/rfcn_models/resnet50_rfcn_final.caffemodel</span>
<span class="title">py</span>-<span class="type">R</span>-<span class="type">FCN</span>-<span class="type">MultiGPU</span>-coco/<span class="typedef"><span class="keyword">data</span>/rfcn_models/resnet101_rfcn_final.caffemodel</span>
</code></pre><p>运行demo</p>
<pre><code>.<span class="regexp">/tools/</span>demo_rfcn.py
</code></pre><hr>
<p>demo报错：</p>
<pre><code><span class="comment">[libprotobuf ERROR google/protobuf/message_lite.cc:123]</span> 
Can't parse message <span class="keyword">of</span> type <span class="string">"caffe.NetParameter"</span> 
because it <span class="keyword">is</span> missing required fields: 
layer<span class="comment">[494]</span>.psroi_pooling_param.output_dim, 
layer<span class="comment">[494]</span>.psroi_pooling_param.group_size
</code></pre><p>可能的解决方法：    </p>
<pre><code>zhanghaoinf commented <span class="function_start"><span class="keyword">on</span></span> Apr <span class="number">12</span> • edited
Hi, @liu09114 , I checked <span class="keyword">before</span> when I used <span class="keyword">the</span> detection model published
 <span class="keyword">by</span> msra (models store <span class="keyword">in</span> onedrive), <span class="keyword">the</span> problem will occur. If you 
 initialize <span class="keyword">and</span> train your own model <span class="keyword">with</span> resnet-<span class="number">101</span> (classification model 
 pre-trained <span class="function_start"><span class="keyword">on</span></span> ImageNet-<span class="number">1000</span>), <span class="keyword">the</span> problem will disappear. By <span class="keyword">the</span> way, you 
 need <span class="keyword">the</span> coco branch <span class="keyword">to</span> train your own model.

I think <span class="keyword">the</span> sentence <span class="string">"If you want to use/train this model, 
please use the coco branch of this repository. "</span> <span class="keyword">in</span> <span class="keyword">the</span> readme <span class="keyword">is</span> important. :)    
</code></pre><hr>
<h2 id="训练自己的模型">训练自己的模型</h2><p>1.数据集</p>
<p>数据集拷贝到$RFCN_ROOT/data下，此处只有VOC2007的数据：</p>
<pre><code>VOCdevkit2007  <span class="comment">#link</span>
VOCdevkit0712  <span class="comment">#link                     </span>
VOCdevkit<span class="regexp">/VOC2007/</span>                  
VOCdevkit<span class="regexp">/VOC0712/</span>   <span class="comment">#作者是用VOC2007和VOC2012训练的，所以文件夹名字带0712                </span>
</code></pre><p>2.准备预训练模型</p>
<p>deep-residual-networks: <a href="https://github.com/KaimingHe/deep-residual-networks" target="_blank" rel="external">https://github.com/KaimingHe/deep-residual-networks</a></p>
<p>OneDrive download: <a href="https://onedrive.live.com/?authkey=%21AAFW2-FVoxeVRck&amp;id=4006CBB8476FF777%2117887&amp;cid=4006CBB8476FF777" target="_blank" rel="external">https://onedrive.live.com/?authkey=%21AAFW2-FVoxeVRck&amp;id=4006CBB8476FF777%2117887&amp;cid=4006CBB8476FF777</a></p>
<p>然后将caffemodel放在<code>./data/imagenet_models</code>文件夹下。</p>
<p>3.修改网络</p>
<p>打开<code>./models/pascal_voc/ResNet-50/rfcn_end2end</code>  (以end2end为例)</p>
<p>PS：下面的cls_num指的是你数据集的类别数+1（背景）。比如我有15类，+1类背景，cls_num=16.</p>
<p><1>修改class-aware/train_ohem.prototxt</1></p>
<pre><code>layer {  
  name: <span class="symbol">'input</span>-data'  
  <span class="keyword">type</span>: <span class="symbol">'Python'</span>  
  top: <span class="symbol">'data'</span>  
  top: <span class="symbol">'im_info'</span>  
  top: <span class="symbol">'gt_boxes'</span>  
  python_param {  
    <span class="keyword">module</span>: <span class="symbol">'roi_data_layer</span>.layer'  
    layer: <span class="symbol">'RoIDataLayer'</span>  
    param_str: <span class="string">"'num_classes': 16"</span> #cls_num  
  }  
}  
</code></pre><p>+</p>
<pre><code>layer {  
  name: <span class="symbol">'roi</span>-data'  
  <span class="keyword">type</span>: <span class="symbol">'Python'</span>  
  bottom: <span class="symbol">'rpn_rois'</span>  
  bottom: <span class="symbol">'gt_boxes'</span>  
  top: <span class="symbol">'rois'</span>  
  top: <span class="symbol">'labels'</span>  
  top: <span class="symbol">'bbox_targets'</span>  
  top: <span class="symbol">'bbox_inside_weights'</span>  
  top: <span class="symbol">'bbox_outside_weights'</span>  
  python_param {  
    <span class="keyword">module</span>: <span class="symbol">'rpn</span>.proposal_target_layer'  
    layer: <span class="symbol">'ProposalTargetLayer'</span>  
    param_str: <span class="string">"'num_classes': 16"</span> #cls_num  
  }  
}  
</code></pre><p>+</p>
<pre><code>layer {  
    bottom: <span class="string">"conv_new_1"</span>  
    top: <span class="string">"rfcn_cls"</span>  
    name: <span class="string">"rfcn_cls"</span>  
    <span class="class"><span class="keyword">type</span>:</span> <span class="string">"Convolution"</span>  
    convolution_param {  
        num_output: <span class="number">784</span> #cls_num*(score_maps_size^<span class="number">2</span>)  
        kernel_size: <span class="number">1</span>  
        pad: <span class="number">0</span>  
        weight_filler {  
            <span class="class"><span class="keyword">type</span>:</span> <span class="string">"gaussian"</span>  
            std: <span class="number">0.01</span>  
        }  
        bias_filler {  
            <span class="class"><span class="keyword">type</span>:</span> <span class="string">"constant"</span>  
            value: <span class="number">0</span>  
        }  
    }  
    param {  
        lr_mult: <span class="number">1.0</span>  
    }  
    param {  
        lr_mult: <span class="number">2.0</span>  
    }  
}  
</code></pre><p>+</p>
<pre><code>layer {  
    bottom: <span class="string">"conv_new_1"</span>  
    top: <span class="string">"rfcn_bbox"</span>  
    name: <span class="string">"rfcn_bbox"</span>  
    <span class="class"><span class="keyword">type</span>:</span> <span class="string">"Convolution"</span>  
    convolution_param {  
        num_output: <span class="number">3136</span> #<span class="number">4</span>*cls_num*(score_maps_size^<span class="number">2</span>)  
        kernel_size: <span class="number">1</span>  
        pad: <span class="number">0</span>  
        weight_filler {  
            <span class="class"><span class="keyword">type</span>:</span> <span class="string">"gaussian"</span>  
            std: <span class="number">0.01</span>  
        }  
        bias_filler {  
            <span class="class"><span class="keyword">type</span>:</span> <span class="string">"constant"</span>  
            value: <span class="number">0</span>  
        }  
    }  
    param {  
        lr_mult: <span class="number">1.0</span>  
    }  
    param {  
        lr_mult: <span class="number">2.0</span>  
    }  
}  
</code></pre><p>+</p>
<pre><code>layer {  
    bottom: <span class="string">"rfcn_cls"</span>  
    bottom: <span class="string">"rois"</span>  
    top: <span class="string">"psroipooled_cls_rois"</span>  
    <span class="property">name</span>: <span class="string">"psroipooled_cls_rois"</span>  
    type: <span class="string">"PSROIPooling"</span>  
    psroi_pooling_param {  
        spatial_scale: <span class="number">0.0625</span>  
        output_dim: <span class="number">16</span>  <span class="comment">#cls_num  </span>
        group_size: <span class="number">7</span>  
    }  
}  
</code></pre><p>+</p>
<pre><code>layer {  
    bottom: <span class="string">"rfcn_bbox"</span>  
    bottom: <span class="string">"rois"</span>  
    top: <span class="string">"psroipooled_loc_rois"</span>  
    <span class="property">name</span>: <span class="string">"psroipooled_loc_rois"</span>  
    type: <span class="string">"PSROIPooling"</span>  
    psroi_pooling_param {  
        spatial_scale: <span class="number">0.0625</span>  
        output_dim: <span class="number">64</span> <span class="comment">#4*cls_num  </span>
        group_size: <span class="number">7</span>  
    }  
}  
</code></pre><p><2>修改class-aware/test.prototxt</2></p>
<pre><code>layer {  
    bottom: <span class="string">"conv_new_1"</span>  
    top: <span class="string">"rfcn_cls"</span>  
    name: <span class="string">"rfcn_cls"</span>  
    <span class="class"><span class="keyword">type</span>:</span> <span class="string">"Convolution"</span>  
    convolution_param {  
        num_output: <span class="number">784</span> #cls_num*(score_maps_size^<span class="number">2</span>)  
        kernel_size: <span class="number">1</span>  
        pad: <span class="number">0</span>  
        weight_filler {  
            <span class="class"><span class="keyword">type</span>:</span> <span class="string">"gaussian"</span>  
            std: <span class="number">0.01</span>  
        }  
        bias_filler {  
            <span class="class"><span class="keyword">type</span>:</span> <span class="string">"constant"</span>  
            value: <span class="number">0</span>  
        }  
    }  
    param {  
        lr_mult: <span class="number">1.0</span>  
    }  
    param {  
        lr_mult: <span class="number">2.0</span>  
    }  
}  
</code></pre><p>+</p>
<pre><code>layer {  
    bottom: <span class="string">"conv_new_1"</span>  
    top: <span class="string">"rfcn_bbox"</span>  
    name: <span class="string">"rfcn_bbox"</span>  
    <span class="class"><span class="keyword">type</span>:</span> <span class="string">"Convolution"</span>  
    convolution_param {  
        num_output: <span class="number">3136</span> #<span class="number">4</span>*cls_num*(score_maps_size^<span class="number">2</span>)  
        kernel_size: <span class="number">1</span>  
        pad: <span class="number">0</span>  
        weight_filler {  
            <span class="class"><span class="keyword">type</span>:</span> <span class="string">"gaussian"</span>  
            std: <span class="number">0.01</span>  
        }  
        bias_filler {  
            <span class="class"><span class="keyword">type</span>:</span> <span class="string">"constant"</span>  
            value: <span class="number">0</span>  
        }  
    }  
    param {  
        lr_mult: <span class="number">1.0</span>  
    }  
    param {  
        lr_mult: <span class="number">2.0</span>  
    }  
}  
</code></pre><p>+</p>
<pre><code>layer {  
    bottom: <span class="string">"rfcn_cls"</span>  
    bottom: <span class="string">"rois"</span>  
    top: <span class="string">"psroipooled_cls_rois"</span>  
    <span class="property">name</span>: <span class="string">"psroipooled_cls_rois"</span>  
    type: <span class="string">"PSROIPooling"</span>  
    psroi_pooling_param {  
        spatial_scale: <span class="number">0.0625</span>  
        output_dim: <span class="number">16</span>  <span class="comment">#cls_num  </span>
        group_size: <span class="number">7</span>  
    }  
}  
</code></pre><p>+</p>
<pre><code>layer {  
    bottom: <span class="string">"rfcn_bbox"</span>  
    bottom: <span class="string">"rois"</span>  
    top: <span class="string">"psroipooled_loc_rois"</span>  
    <span class="property">name</span>: <span class="string">"psroipooled_loc_rois"</span>  
    type: <span class="string">"PSROIPooling"</span>  
    psroi_pooling_param {  
        spatial_scale: <span class="number">0.0625</span>  
        output_dim: <span class="number">64</span>  <span class="comment">#4*cls_num  </span>
        group_size: <span class="number">7</span>  
    }  
}  
</code></pre><p>+</p>
<pre><code>layer {  
    <span class="property">name</span>: <span class="string">"cls_prob_reshape"</span>  
    type: <span class="string">"Reshape"</span>  
    bottom: <span class="string">"cls_prob_pre"</span>  
    top: <span class="string">"cls_prob"</span>  
    reshape_param {  
        shape {  
            dim: -<span class="number">1</span>  
            dim: <span class="number">16</span>  <span class="comment">#cls_num  </span>
        }  
    }  
}  
</code></pre><p>+</p>
<pre><code>layer {  
    <span class="property">name</span>: <span class="string">"bbox_pred_reshape"</span>  
    type: <span class="string">"Reshape"</span>  
    bottom: <span class="string">"bbox_pred_pre"</span>  
    top: <span class="string">"bbox_pred"</span>  
    reshape_param {  
        shape {  
            dim: -<span class="number">1</span>  
            dim: <span class="number">64</span>  <span class="comment">#4*cls_num  </span>
        }  
    }  
}  
</code></pre><p><3>修改train_agnostic.prototxt</3></p>
<pre><code>layer {  
  name: <span class="symbol">'input</span>-data'  
  <span class="keyword">type</span>: <span class="symbol">'Python'</span>  
  top: <span class="symbol">'data'</span>  
  top: <span class="symbol">'im_info'</span>  
  top: <span class="symbol">'gt_boxes'</span>  
  python_param {  
    <span class="keyword">module</span>: <span class="symbol">'roi_data_layer</span>.layer'  
    layer: <span class="symbol">'RoIDataLayer'</span>  
    param_str: <span class="string">"'num_classes': 16"</span>  #cls_num  
  }  
}  
</code></pre><p>+</p>
<pre><code>layer {  
    bottom: <span class="string">"conv_new_1"</span>  
    top: <span class="string">"rfcn_cls"</span>  
    name: <span class="string">"rfcn_cls"</span>  
    <span class="class"><span class="keyword">type</span>:</span> <span class="string">"Convolution"</span>  
    convolution_param {  
        num_output: <span class="number">784</span> #cls_num*(score_maps_size^<span class="number">2</span>)   ###  
        kernel_size: <span class="number">1</span>  
        pad: <span class="number">0</span>  
        weight_filler {  
            <span class="class"><span class="keyword">type</span>:</span> <span class="string">"gaussian"</span>  
            std: <span class="number">0.01</span>  
        }  
        bias_filler {  
            <span class="class"><span class="keyword">type</span>:</span> <span class="string">"constant"</span>  
            value: <span class="number">0</span>  
        }  
    }  
    param {  
        lr_mult: <span class="number">1.0</span>  
    }  
    param {  
        lr_mult: <span class="number">2.0</span>  
    }  
}  
</code></pre><p>+</p>
<pre><code>layer {  
    bottom: <span class="string">"rfcn_cls"</span>  
    bottom: <span class="string">"rois"</span>  
    top: <span class="string">"psroipooled_cls_rois"</span>  
    <span class="property">name</span>: <span class="string">"psroipooled_cls_rois"</span>  
    type: <span class="string">"PSROIPooling"</span>  
    psroi_pooling_param {  
        spatial_scale: <span class="number">0.0625</span>  
        output_dim: <span class="number">16</span> <span class="comment">#cls_num   ###  </span>
        group_size: <span class="number">7</span>  
    }  
}  
</code></pre><p><4>修改train_agnostic_ohem.prototxt</4></p>
<pre><code>layer {  
  name: <span class="symbol">'input</span>-data'  
  <span class="keyword">type</span>: <span class="symbol">'Python'</span>  
  top: <span class="symbol">'data'</span>  
  top: <span class="symbol">'im_info'</span>  
  top: <span class="symbol">'gt_boxes'</span>  
  python_param {  
    <span class="keyword">module</span>: <span class="symbol">'roi_data_layer</span>.layer'  
    layer: <span class="symbol">'RoIDataLayer'</span>  
    param_str: <span class="string">"'num_classes': 16"</span> #cls_num ###  
  }  
}  
</code></pre><p>+</p>
<pre><code>layer {  
    bottom: <span class="string">"conv_new_1"</span>  
    top: <span class="string">"rfcn_cls"</span>  
    name: <span class="string">"rfcn_cls"</span>  
    <span class="class"><span class="keyword">type</span>:</span> <span class="string">"Convolution"</span>  
    convolution_param {  
        num_output: <span class="number">784</span> #cls_num*(score_maps_size^<span class="number">2</span>)   ###  
        kernel_size: <span class="number">1</span>  
        pad: <span class="number">0</span>  
        weight_filler {  
            <span class="class"><span class="keyword">type</span>:</span> <span class="string">"gaussian"</span>  
            std: <span class="number">0.01</span>  
        }  
        bias_filler {  
            <span class="class"><span class="keyword">type</span>:</span> <span class="string">"constant"</span>  
            value: <span class="number">0</span>  
        }  
    }  
    param {  
        lr_mult: <span class="number">1.0</span>  
    }  
    param {  
        lr_mult: <span class="number">2.0</span>  
    }  
}  
</code></pre><p>+</p>
<pre><code>layer {  
    bottom: <span class="string">"rfcn_cls"</span>  
    bottom: <span class="string">"rois"</span>  
    top: <span class="string">"psroipooled_cls_rois"</span>  
    <span class="property">name</span>: <span class="string">"psroipooled_cls_rois"</span>  
    type: <span class="string">"PSROIPooling"</span>  
    psroi_pooling_param {  
        spatial_scale: <span class="number">0.0625</span>  
        output_dim: <span class="number">16</span> <span class="comment">#cls_num   ###  </span>
        group_size: <span class="number">7</span>  
    }  
}  
</code></pre><p><5>修改test_agnostic.prototxt</5></p>
<pre><code>layer {  
    bottom: <span class="string">"conv_new_1"</span>  
    top: <span class="string">"rfcn_cls"</span>  
    name: <span class="string">"rfcn_cls"</span>  
    <span class="class"><span class="keyword">type</span>:</span> <span class="string">"Convolution"</span>  
    convolution_param {  
        num_output: <span class="number">784</span> #cls_num*(score_maps_size^<span class="number">2</span>) ###  
        kernel_size: <span class="number">1</span>  
        pad: <span class="number">0</span>  
        weight_filler {  
            <span class="class"><span class="keyword">type</span>:</span> <span class="string">"gaussian"</span>  
            std: <span class="number">0.01</span>  
        }  
        bias_filler {  
            <span class="class"><span class="keyword">type</span>:</span> <span class="string">"constant"</span>  
            value: <span class="number">0</span>  
        }  
    }  
    param {  
        lr_mult: <span class="number">1.0</span>  
    }  
    param {  
        lr_mult: <span class="number">2.0</span>  
    }  
}  
</code></pre><p>+</p>
<pre><code>layer {  
    bottom: <span class="string">"rfcn_cls"</span>  
    bottom: <span class="string">"rois"</span>  
    top: <span class="string">"psroipooled_cls_rois"</span>  
    <span class="property">name</span>: <span class="string">"psroipooled_cls_rois"</span>  
    type: <span class="string">"PSROIPooling"</span>  
    psroi_pooling_param {  
        spatial_scale: <span class="number">0.0625</span>  
        output_dim: <span class="number">16</span> <span class="comment">#cls_num   ###  </span>
        group_size: <span class="number">7</span>  
    }  
}  
</code></pre><p>+</p>
<pre><code>layer {  
    <span class="property">name</span>: <span class="string">"cls_prob_reshape"</span>  
    type: <span class="string">"Reshape"</span>  
    bottom: <span class="string">"cls_prob_pre"</span>  
    top: <span class="string">"cls_prob"</span>  
    reshape_param {  
        shape {  
            dim: -<span class="number">1</span>  
            dim: <span class="number">16</span> <span class="comment">#cls_num   ###  </span>
        }  
    }  
}  
</code></pre><p>4.修改代码</p>
<p><1>修改./lib/datasets/pascal_voc.py</1></p>
<pre><code><span class="class"><span class="keyword">class</span> <span class="title">pascal_voc</span>(<span class="title">imdb</span>):  </span>
    <span class="function"><span class="keyword">def</span> </span>__init_<span class="number">_</span>(<span class="keyword">self</span>, image_set, year, devkit_path=<span class="constant">None</span>)<span class="symbol">:</span>  
        imdb.__init_<span class="number">_</span>(<span class="keyword">self</span>, <span class="string">'voc_'</span> + year + <span class="string">'_'</span> + image_set)  
        <span class="keyword">self</span>._year = year  
        <span class="keyword">self</span>._image_set = image_set  
        <span class="keyword">self</span>._devkit_path = <span class="keyword">self</span>._get_default_path() <span class="keyword">if</span> devkit_path is <span class="constant">None</span> \  
                            <span class="keyword">else</span> devkit_path  
        <span class="keyword">self</span>._data_path = os.path.join(<span class="keyword">self</span>._devkit_path, <span class="string">'VOC'</span> + <span class="keyword">self</span>._year)  
        <span class="keyword">self</span>._classes = (<span class="string">'__background__'</span>, <span class="comment"># always index 0  </span>
                         <span class="string">'你的标签1'</span>,<span class="string">'你的标签2'</span>,你的标签<span class="number">3</span><span class="string">','</span>你的标签<span class="number">4</span><span class="string">'  
                      )  </span>
</code></pre><p><2>修改./lib/datasets/imdb.py</2></p>
<p>在语句<code>assert (boxes[:, 2] &gt;= boxes[:, 0]).all()</code>前面添加：</p>
<pre><code><span class="keyword">for</span> <span class="tag">b</span> <span class="keyword">in</span> <span class="function"><span class="title">range</span><span class="params">(len(boxes)</span></span>):
    <span class="keyword">if</span> boxes[b][<span class="number">2</span>]&lt; boxes[b][<span class="number">0</span>]:
        boxes[b][<span class="number">0</span>] = <span class="number">0</span>
</code></pre><p>以避免出现AssertionError.</p>
<p><3>修改./lib/fast_rcnn/train.py和train_multi_gpu.py </3></p>
<p>在开头添加：<code>import google.protobuf.text_format</code>，以避免因protobuf版本问题出现的<code>AttributeError: &#39;module&#39; object has no attribute &#39;text_format&#39;</code>.</p>
<p>5.开始训练</p>
<p>Multi-GPU Training R-FCN</p>
<pre><code>cd py-R-FCN-multiGPU-coco

python ./tools/train_net_multi_gpu<span class="class">.py</span> --gpu <span class="number">0</span>,<span class="number">1</span> ...
--solver models/pascal_voc/ResNet-<span class="number">50</span>/rfcn_end2end/solver_ohem<span class="class">.prototxt</span> ...
--weights data/imagenet_models/ResNet-<span class="number">50</span>-model<span class="class">.caffemodel</span> ...
--iters <span class="number">110000</span> --cfg experiments/cfgs/rfcn_end2end_ohem.yml
</code></pre>
      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/DeepLearning/">DeepLearning</a></li></ul>
	</div>

      
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/Research/">Research</a>
	</div>


      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-Faster-RCNN+Ubuntu16.04+Titan XP+CUDA8.0+cudnn5.0" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2017/07/26/Faster-RCNN+Ubuntu16.04+Titan XP+CUDA8.0+cudnn5.0/" class="article-date">
  	<time datetime="2017-07-26T03:36:45.000Z" itemprop="datePublished">2017-07-26</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/07/26/Faster-RCNN+Ubuntu16.04+Titan XP+CUDA8.0+cudnn5.0/">Faster-RCNN+Ubuntu16.04+Titan XP+CUDA8.0+cudnn5.0</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>1.安装Ubuntu16.04 LTS x64</strong></p>
<p>利用工具rufus制作USB系统盘(官方下载64位版本: <a href="http://www.ubuntu.com/download/alternative-downloads" target="_blank" rel="external">ubuntu-16.04-desktop-amd64.iso</a>).</p>
<p>语言选择English，安装开始：1.不选安装第三方软件；2.安装类型选择“其他选项（something else）”；3.设置分区，多硬盘挂载，如挂载到/data，/data2…；开始执行安装直到提示重新启动。</p>
<p><strong>2.更新源</strong></p>
<pre><code>cd /etc/apt/
sudo cp sources<span class="class">.list</span> sources<span class="class">.list</span><span class="class">.bak</span>
sudo gedit sources.list
</code></pre><p>在sources.list文件头部添加如下源：</p>
<pre><code>deb <span class="string">http:</span><span class="comment">//mirrors.ustc.edu.cn/ubuntu/ xenial main restricted universe multiverse</span>
deb <span class="string">http:</span><span class="comment">//mirrors.ustc.edu.cn/ubuntu/ xenial-security main restricted universe multiverse</span>
deb <span class="string">http:</span><span class="comment">//mirrors.ustc.edu.cn/ubuntu/ xenial-updates main restricted universe multiverse</span>
deb <span class="string">http:</span><span class="comment">//mirrors.ustc.edu.cn/ubuntu/ xenial-proposed main restricted universe multiverse</span>
deb <span class="string">http:</span><span class="comment">//mirrors.ustc.edu.cn/ubuntu/ xenial-backports main restricted universe multiverse</span>
deb-src <span class="string">http:</span><span class="comment">//mirrors.ustc.edu.cn/ubuntu/ xenial main restricted universe multiverse</span>
deb-src <span class="string">http:</span><span class="comment">//mirrors.ustc.edu.cn/ubuntu/ xenial-security main restricted universe multiverse</span>
deb-src <span class="string">http:</span><span class="comment">//mirrors.ustc.edu.cn/ubuntu/ xenial-updates main restricted universe multiverse</span>
deb-src <span class="string">http:</span><span class="comment">//mirrors.ustc.edu.cn/ubuntu/ xenial-proposed main restricted universe multiverse</span>
deb-src <span class="string">http:</span><span class="comment">//mirrors.ustc.edu.cn/ubuntu/ xenial-backports main restricted universe multiverse</span>
</code></pre><p>然后更新源和安装的包:</p>
<pre><code>sudo apt-<span class="built_in">get</span> <span class="keyword">update</span>
sudo apt-<span class="built_in">get</span> upgrade
</code></pre><p>常用软件安装：</p>
<pre><code>sudo apt-<span class="keyword">get</span> install vim <span class="comment">#编辑</span>
sudo apt-<span class="keyword">get</span> install htop <span class="comment">#查看cpu和内存占用情况</span>
sudo apt-<span class="keyword">get</span> install python-pip
</code></pre><p><strong>3.配置静态IP</strong></p>
<p>首先查看本机的网卡名称</p>
<pre><code>ifconfig
</code></pre><p>配置静态ip地址</p>
<pre><code><span class="title">sudo</span> vim /etc/network/interfaces

<span class="comment">#在打开的interfaces文件中添加如下信息：</span>
auto eth0 <span class="comment">#eth0对应你的网卡名称，在ifconfig中查看</span>
iface eth0 inet static
address <span class="number">192.168.1.100</span>
netmask <span class="number">255.255.255.0</span>
gateway <span class="number">192.168.1.1</span>
dns-nameserver <span class="number">114.114.114.114</span>
</code></pre><p>配置DNS</p>
<pre><code><span class="title">sudo</span> vim /etc/resolv.conf

<span class="comment">#添加如下信息：</span>
nameserver <span class="number">114.114.114.114</span>

sudo vim /etc/resolvconf/resolv.conf.d/base

<span class="comment">#添加如下信息：</span>
nameserver <span class="number">114.114.114.114</span>
</code></pre><p>重启网卡服务</p>
<pre><code><span class="title">sudo</span> /etc/init.d/networking restart
<span class="comment">#重启检验是否设置成功</span>
sudo reboot
</code></pre><p><strong>4.配置SSH和SFTP</strong></p>
<p>SSH安装命令：</p>
<pre><code>sudo apt-get <span class="operator"><span class="keyword">install</span> openssh-<span class="keyword">server</span></span>
</code></pre><p>ssh-server配置文件位于<code>/etc/ssh/sshd_config</code>，在这里可以定义SSH的服务端口，默认端口是22。</p>
<pre><code><span class="comment">#若更改端口后请重启SSH服务：</span>
<span class="title">sudo</span> /etc/init.d/ssh resart
</code></pre><p>Ubuntu或Mac客户端可在命令行中执行如下语句来使用ssh：</p>
<pre><code><span class="title">ssh</span> username@<span class="number">192.168.1.100</span> 
</code></pre><p>sftp安装：</p>
<pre><code>sudo apt-get <span class="operator"><span class="keyword">install</span> openssh-sftp-<span class="keyword">server</span></span>
</code></pre><p>Ubuntu客户端可在文件管理器中选择“connect to server”，然后输入：</p>
<pre><code><span class="string">sftp:</span><span class="comment">//192.168.1.100</span>
</code></pre><p>即可查看到username所在的home文件夹下的内容。</p>
<p><strong>5.安装NVIDIA显卡驱动</strong></p>
<p>此处由于NVIDIA驱动和Ubuntu桌面冲突的问题（如循环卡在登录界面）。这里我们的VGA显示器默认接在主板的集显上，而不是接在NVIDIA显卡上，所以我们不采用ppa的显卡安装方式，而是采用独立的显卡驱动安装方式，关键之处在于不勾选OpenGL即可。</p>
<p>首先到NVIDIA官网下载官方驱动：<a href="http://www.nvidia.cn/Download/index.aspx?lang=cn" target="_blank" rel="external">http://www.nvidia.cn/Download/index.aspx?lang=cn</a>，其中Titan XP属于GeForce 10 series系列。下载驱动：NVIDIA-Linux-x86_64-375.66.run</p>
<p><strong>安装前准备：</strong></p>
<p>卸载原有nvidia驱动，若采用的是<code>apt-get</code>安装方式</p>
<pre><code>sudo apt-<span class="keyword">get</span> purge nvidia* 
</code></pre><p>或者采用<code>--uninstall</code>的方式卸载，按提示操作</p>
<pre><code>sudo sh NVIDIA-Linux-x86_64-<span class="number">375.66</span>.<span class="command">run</span> <span class="comment">--uninstall</span>
</code></pre><p>禁用nouveau</p>
<pre><code>sudo vim /etc/modprobe.<span class="keyword">d</span>/blacklist.<span class="keyword">conf</span>
</code></pre><p>在打开的文件的最后加入nouveau黑名单，禁用第三方驱动</p>
<pre><code><span class="keyword">blacklist </span>nouveau 
</code></pre><p>然后执行</p>
<pre><code>sudo <span class="keyword">update</span>-initramfs -<span class="keyword">u</span>
</code></pre><p>再执行如下语句，没有输出即说明已屏蔽成功</p>
<pre><code>lsmod <span class="string">| grep nouveau </span>
</code></pre><p><strong>开始安装驱动</strong></p>
<p>首先关闭X服务：</p>
<pre><code>sudo <span class="keyword">service</span> lightdm <span class="literal">stop</span>
</code></pre><p>若在本机则要进入<code>Ctrl-Alt+F1</code>命令行界面</p>
<p>若在远程主机则在ssh中执行即可，前提是要关闭x服务。</p>
<p>开始：</p>
<pre><code>sudo apt-get <span class="operator"><span class="keyword">install</span> build-essential pkg-config xserver-xorg-dev linux-headers-<span class="string">`uname -r`</span>

sudo chmod a+x NVIDIA-Linux-x86_64-<span class="number">375.66</span>.run
sudo sh NVIDIA-Linux-x86_64-<span class="number">375.66</span>.run -<span class="keyword">no</span>-opengl-files
sudo apt-<span class="keyword">get</span> <span class="keyword">install</span> mesa-common-dev
sudo apt-<span class="keyword">get</span> <span class="keyword">install</span> freeglut3-dev
sudo reboot</span>
</code></pre><p>其中参数(后面两个参数不加):</p>
<pre><code>–<span class="literal">no</span>-opengl-files <span class="comment">#只安装驱动文件，不安装OpenGL文件。这个参数最重要</span>
–<span class="literal">no</span>-x-check <span class="comment">#安装驱动时不检查X服务</span>
–<span class="literal">no</span>-nouveau-check <span class="comment">#安装驱动时不检查nouveau </span>
</code></pre><p>若安装过程中报关于kernel-source的错误:</p>
<pre><code><span class="constant">E</span>RROR: <span class="constant">Unable</span> to find the <span class="built_in">kernel</span> <span class="literal">source</span> tree for the currently <span class="literal">running</span> <span class="built_in">kernel</span>.  <span class="constant">Please</span> make sure you have installed the <span class="built_in">kernel</span> <span class="literal">source</span> files for your <span class="built_in">kernel</span> <span class="keyword">and</span> that they are properly configured; on <span class="constant">Red</span> <span class="constant">Hat</span> <span class="constant">Linux</span> systems, for example, be sure you have the <span class="string">'kernel-source'</span> <span class="keyword">or</span> <span class="string">'kernel-devel'</span> <span class="constant">R</span>PM installed.  <span class="constant">If</span> you know the correct <span class="built_in">kernel</span> <span class="literal">source</span> files are installed, you may specify the <span class="built_in">kernel</span> <span class="literal">source</span> <span class="built_in">path</span> with the <span class="string">'--kernel-source-path'</span> <span class="literal">command</span> line option.
</code></pre><p>请务必执行如下语句：</p>
<pre><code>sudo apt-get <span class="operator"><span class="keyword">install</span> linux-headers-<span class="string">`uname -r`</span></span>
</code></pre><p>若出现警告说：</p>
<pre><code>/sbin/ldconfig<span class="class">.real</span>: /usr/lib32/nvidia-<span class="number">375</span>/libEGL<span class="class">.so</span>.<span class="number">1</span> is not <span class="tag">a</span> symbolic link
</code></pre><p>可能是由于libEGL.lib存在多个版本的冲突，解决方法：</p>
<pre><code>sudo mv /usr/lib/nvidia-<span class="number">375</span>/libEGL<span class="class">.so</span>.<span class="number">1</span> /usr/lib/nvidia-<span class="number">375</span>/libEGL<span class="class">.so</span>.<span class="number">1</span><span class="class">.org</span>
sudo mv /usr/lib32/nvidia-<span class="number">375</span>/libEGL<span class="class">.so</span>.<span class="number">1</span> /usr/lib32/nvidia-<span class="number">375</span>/libEGL<span class="class">.so</span>.<span class="number">1</span><span class="class">.org</span>
sudo ln -s /usr/lib/nvidia-<span class="number">375</span>/libEGL<span class="class">.so</span>.<span class="number">375.66</span> /usr/lib/nvidia-<span class="number">375</span>/libEGL<span class="class">.so</span>.<span class="number">1</span>
sudo ln -s /usr/lib32/nvidia-<span class="number">375</span>/libEGL<span class="class">.so</span>.<span class="number">375.66</span> /usr/lib32/nvidia-<span class="number">375</span>/libEGL<span class="class">.so</span>.<span class="number">1</span>
</code></pre><p>重启后若还是循环卡在登录界面，则要卸载到驱动，重新安装，在安装过程中务必安装驱动提示的x-config的选项安装，即一路yes即可。</p>
<p>如果出现无法进入桌面的问题，这是因为驱动修改了xorg的配置，可执行一下命令：</p>
<pre><code>cd /usr/share/X11/xorg<span class="class">.conf</span><span class="class">.d</span>/ 
sudo mv nvidia-drm-outputclass<span class="class">.conf</span> nvidia-drm-outputclass<span class="class">.conf</span><span class="class">.bak</span>
</code></pre><p>若进入到界面后发现分辨率问题：启动到界面之后发现分辨率只有600x480，而显示器适合1920x1080，采用xrandr并修改xorg.conf来解决：</p>
<pre><code>sudo gedit /etc/X11/xorg<span class="class">.conf</span>
修改如下：
HorizSync <span class="number">31.0</span> - <span class="number">84.0</span>
VertRefresh <span class="number">56.0</span>-<span class="number">77.0</span>
</code></pre><p>即最终的xorg.conf文件部分内容为：</p>
<pre><code><span class="title">Section "Device"    </span>
    Identifier <span class="string">"Configured Video Device"</span>
EndSection

<span class="title">Section "Monitor"</span>
    Identifier <span class="string">"Configured Monitor"</span>
    Horizsync 30-84
    Vertrefresh 56-77
EndSection

<span class="title">Section "Screen"</span>
Identifier <span class="string">"Default Screen"</span>
Monitor <span class="string">"Configured Monitor"</span>
Device <span class="string">"Configured Video Device"</span>
    SubSection <span class="string">"Display"</span>
        Modes <span class="string">"1920x1080"</span> <span class="string">"1360x768"</span> <span class="string">"1024x768"</span> <span class="string">"1152x864"</span>
    EndSubSection
EndSection        
</code></pre><p><strong>6.安装CUDA8.0</strong></p>
<p>到官网下载<a href="https://developer.nvidia.com/cuda-release-candidate-download" target="_blank" rel="external">cuda_8.0.61_linux.run</a>，复制到根目录下。</p>
<pre><code>sudo sh cuda_8.0.61_linux.<span class="command">run</span> <span class="comment">--tmpdir=/tmp/</span>
</code></pre><p>遇到问题：incomplete installation，然后执行</p>
<pre><code>sudo apt-<span class="built_in">get</span> install libx11-<span class="built_in">dev</span> libxmu-<span class="built_in">dev</span> libxi-<span class="built_in">dev</span> libgl1-mesa-glx libglu1-mesa libglu1-mesa-<span class="built_in">dev</span>

sudo sh cuda_8.0.61_linux.run -silent -driver
</code></pre><p>注：此时安装过程中提示是否要安装NVIDIA驱动时选择no。其他选择yes或默认即可。</p>
<pre><code>Install NVIDIA Accelerated Graphics Driver <span class="keyword">for</span> Linux-x86_64 <span class="number">375.26</span>? <span class="params">(y)</span>es/<span class="params">(n)</span>o/<span class="params">(q)</span>uit: n
</code></pre><p>安装完毕后声明环境变量：</p>
<pre><code><span class="title">sudo</span> vim ~/.bashrc
</code></pre><p>在.bashrc尾部添加如下内容：</p>
<pre><code>export <span class="constant">PATH</span>=<span class="regexp">/usr/local</span><span class="regexp">/cuda-8.0/bin</span><span class="variable">${</span><span class="constant">PATH</span><span class="symbol">:+</span><span class="symbol">:</span><span class="variable">${</span><span class="constant">PATH</span>}}
export <span class="constant">LD_LIBRARY_PATH</span>=<span class="regexp">/usr/local</span><span class="regexp">/cuda-8.0/lib</span>64<span class="variable">${</span><span class="constant">LD_LIBRARY_PATH</span><span class="symbol">:+</span><span class="symbol">:</span><span class="variable">${</span><span class="constant">LD_LIBRARY_PATH</span>}}
</code></pre><p>测试下安装是否成功：</p>
<p>测试：</p>
<pre><code>nvidia-<span class="keyword">smi</span>
</code></pre><p>输出：</p>
<pre><code>xx xx xx 15:20:34 2017       
+-----------------------------------------------------------------------------+
|<span class="string"> NVIDIA-SMI 375.66                 Driver Version: 375.66                    </span>|
|<span class="string">-------------------------------+----------------------+----------------------+
</span>|<span class="string"> GPU  Name        Persistence-M</span>|<span class="string"> Bus-Id        Disp.A </span>|<span class="string"> Volatile Uncorr. ECC </span>|
|<span class="string"> Fan  Temp  Perf  Pwr:Usage/Cap</span>|<span class="string">         Memory-Usage </span>|<span class="string"> GPU-Util  Compute M. </span>|
|<span class="string">===============================+======================+======================</span>|
|<span class="string">   0  GeForce GTX TIT...  Off  </span>|<span class="string"> 0000:01:00.0      On </span>|<span class="string">                  N/A </span>|
|<span class="string"> 22%   48C    P5    27W / 250W </span>|<span class="string">    169MiB / 12205MiB </span>|<span class="string">      1%      Default </span>|
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
|<span class="string"> Processes:                                                       GPU Memory </span>|
|<span class="string">  GPU       PID  Type  Process name                               Usage      </span>|
|<span class="string">=============================================================================</span>|
|<span class="string">    0      2421    G   /usr/lib/xorg/Xorg                             105MiB </span>|
|<span class="string">    0     10062    G   compiz                                          63MiB </span>|
+-----------------------------------------------------------------------------+
</code></pre><p><strong>7.安装OpenCV 3.2.0</strong></p>
<p>从官网下载zip源代码，解压到根目录下。<br>安装依赖：</p>
<pre><code>sudo apt-<span class="built_in">get</span> -y remove ffmpeg x264 libx264-<span class="built_in">dev</span>
sudo apt-<span class="built_in">get</span> -y install libopencv-<span class="built_in">dev</span> build-essential checkinstall cmake pkg-config yasm  libjpeg-<span class="built_in">dev</span> libjasper-<span class="built_in">dev</span> libavcodec-<span class="built_in">dev</span> libavformat-<span class="built_in">dev</span> libswscale-<span class="built_in">dev</span> libdc1394-<span class="number">22</span>-<span class="built_in">dev</span>  libgstreamer0.10-<span class="built_in">dev</span> libgstreamer-plugins-base0.10-<span class="built_in">dev</span> libv4l-<span class="built_in">dev</span> python-<span class="built_in">dev</span> python-numpy libtbb-<span class="built_in">dev</span> libqt4-<span class="built_in">dev</span> libgtk2.0-<span class="built_in">dev</span> libfaac-<span class="built_in">dev</span> libmp3lame-<span class="built_in">dev</span> libopencore-amrnb-<span class="built_in">dev</span> libopencore-amrwb-<span class="built_in">dev</span> libtheora-<span class="built_in">dev</span> libvorbis-<span class="built_in">dev</span> libxvidcore-<span class="built_in">dev</span> x264 v4l-utils ffmpeg libgtk2.0-<span class="built_in">dev</span>

cd opencv-<span class="number">3.2</span>.0
mkdir build   
cd build/
cmake -D CMAKE_BUILD_TYPE=RELEASE -D CMAKE_INSTALL_PREFIX=/usr/local -D WITH_TBB=ON -D BUILD_NEW_PYTHON_SUPPORT=ON -D WITH_V4L=ON -D INSTALL_C_EXAMPLES=ON -D INSTALL_PYTHON_EXAMPLES=ON -D BUILD_EXAMPLES=ON -D WITH_QT=ON -D WITH_OPENGL=ON ..
make -j32
sudo make install
</code></pre><p>安装成功后配置环境：</p>
<pre><code>sudo <span class="keyword">sh</span> -c 'echo <span class="string">"/usr/local/lib"</span> &gt; /etc/ld.<span class="keyword">so</span>.<span class="keyword">conf</span>.<span class="keyword">d</span>/opencv.<span class="keyword">conf</span>'
sudo ldconfig
</code></pre><p>测试OpenCV安装是否成功：</p>
<pre><code><span class="built_in">mkdir</span> DisplayImage  
<span class="keyword">cd</span> DisplayImage 
<span class="keyword">vim</span> DisplayImage.cpp 
</code></pre><p>添加代码：</p>
<pre><code><span class="preprocessor">#<span class="keyword">include</span> &lt;stdio.h&gt;  </span>
<span class="preprocessor">#<span class="keyword">include</span> &lt;opencv2/opencv.hpp&gt;  </span>
<span class="keyword">using</span> <span class="keyword">namespace</span> cv;  

<span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span>** argv)</span>  
</span>{  
     <span class="keyword">if</span>(argc!= <span class="number">2</span>)  
     {  
               <span class="built_in">printf</span>(<span class="string">"usage:DisplayImage.out &lt;Image_Path&gt;\n"</span>);  
               <span class="keyword">return</span> -<span class="number">1</span>;  
     }  

     Mat image;  
     image= imread(argv[<span class="number">1</span>], <span class="number">1</span>);  

    <span class="keyword">if</span>(!image.data)  
    {  
               <span class="built_in">printf</span>(<span class="string">"Noimage data\n"</span>);  
               <span class="keyword">return</span> -<span class="number">1</span>;  
     }  

     namedWindow(<span class="string">"DisplayImage"</span>,CV_WINDOW_AUTOSIZE);  
     imshow(<span class="string">"DisplayImage"</span>,image);  

     waitKey(<span class="number">0</span>);  
     <span class="keyword">return</span> <span class="number">0</span>;  
}  
</code></pre><p>创建CMake文件：</p>
<pre><code>vim CMakeLists<span class="class">.txt</span>  
</code></pre><p>添加内容：</p>
<pre><code><span class="function"><span class="title">cmake_minimum_required</span><span class="params">(VERSION <span class="number">2.8</span>)</span></span>  
<span class="function"><span class="title">project</span><span class="params">(DisplayImage)</span></span>  
<span class="function"><span class="title">find_package</span><span class="params">(OpenCV REQUIRED)</span></span>  
<span class="function"><span class="title">add_executable</span><span class="params">(DisplayImage DisplayImage.cpp)</span></span>  
<span class="function"><span class="title">target_link_libraries</span><span class="params">(DisplayImage ${OpenCV_LIBS})</span></span> 
</code></pre><p>编译：</p>
<pre><code>cmake .  
<span class="built_in">make</span> 
</code></pre><p>执行：</p>
<pre><code>./DisplayImage lena<span class="class">.jpg</span>  
</code></pre><p>如果在make opencv-3.2过程中错误：</p>
<pre><code>fatal <span class="keyword">error</span>: LAPACKE_H_PATH-NOTFOUND/lapacke.<span class="keyword">h</span>: <span class="keyword">No</span> such <span class="keyword">file</span> or directory #<span class="keyword">include</span> <span class="string">"LAPACKE_H_PATH-NOTFOUND/lapacke.h"</span>
</code></pre><p>此时LAPACK和BLAS都已经安装了，解决方案：</p>
<pre><code>sudo apt-get install liblapacke-dev checkinstall
修改在build文件夹内的lapack.h文件，将如下语句
<span class="preprocessor">#<span class="keyword">include</span> "LAPACKE_H_PATH-NOTFOUND/lapacke.h"</span>
改为
<span class="preprocessor">#<span class="keyword">include</span> "lapacke.h"</span>
</code></pre><p><strong>8.安装cudnn 5.0</strong></p>
<p>从官网下载<a href="https://developer.nvidia.com/cudnn" target="_blank" rel="external">cudnn-8.0-linux-x64-v5.0.tgz</a> for CUDA 8.0. 解压到当前目录：</p>
<pre><code><span class="tag">tar</span> <span class="tag">-zxvf</span> <span class="tag">cudnn-8</span><span class="class">.0-linux-x64-v5</span><span class="class">.0</span><span class="class">.tgz</span>
</code></pre><p>解压后的文件如下：</p>
<pre><code>cuda/include/cudnn<span class="class">.h</span>
cuda/lib64/libcudnn<span class="class">.so</span>
cuda/lib64/libcudnn<span class="class">.so</span>.<span class="number">5</span>
cuda/lib64/libcudnn<span class="class">.so</span>.<span class="number">5.0</span>.<span class="number">5</span>
cuda/lib64/libcudnn_static.a
</code></pre><p>然后执行：</p>
<pre><code>sudo cp cuda<span class="regexp">/include/</span>cudnn.h <span class="regexp">/usr/</span>local<span class="regexp">/cuda/</span>include/
sudo cp cuda<span class="regexp">/lib64/</span>libcudnn* <span class="regexp">/usr/</span>local<span class="regexp">/cuda/</span>lib64/
sudo chmod a+r <span class="regexp">/usr/</span>local<span class="regexp">/cuda/</span>include/cudnn.h
sudo chmod a+r <span class="regexp">/usr/</span>local<span class="regexp">/cuda/</span>lib64/libcudnn*
</code></pre><p><strong>9.BLAS安装与配置</strong></p>
<p>BLAS（基础线性代数集合）是一个应用程序接口的标准。caffe官网上推荐了三种实现：ATLAS, MKL, OpenBLAS。其中ATLAS可以直接通过命令行安装。MKL是微软开发的商业工具包，面向科研和学生免费开放。申请学生版的<a href="https://software.intel.com/en-us/qualify-for-free-software/student" target="_blank" rel="external">Parallel Studio XE Cluster Edition</a>，下载parallel_studio_xe_2017.tgz。注意接收邮件中的key(<em>2HWS-34Z7S69B</em>)。</p>
<pre><code>tar zxvf parallel_studio_xe_2017.tgz   <span class="comment">#解压下载文件</span>
chmod <span class="number">777</span> parallel_studio_xe_2017 -R   <span class="comment">#获取文件权限</span>
<span class="built_in">cd</span> parallel_studio_xe_2017/
sudo ./install_GUI.sh
</code></pre><p>安装完成之后，进行相关文件的链接：</p>
<pre><code>sudo gedit /etc/ld.<span class="keyword">so</span>.<span class="keyword">conf</span>.<span class="keyword">d</span>/intel_mkl.<span class="keyword">conf</span>
</code></pre><p>添加库文件:</p>
<pre><code><span class="regexp">/opt/i</span>ntel<span class="regexp">/lib/i</span>ntel64
<span class="regexp">/opt/i</span>ntel<span class="regexp">/mkl/</span>lib<span class="regexp">/intel64</span>
</code></pre><p>编译链接使lib文件生效：</p>
<pre><code><span class="title">sudo</span> ldconfig    
</code></pre><p>如果选择安装ATLAS，在终端输入<code>sudo apt-get install libatlas-base-dev</code>即可。</p>
<p><strong>10.Py-Faster-RCNN配置</strong></p>
<p>下载源码：包含caffe文件夹</p>
<pre><code>git clone --recursive http<span class="variable">s:</span>//github.<span class="keyword">com</span>/rbgirshick/<span class="keyword">py</span>-faster-rcnn.git
</code></pre><p>安装库文件：</p>
<pre><code>sudo apt-<span class="built_in">get</span> install python-opencv
sudo pip install cython easydict

sudo apt-<span class="built_in">get</span> install libprotobuf-<span class="built_in">dev</span> libleveldb-<span class="built_in">dev</span> libsnappy-<span class="built_in">dev</span> libboost-<span class="built_in">all</span>-<span class="built_in">dev</span> libhdf5-serial-<span class="built_in">dev</span> libgflags-<span class="built_in">dev</span> libgoogle-glog-<span class="built_in">dev</span> liblmdb-<span class="built_in">dev</span> protobuf-compiler
</code></pre><p>安装依赖：</p>
<pre><code>sudo apt-<span class="built_in">get</span> install -y build-essential cmake git pkg-config libprotobuf-<span class="built_in">dev</span> libleveldb-<span class="built_in">dev</span> libsnappy-<span class="built_in">dev</span> libopencv-<span class="built_in">dev</span> libhdf5-serial-<span class="built_in">dev</span> protobuf-compiler libatlas-base-<span class="built_in">dev</span> libgflags-<span class="built_in">dev</span> libgoogle-glog-<span class="built_in">dev</span> liblmdb-<span class="built_in">dev</span>
sudo apt-<span class="built_in">get</span> install --no-install-recommends libboost-<span class="built_in">all</span>-<span class="built_in">dev</span>
</code></pre><p>安装Python接口依赖：</p>
<pre><code>sudo apt-<span class="built_in">get</span> install <span class="keyword">python</span>-tk
sudo apt-<span class="built_in">get</span> install <span class="keyword">python</span>-dev
sudo apt-<span class="built_in">get</span> install -<span class="keyword">y</span> <span class="keyword">python</span>-pip
sudo apt-<span class="built_in">get</span> install -<span class="keyword">y</span> <span class="keyword">python</span>-dev
sudo apt-<span class="built_in">get</span> install -<span class="keyword">y</span> <span class="keyword">python</span>-numpy <span class="keyword">python</span>-scipy     sudo apt-<span class="built_in">get</span> install -<span class="keyword">y</span> <span class="keyword">python3</span>-dev
sudo apt-<span class="built_in">get</span> install -<span class="keyword">y</span> <span class="keyword">python3</span>-numpy <span class="keyword">python3</span>-scipy 
</code></pre><p>在caffe的python文件夹内，使用root执行依赖项的检查与安装：</p>
<pre><code>sudo <span class="keyword">su</span>
<span class="keyword">cd</span> caffe-fast-rcnn/python
<span class="keyword">for</span> req <span class="keyword">in</span> $(<span class="keyword">cat</span> requirements.txt); <span class="keyword">do</span> pip install <span class="label">$req</span>; done
</code></pre><p>修改Makefile文件</p>
<pre><code>终端输入
cd py-faster-rcnn<span class="regexp">/caffe-fast-rcnn/</span>
cp Makefile.config.example Makefile.config
vim Makefile.config

使用python层
将 # <span class="string">WITH_PYTHON_LAYER :</span>= <span class="number">1</span>修改为 <span class="string">WITH_PYTHON_LAYER :</span>= <span class="number">1</span>

使用cudnn加速
将 # <span class="string">USE_CUDNN :</span>= <span class="number">1</span>修改为 <span class="string">USE_CUDNN :</span>= <span class="number">1</span>

保留 # <span class="string">CPU_ONLY :</span>= <span class="number">1</span>不变，使用GPU运行

如下两行对应内容修改为：
<span class="string">INCLUDE_DIRS :</span>= $(PYTHON_INCLUDE) <span class="regexp">/usr/</span>local<span class="regexp">/include  /</span>usr<span class="regexp">/include/</span>hdf5/serial
<span class="string">LIBRARY_DIRS :</span>= $(PYTHON_LIB) <span class="regexp">/usr/</span>local<span class="regexp">/lib /</span>usr<span class="regexp">/lib /</span>usr<span class="regexp">/lib/</span>x86_64-linux-gnu <span class="regexp">/usr/</span>lib<span class="regexp">/x86_64-linux-gnu/</span>hdf5<span class="regexp">/serial /</span>usr<span class="regexp">/local/</span>share<span class="regexp">/OpenCV/</span><span class="number">3</span>rdparty<span class="regexp">/lib/</span>
</code></pre><p>在Makefile中配置：</p>
<pre><code>LIBRARIES += glog gflags protobuf boost_system boost_filesystem <span class="keyword">m</span> hdf5_hl hdf5 opencv_core opencv_highgui opencv_imgproc opencv_imgcodecs

hdf5的配置：官方说这对于Ubuntu 16.04是必须的；（libhdf5的版本号需要根据实际来修改）
sudo find . -<span class="keyword">type</span> f -exec sed -i -<span class="keyword">e</span> 's^<span class="string">"hdf5.h"</span>^<span class="string">"hdf5/serial/hdf5.h"</span>^<span class="keyword">g</span>' -<span class="keyword">e</span> 's^<span class="string">"hdf5_hl.h"</span>^<span class="string">"hdf5/serial/hdf5_hl.h"</span>^<span class="keyword">g</span>' '{}' \;
<span class="keyword">cd</span> /usr/lib/x86_64-linux-gnu
sudo ln -s libhdf5_serial.<span class="keyword">so</span>.10.1.0 libhdf5.<span class="keyword">so</span>
sudo ln -s libhdf5_serial_hl.<span class="keyword">so</span>.10.0.2 libhdf5_hl.<span class="keyword">so</span>
</code></pre><p><strong>编译Cython模块</strong></p>
<pre><code><span class="keyword">cd</span> <span class="keyword">py</span>-faster-rcnn/lib/
<span class="keyword">make</span>
</code></pre><p><strong>编译caffe</strong></p>
<p>由于当前版本的caffe中cudnn实现与系统所安装的cudnn的版本不一致会引起错误，rbgirshick的py-faster-rcnn其cudnn实现为旧版本的实现，所有出现了以上问题。</p>
<pre><code><span class="tag">cudnn-7</span><span class="class">.0-linux-x64-v4</span><span class="class">.0-prod</span><span class="class">.tgz</span>不会出现此问题
<span class="tag">cudnn-7</span><span class="class">.5-linux-x64-v5</span><span class="class">.1</span><span class="class">.tgz</span>会出现同样问题
<span class="tag">cudnn-8</span><span class="class">.0-linux-x64-v5</span><span class="class">.1</span><span class="class">.tgz</span>会出现同样问题
</code></pre><p>解决办法：</p>
<pre><code><span class="number">1</span>将py-faster-rcnn<span class="regexp">/caffe-fast-rcnn/</span>include<span class="regexp">/caffe/</span>util/cudnn.hpp 换成最新版caffe里的相应目录下的cudnn.hpp；
<span class="number">2</span>将py-faster-rcnn<span class="regexp">/caffe-fast-rcnn/</span>include<span class="regexp">/caffe/</span>layers/下所有cudnn开头的文件都替换为最新版caffe里相应目录下的同名文件；
<span class="number">3</span>将py-faster-rcnn<span class="regexp">/caffe-fast-rcnn/</span>src<span class="regexp">/caffe/</span>layer下所有cudnn开头的文件都替换为最新版caffe里相应目录下的同名文件；
</code></pre><p>注：官方caffe源包<a href="https://github.com/BVLC/caffe" target="_blank" rel="external">caffe-master：https://github.com/BVLC/caffe</a></p>
<p>编译</p>
<pre><code><span class="keyword">cd</span> <span class="keyword">py</span>-faster-rcnn/caffe-fast-rcnn/
<span class="keyword">make</span> clean #清除前一次编译结果
<span class="keyword">make</span> -j32
</code></pre><p><strong>编译pycaffe</strong></p>
<pre><code><span class="keyword">cd</span> <span class="keyword">py</span>-faster-rcnn/caffe-fast-rcnn/
<span class="keyword">make</span> pycaffe
</code></pre><p><strong>下载训练好的模型</strong></p>
<pre><code>终端输入
<span class="keyword">cd</span> <span class="keyword">py</span>-faster-rcnn/
./data/scripts/fetch_faster_rcnn_models.<span class="keyword">sh</span>
</code></pre><p><strong>faster-rcnn测试pascal_voc目标检测</strong></p>
<pre><code><span class="keyword">cd</span> <span class="keyword">py</span>-faster-rcnn/
./tools/demo.<span class="keyword">py</span>
</code></pre><hr>
<p>常见的报错Debug：</p>
<hr>
<p><em>AttributeError: ‘module’ object has no attribute ‘text_format’</em></p>
<p>需要在py-faster-rcnn/lib/fast_rcnn/train.py中添加：</p>
<pre><code>import google<span class="class">.protobuf</span><span class="class">.text_format</span>
</code></pre><hr>
<p><em>KeyError: ‘chair’ [when train only several classes]</em><br><em>使用py-faster-rcnn训练VOC2007数据集时遇到如下问题：</em></p>
<p>File “/home/sai/py-faster-rcnn/tools/../lib/datasets/pascal_voc.py”, line 217, in _load_pascal_annotation<br>cls = self._class_to_ind[obj.find(‘name’).text.lower().strip()]<br>KeyError: ‘chair‘</p>
<p>解决：</p>
<p>You probably need to write some line of codes to ignore any objects with classes except the classes you are looking for when you are loading the annotation _load_pascal_annotation.<br>Something like</p>
<pre><code>cls_objs = [obj <span class="keyword">for</span> obj, clas <span class="keyword">in</span> objs, self._classes <span class="keyword">if</span> obj.<span class="function"><span class="title">find</span><span class="params">(‘name‘)</span></span>.text== clas]
</code></pre><p>when you are loading the annotation in _load_pascal_annotation method, look for something like</p>
<pre><code>objs = diff_objs <span class="list">(<span class="keyword">or</span> non_diff_objs)</span> <span class="list">(<span class="keyword">after</span> this line in pascal_voc.py)</span>
</code></pre><p>After that line insert something similar to below code</p>
<pre><code>cls_objs = [obj <span class="keyword">for</span> obj <span class="keyword">in</span> objs <span class="keyword">if</span> obj.<span class="function"><span class="title">find</span><span class="params">(<span class="string">'name'</span>)</span></span><span class="class">.text</span> <span class="keyword">in</span> self._classes]
objs = cls_objs
</code></pre><p>参考：<a href="https://github.com/rbgirshick/py-faster-rcnn/issues/316" target="_blank" rel="external">https://github.com/rbgirshick/py-faster-rcnn/issues/316</a></p>
<hr>
<p><em>Annotations files 标记文件问题</em></p>
<p>Note that: <code>&lt;difficult&gt;0&lt;/difficult&gt;</code></p>
<p>must be 0, if not, we will get error:  ZeroDivisionError: integer division or modulo by zero</p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/DeepLearning/">DeepLearning</a></li></ul>
	</div>

      
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/Research/">Research</a>
	</div>


      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-Git配置出错Permission Denied" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2017/07/06/Git配置出错Permission Denied/" class="article-date">
  	<time datetime="2017-07-06T03:20:16.000Z" itemprop="datePublished">2017-07-06</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/07/06/Git配置出错Permission Denied/">Git配置出现Permission denied问题</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>MacOS github后台配置ssh key之后本地无法git clone的问题 </p>
<pre><code><span class="variable">Permission</span> denied (publickey).
</code></pre><p>当你在github后台添加了ssh keys之后，在本地这么测试一下：</p>
<pre><code><span class="title">ssh</span> -T git<span class="variable">@github</span>.com
</code></pre><p>如果返回是：</p>
<pre><code><span class="variable">Permission</span> denied (publickey).
</code></pre><p>那么你可能要在本地ssh-add一下，当然在这之前你可以使用 ssh -vT git@github.com 查看一下到底是因为什么原因导致的失败。</p>
<pre><code><span class="label">ssh</span>-<span class="keyword">add </span>~/.ssh/id_rsa (maybe: ssh-<span class="keyword">add </span>~/id_rsa)
</code></pre><p>然后会返回如下：</p>
<pre><code>Enter passphrase <span class="keyword">for</span> <span class="regexp">/Users/</span>xxx<span class="regexp">/.ssh/</span><span class="string">id_rsa:</span>
Identity <span class="string">added:</span> <span class="regexp">/Users/</span>xxx<span class="regexp">/.ssh/</span>id_rsa (<span class="regexp">/Users/</span>xxx<span class="regexp">/.ssh/</span>youraccount_rsa)
</code></pre><p>之后再使用 </p>
<pre><code><span class="title">ssh</span> -T git<span class="variable">@github</span>.com
</code></pre><p>会返回成功：</p>
<pre><code>Hi youraccount! You've successfully authenticated, <span class="keyword">but</span> GitHub <span class="keyword">does</span> <span class="keyword">not</span> provide shell access.
</code></pre><p>说明你目前本地的ssh已经切换到了id_rsa这个账号，</p>
<p>之后便可以进行git clone到本地的操作了！</p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Mac/">Mac</a></li></ul>
	</div>

      
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/Debug/">Debug</a>
	</div>


      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-Python除法" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2017/07/06/Python除法/" class="article-date">
  	<time datetime="2017-07-06T03:20:16.000Z" itemprop="datePublished">2017-07-06</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/07/06/Python除法/">Python除法</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>python 2.x版本中存在两种除法运算:</p>
<p>即所谓的true除法和floor除法。</p>
<p>当使用x/y形式进行除法运算时，如果x和y都是整形，那么运算的会对结果进行截取，取运算的整数部分，比如2/3的运算结果是0；</p>
<p>如果x和y中有一个是浮点数，那么会进行所谓的true除法，比如2.0/3的结果是 0.66666666666666663。</p>
<p>另外一种除法是采用x//y的形式，那么这里采用的是所谓floor除法，即得到不大于结果的最大整数值，这个运算时与操作数无关的。比如2//3的结果是0，-2//3的结果是-1，-2.0//3的结果是-1.0。</p>
<hr>
<p>在python 3.x中，x/y将只执行true除法，而与操作数无关；x//y则执行floor除法。</p>
<hr>
<p>如果需要在2.x版本的python中进行这样的用法，则需要在代码最前加入from <strong>future</strong> import division的声明。</p>
<p>Python代码 </p>
<pre><code><span class="keyword">from</span> __future__ <span class="keyword">import</span> division  
a=<span class="number">2</span>/<span class="number">3</span>                  
</code></pre><p>这时变量a的结果将是0.66666666666666663，而不是原来的0了。</p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/python/">python</a></li></ul>
	</div>

      
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/Debug/">Debug</a>
	</div>


      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-Ubuntu16.04+Titan X+CUDA8.0+cudnn5" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/12/30/Ubuntu16.04+Titan X+CUDA8.0+cudnn5/" class="article-date">
  	<time datetime="2016-12-30T03:15:04.000Z" itemprop="datePublished">2016-12-30</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/12/30/Ubuntu16.04+Titan X+CUDA8.0+cudnn5/">Ubuntu16.04+Titan X+CUDA8.0+cudnn5.1+Caffe</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>1.安装Ubuntu16.04 LTS x64</strong></p>
<p>利用工具rufus制作USB系统盘(官方下载64位版本: <a href="http://www.ubuntu.com/download/alternative-downloads" target="_blank" rel="external">ubuntu-16.04-desktop-amd64.iso</a>)，因为已有Win7系统，此处选择“Install Ubuntu alongside Windows Boot Manager”，分区采用默认选择，语言选择English，安装完毕。</p>
<p><em>注：此时显示器VGA接口接到主板集成显卡接口上。</em><br><em>PS: or always plug VGA to Nvidia Titan X, and then set “nomodeset” in /etc/default/grub, then install nvidia drivers in tty…</em></p>
<p><strong>2.更新源</strong></p>
<pre><code>cd /etc/apt/
sudo cp sources<span class="class">.list</span> sources<span class="class">.list</span><span class="class">.bak</span>
sudo gedit sources.list
</code></pre><p>在sources.list文件头部添加如下源：</p>
<pre><code>deb <span class="string">http:</span><span class="comment">//mirrors.ustc.edu.cn/ubuntu/ xenial main restricted universe multiverse</span>
deb <span class="string">http:</span><span class="comment">//mirrors.ustc.edu.cn/ubuntu/ xenial-security main restricted universe multiverse</span>
deb <span class="string">http:</span><span class="comment">//mirrors.ustc.edu.cn/ubuntu/ xenial-updates main restricted universe multiverse</span>
deb <span class="string">http:</span><span class="comment">//mirrors.ustc.edu.cn/ubuntu/ xenial-proposed main restricted universe multiverse</span>
deb <span class="string">http:</span><span class="comment">//mirrors.ustc.edu.cn/ubuntu/ xenial-backports main restricted universe multiverse</span>
deb-src <span class="string">http:</span><span class="comment">//mirrors.ustc.edu.cn/ubuntu/ xenial main restricted universe multiverse</span>
deb-src <span class="string">http:</span><span class="comment">//mirrors.ustc.edu.cn/ubuntu/ xenial-security main restricted universe multiverse</span>
deb-src <span class="string">http:</span><span class="comment">//mirrors.ustc.edu.cn/ubuntu/ xenial-updates main restricted universe multiverse</span>
deb-src <span class="string">http:</span><span class="comment">//mirrors.ustc.edu.cn/ubuntu/ xenial-proposed main restricted universe multiverse</span>
deb-src <span class="string">http:</span><span class="comment">//mirrors.ustc.edu.cn/ubuntu/ xenial-backports main restricted universe multiverse</span>
</code></pre><p>然后更新源和安装的包:</p>
<pre><code>sudo apt-<span class="built_in">get</span> <span class="keyword">update</span>
sudo apt-<span class="built_in">get</span> upgrade
</code></pre><p><strong>3.安装NVIDIA显卡驱动</strong></p>
<p>采用ppa安装方式，没选择最新的nvidia-370，我选择了nvidia-367。</p>
<p>Ctrl+Alt+F1进入tty命令控制台，停止lightdm，然后开始安装驱动。</p>
<pre><code>sudo services lightdm stop

sudo<span class="instruction"> add-apt-repository </span>ppa:graphics-drivers/ppa
sudo apt-get update
sudo apt-get install nvidia-367
sudo apt-get install mesa-common-dev
sudo apt-get install freeglut3-dev
sudo reboot
</code></pre><p><em>将显示器VGA接口换到NVIDIA显卡上。</em></p>
<p>PS: If login loop, then Ctrl+Alt+F1, and then uninstall nvidia driver and reinstall again..</p>
<pre><code>sudo apt-get purge nvidia-*
sudo<span class="instruction"> add-apt-repository </span>ppa:graphics-drivers/ppa
sudo apt-get update 
sudo apt-get install nvidia-367
sudo apt-get install mesa-common-dev
sudo apt-get install freeglut3-dev
sudo reboot
</code></pre><p><strong>4.修改分辨率</strong></p>
<p>启动到界面之后发现分辨率只有1366x768，显示器适合1920x1080，采用xrandr并修改xorg.conf来解决。[或者，更容易的是采用一个HDMI的转接头来解决！]</p>
<pre><code>sudo gedit /etc/X11/xorg<span class="class">.conf</span>
修改如下：
HorizSync <span class="number">31.0</span> - <span class="number">84.0</span>
VertRefresh <span class="number">56.0</span>-<span class="number">77.0</span>
</code></pre><p>即最终的xorg.conf文件为：</p>
<pre><code><span class="title">Section "Device"    </span>
    Identifier <span class="string">"Configured Video Device"</span>
EndSection

<span class="title">Section "Monitor"</span>
    Identifier <span class="string">"Configured Monitor"</span>
    Horizsync 30-84
    Vertrefresh 56-77
EndSection

<span class="title">Section "Screen"</span>
Identifier <span class="string">"Default Screen"</span>
Monitor <span class="string">"Configured Monitor"</span>
Device <span class="string">"Configured Video Device"</span>
    SubSection <span class="string">"Display"</span>
        Modes <span class="string">"1920x1080"</span> <span class="string">"1360x768"</span> <span class="string">"1024x768"</span> <span class="string">"1152x864"</span>
    EndSubSection
EndSection        
</code></pre><p>注销系统再次登录后，选择适合的桌面分辨率即可。</p>
<p><strong>5.安装CUDA8.0</strong></p>
<p>到官网下载<a href="https://developer.nvidia.com/cuda-release-candidate-download" target="_blank" rel="external">cuda_8.0.44_linux.run</a>，复制到根目录下。</p>
<pre><code>sudo sh cuda_8.0.44_linux.<span class="command">run</span> <span class="comment">--tmpdir=/tmp/</span>
</code></pre><p>遇到问题：incomplete installation，然后执行</p>
<pre><code>sudo apt-<span class="built_in">get</span> install freeglut3-<span class="built_in">dev</span> build-essential libx11-<span class="built_in">dev</span> libxmu-<span class="built_in">dev</span> libxi-<span class="built_in">dev</span> libgl1-mesa-glx libglu1-mesa libglu1-mesa-<span class="built_in">dev</span>
sudo sh cuda_8.0.44_linux.run -silent -driver
</code></pre><p>注：此时安装过程中提示是否要安装NVIDIA驱动时选择no。其他选择yes或默认即可。</p>
<pre><code>Install NVIDIA Accelerated Graphics Driver <span class="keyword">for</span> Linux-x86_64 <span class="number">361.62</span>? <span class="params">(y)</span>es/<span class="params">(n)</span>o/<span class="params">(q)</span>uit: n
</code></pre><p>安装完毕后声明环境变量：</p>
<pre><code><span class="title">sudo</span> gedit ~/.bashrc
</code></pre><p>在.bashrc尾部添加如下内容：</p>
<pre><code>export <span class="constant">PATH</span>=<span class="regexp">/usr/local</span><span class="regexp">/cuda-8.0/bin</span><span class="variable">${</span><span class="constant">PATH</span><span class="symbol">:+</span><span class="symbol">:</span><span class="variable">${</span><span class="constant">PATH</span>}}
export <span class="constant">LD_LIBRARY_PATH</span>=<span class="regexp">/usr/local</span><span class="regexp">/cuda-8.0/lib</span>64<span class="variable">${</span><span class="constant">LD_LIBRARY_PATH</span><span class="symbol">:+</span><span class="symbol">:</span><span class="variable">${</span><span class="constant">LD_LIBRARY_PATH</span>}}
</code></pre><p>测试下安装是否成功：</p>
<p>测试1：</p>
<pre><code>cd NVIDI<span class="built_in">A_CUDA</span>-<span class="number">8.0</span>_Samples/
nvidia-smi
</code></pre><p>输出：</p>
<pre><code>Tue Oct 18 15:20:34 2016       
+-----------------------------------------------------------------------------+
|<span class="string"> NVIDIA-SMI 367.44                 Driver Version: 367.44                    </span>|
|<span class="string">-------------------------------+----------------------+----------------------+
</span>|<span class="string"> GPU  Name        Persistence-M</span>|<span class="string"> Bus-Id        Disp.A </span>|<span class="string"> Volatile Uncorr. ECC </span>|
|<span class="string"> Fan  Temp  Perf  Pwr:Usage/Cap</span>|<span class="string">         Memory-Usage </span>|<span class="string"> GPU-Util  Compute M. </span>|
|<span class="string">===============================+======================+======================</span>|
|<span class="string">   0  GeForce GTX TIT...  Off  </span>|<span class="string"> 0000:01:00.0      On </span>|<span class="string">                  N/A </span>|
|<span class="string"> 22%   48C    P5    27W / 250W </span>|<span class="string">    169MiB / 12205MiB </span>|<span class="string">      1%      Default </span>|
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
|<span class="string"> Processes:                                                       GPU Memory </span>|
|<span class="string">  GPU       PID  Type  Process name                               Usage      </span>|
|<span class="string">=============================================================================</span>|
|<span class="string">    0      2421    G   /usr/lib/xorg/Xorg                             105MiB </span>|
|<span class="string">    0     10062    G   compiz                                          63MiB </span>|
+-----------------------------------------------------------------------------+
</code></pre><p>测试2：</p>
<pre><code>cd <span class="number">1</span>_Utilities/deviceQuery
make
<span class="attribute">...</span><span class="attribute">...</span><span class="built_in">..
</span><span class="built_in">.</span>/deviceQuery 
</code></pre><p>输出：</p>
<pre><code>./deviceQuery Starting...

 CUDA Device Query (Runtime API) version (CUDART static linking)

Detected 1 CUDA Capable device(s)

Device 0: "GeForce GTX TITAN X"
  CUDA Driver Version / Runtime Version          8.0 / 8.0
  CUDA Capability Major/Minor version number:    5.2
  Total amount of global memory:                 12205 MBytes (12798197760 bytes)
  (24) Multiprocessors, (128) CUDA Cores/MP:     3072 CUDA Cores
  GPU Max Clock rate:                            1076 MHz (1.08 GHz)
  Memory Clock rate:                             3505 Mhz
  Memory Bus Width:                              384-bit
  L2 <span class="operator"><span class="keyword">Cache</span> <span class="keyword">Size</span>:                                 <span class="number">3145728</span> bytes
  Maximum Texture Dimension <span class="keyword">Size</span> (x,y,z)         <span class="number">1</span>D=(<span class="number">65536</span>), <span class="number">2</span>D=(<span class="number">65536</span>, <span class="number">65536</span>), <span class="number">3</span>D=(<span class="number">4096</span>, <span class="number">4096</span>, <span class="number">4096</span>)
  Maximum Layered <span class="number">1</span>D Texture <span class="keyword">Size</span>, (num) layers  <span class="number">1</span>D=(<span class="number">16384</span>), <span class="number">2048</span> layers
  Maximum Layered <span class="number">2</span>D Texture <span class="keyword">Size</span>, (num) layers  <span class="number">2</span>D=(<span class="number">16384</span>, <span class="number">16384</span>), <span class="number">2048</span> layers
  Total amount <span class="keyword">of</span> constant memory:               <span class="number">65536</span> bytes
  Total amount <span class="keyword">of</span> shared memory per block:       <span class="number">49152</span> bytes
  Total <span class="built_in">number</span> <span class="keyword">of</span> registers available per block: <span class="number">65536</span>
  Warp <span class="keyword">size</span>:                                     <span class="number">32</span>
  Maximum <span class="built_in">number</span> <span class="keyword">of</span> threads per multiprocessor:  <span class="number">2048</span>
  Maximum <span class="built_in">number</span> <span class="keyword">of</span> threads per block:           <span class="number">1024</span>
  <span class="keyword">Max</span> dimension <span class="keyword">size</span> <span class="keyword">of</span> a thread block (x,y,z): (<span class="number">1024</span>, <span class="number">1024</span>, <span class="number">64</span>)
  <span class="keyword">Max</span> dimension <span class="keyword">size</span> <span class="keyword">of</span> a grid <span class="keyword">size</span>    (x,y,z): (<span class="number">2147483647</span>, <span class="number">65535</span>, <span class="number">65535</span>)
  Maximum memory pitch:                          <span class="number">2147483647</span> bytes
  Texture alignment:                             <span class="number">512</span> bytes
  <span class="keyword">Concurrent</span> copy <span class="keyword">and</span> kernel execution:          Yes <span class="keyword">with</span> <span class="number">2</span> copy <span class="keyword">engine</span>(s)
  Run <span class="keyword">time</span> <span class="keyword">limit</span> <span class="keyword">on</span> kernels:                     Yes
  Integrated GPU sharing Host Memory:            <span class="keyword">No</span>
  Support host page-locked memory mapping:       Yes
  Alignment requirement <span class="keyword">for</span> Surfaces:            Yes
  Device has ECC support:                        Disabled
  Device supports Unified Addressing (UVA):      Yes
  Device PCI <span class="keyword">Domain</span> ID / Bus ID / location ID:   <span class="number">0</span> / <span class="number">1</span> / <span class="number">0</span>
  Compute <span class="keyword">Mode</span>:
     &lt; <span class="keyword">Default</span> (multiple host threads can <span class="keyword">use</span> ::cudaSetDevice() <span class="keyword">with</span> device simultaneously) &gt;

deviceQuery, CUDA Driver = CUDART, CUDA Driver <span class="keyword">Version</span> = <span class="number">8.0</span>, CUDA Runtime <span class="keyword">Version</span> = <span class="number">8.0</span>, NumDevs = <span class="number">1</span>, Device0 = GeForce GTX TITAN X
Result = PASS</span>
</code></pre><p>测试3：</p>
<pre><code>cd <span class="built_in">..</span><span class="subst">/</span><span class="built_in">..</span>/<span class="number">5</span>_Simulations/nbody<span class="subst">/</span>
make
<span class="attribute">...</span><span class="attribute">...</span><span class="attribute">...</span>
<span class="built_in">.</span>/nbody <span class="attribute">-benchmark</span> <span class="attribute">-numbodies</span><span class="subst">=</span><span class="number">256000</span> <span class="attribute">-device</span><span class="subst">=</span><span class="number">0</span>
</code></pre><p>输出：</p>
<pre><code>mark -numbodies=<span class="number">256000</span> -device=<span class="number">0</span>
Run <span class="string">"nbody -benchmark [-numbodies=&lt;numBodies&gt;]"</span> <span class="keyword">to</span> measure performance.
-fullscreen       (<span class="command">run</span> n-body simulation <span class="keyword">in</span> fullscreen mode)
-fp64             (use double precision floating point values <span class="keyword">for</span> simulation)
-hostmem          (stores simulation data <span class="keyword">in</span> host memory)
-benchmark        (<span class="command">run</span> benchmark <span class="keyword">to</span> measure performance) 
-numbodies=&lt;N&gt;    (<span class="type">number</span> <span class="keyword">of</span> bodies (&gt;= <span class="number">1</span>) <span class="keyword">to</span> <span class="command">run</span> <span class="keyword">in</span> simulation) 
-device=&lt;d&gt;       (<span class="keyword">where</span> d=<span class="number">0</span>,<span class="number">1</span>,<span class="number">2.</span>... <span class="keyword">for</span> <span class="keyword">the</span> CUDA device <span class="keyword">to</span> use)
-numdevices=&lt;i&gt;   (<span class="keyword">where</span> i=(<span class="type">number</span> <span class="keyword">of</span> CUDA devices &gt; <span class="number">0</span>) <span class="keyword">to</span> use <span class="keyword">for</span> simulation)
-compare          (compares simulation results <span class="property">running</span> once <span class="function_start"><span class="keyword">on</span></span> <span class="keyword">the</span> default GPU <span class="keyword">and</span> once <span class="function_start"><span class="keyword">on</span></span> <span class="keyword">the</span> CPU)
-cpu              (<span class="command">run</span> n-body simulation <span class="function_start"><span class="keyword">on</span></span> <span class="keyword">the</span> CPU)
-tipsy=&lt;<span class="type">file</span>.bin&gt; (load a tipsy model <span class="type">file</span> <span class="keyword">for</span> simulation)

NOTE: The CUDA Samples are <span class="keyword">not</span> meant <span class="keyword">for</span> performance measurements. Results may vary when GPU Boost <span class="keyword">is</span> enabled.

&gt; Windowed mode
&gt; Simulation data stored <span class="keyword">in</span> video memory
&gt; Single precision floating point simulation
&gt; <span class="number">1</span> Devices used <span class="keyword">for</span> simulation
gpuDeviceInit() CUDA Device [<span class="number">0</span>]: <span class="string">"GeForce GTX TITAN X
&gt; Compute 5.2 CUDA device: [GeForce GTX TITAN X]
number of bodies = 256000
256000 bodies, total time for 10 iterations: 3104.433 ms
= 211.105 billion interactions per second
= 4222.091 single-precision GFLOP/s at 20 flops per interaction</span>
</code></pre><p><strong>6.安装OpenCV 3.1.0</strong></p>
<p>从官网下载zip源代码，解压到根目录下。<br>安装依赖：</p>
<pre><code>sudo apt-<span class="built_in">get</span> -y remove ffmpeg x264 libx264-<span class="built_in">dev</span>
sudo apt-<span class="built_in">get</span> -y install libopencv-<span class="built_in">dev</span> build-essential checkinstall cmake pkg-config yasm  libjpeg-<span class="built_in">dev</span> libjasper-<span class="built_in">dev</span> libavcodec-<span class="built_in">dev</span> libavformat-<span class="built_in">dev</span> libswscale-<span class="built_in">dev</span> libdc1394-<span class="number">22</span>-<span class="built_in">dev</span>  libgstreamer0.10-<span class="built_in">dev</span> libgstreamer-plugins-base0.10-<span class="built_in">dev</span> libv4l-<span class="built_in">dev</span> python-<span class="built_in">dev</span> python-numpy libtbb-<span class="built_in">dev</span> libqt4-<span class="built_in">dev</span> libgtk2.0-<span class="built_in">dev</span> libfaac-<span class="built_in">dev</span> libmp3lame-<span class="built_in">dev</span> libopencore-amrnb-<span class="built_in">dev</span> libopencore-amrwb-<span class="built_in">dev</span> libtheora-<span class="built_in">dev</span> libvorbis-<span class="built_in">dev</span> libxvidcore-<span class="built_in">dev</span> x264 v4l-utils ffmpeg libgtk2.0-<span class="built_in">dev</span>

cd opencv-<span class="number">3.1</span>.0
mkdir build   
cd build/
cmake -D CMAKE_BUILD_TYPE=RELEASE -D CMAKE_INSTALL_PREFIX=/usr/local -D WITH_TBB=ON -D BUILD_NEW_PYTHON_SUPPORT=ON -D WITH_V4L=ON -D INSTALL_C_EXAMPLES=ON -D INSTALL_PYTHON_EXAMPLES=ON -D BUILD_EXAMPLES=ON -D WITH_QT=ON -D WITH_OPENGL=ON ..
make -j8
sudo make install
</code></pre><p>遇到的错误：Errors</p>
<pre><code><span class="keyword">error</span>: ‘NppiGraphcutState’ has <span class="keyword">not</span> been declared
<span class="keyword">error</span>: ‘NppiGraphcutState’ <span class="keyword">does</span> <span class="keyword">not</span> <span class="property">name</span> a type
...
</code></pre><p>解决方法：(由于CUDA版本高于8.0，所以需要做如下修改。在源文件中找到“graphcuts.cpp”)</p>
<p>将：</p>
<pre><code><span class="preprocessor">#<span class="keyword">include</span> "precomp.hpp"</span>
<span class="preprocessor">#<span class="keyword">if</span> !defined (HAVE_CUDA) || defined (CUDA_DISABLER)</span>
</code></pre><p>改为:</p>
<pre><code><span class="preprocessor">#<span class="keyword">include</span> "precomp.hpp"</span>
<span class="preprocessor">#<span class="keyword">if</span> !defined (HAVE_CUDA) || defined (CUDA_DISABLER)  || (CUDART_VERSION &gt;= 8000)</span>
</code></pre><p>because graphcuts is not supported directly with CUDA8 anymore.</p>
<p>安装成功后配置环境：</p>
<pre><code>sudo <span class="keyword">sh</span> -c 'echo <span class="string">"/usr/local/lib"</span> &gt; /etc/ld.<span class="keyword">so</span>.<span class="keyword">conf</span>.<span class="keyword">d</span>/opencv.<span class="keyword">conf</span>'
sudo ldconfig
</code></pre><p>测试OpenCV安装是否成功：</p>
<pre><code><span class="built_in">mkdir</span> DisplayImage  
<span class="built_in">cd</span> DisplayImage 
gedit DisplayImage.cpp 
</code></pre><p>添加代码：</p>
<pre><code><span class="preprocessor">#<span class="keyword">include</span> &lt;stdio.h&gt;  </span>
<span class="preprocessor">#<span class="keyword">include</span> &lt;opencv2/opencv.hpp&gt;  </span>
<span class="keyword">using</span> <span class="keyword">namespace</span> cv;  

<span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span>** argv)</span>  
</span>{  
     <span class="keyword">if</span>(argc!= <span class="number">2</span>)  
     {  
               <span class="built_in">printf</span>(<span class="string">"usage:DisplayImage.out &lt;Image_Path&gt;\n"</span>);  
               <span class="keyword">return</span> -<span class="number">1</span>;  
     }  

     Mat image;  
     image= imread(argv[<span class="number">1</span>], <span class="number">1</span>);  

    <span class="keyword">if</span>(!image.data)  
    {  
               <span class="built_in">printf</span>(<span class="string">"Noimage data\n"</span>);  
               <span class="keyword">return</span> -<span class="number">1</span>;  
     }  

     namedWindow(<span class="string">"DisplayImage"</span>,CV_WINDOW_AUTOSIZE);  
     imshow(<span class="string">"DisplayImage"</span>,image);  

     waitKey(<span class="number">0</span>);  
     <span class="keyword">return</span> <span class="number">0</span>;  
}  
</code></pre><p>创建CMake文件：</p>
<pre><code>gedit CMakeLists<span class="class">.txt</span>  
</code></pre><p>添加内容：</p>
<pre><code><span class="function"><span class="title">cmake_minimum_required</span><span class="params">(VERSION <span class="number">2.8</span>)</span></span>  
<span class="function"><span class="title">project</span><span class="params">(DisplayImage)</span></span>  
<span class="function"><span class="title">find_package</span><span class="params">(OpenCV REQUIRED)</span></span>  
<span class="function"><span class="title">add_executable</span><span class="params">(DisplayImage DisplayImage.cpp)</span></span>  
<span class="function"><span class="title">target_link_libraries</span><span class="params">(DisplayImage ${OpenCV_LIBS})</span></span> 
</code></pre><p>编译：</p>
<pre><code>cmake .  
<span class="built_in">make</span> 
</code></pre><p>执行：</p>
<pre><code>./DisplayImage lena<span class="class">.jpg</span>  
</code></pre><p><strong>7.安装cudnn 5.1</strong></p>
<p>从官网下载<a href="https://developer.nvidia.com/cudnn" target="_blank" rel="external">cudnn-8.0-linux-x64-v5.1.tgz</a> for CUDA 8.0. 解压到当前目录：</p>
<pre><code><span class="tag">tar</span> <span class="tag">-zxvf</span> <span class="tag">cudnn-8</span><span class="class">.0-linux-x64-v5</span><span class="class">.1</span><span class="class">.tgz</span>
</code></pre><p>解压后的文件如下：</p>
<pre><code>cuda/include/cudnn<span class="class">.h</span>
cuda/lib64/libcudnn<span class="class">.so</span>
cuda/lib64/libcudnn<span class="class">.so</span>.<span class="number">5</span>
cuda/lib64/libcudnn<span class="class">.so</span>.<span class="number">5.1</span>.<span class="number">5</span>
cuda/lib64/libcudnn_static.a
</code></pre><p>然后执行：</p>
<pre><code>sudo cp cuda<span class="regexp">/include/</span>cudnn.h <span class="regexp">/usr/</span>local<span class="regexp">/cuda/</span>include/
sudo cp cuda<span class="regexp">/lib64/</span>libcudnn* <span class="regexp">/usr/</span>local<span class="regexp">/cuda/</span>lib64/
sudo chmod a+r <span class="regexp">/usr/</span>local<span class="regexp">/cuda/</span>include/cudnn.h
sudo chmod a+r <span class="regexp">/usr/</span>local<span class="regexp">/cuda/</span>lib64/libcudnn*
</code></pre><p><strong>8.安装MATLAB 2014a</strong></p>
<p>需要注意的是Ubuntu16.04 LTS的gcc版本为5.4，而Matlab2014a支持的是gcc4.7。</p>
<p>降级安装gcc/g++版本为4.7.x</p>
<p>下载gcc/g++ 4.7.x</p>
<pre><code>sudo apt-get <span class="operator"><span class="keyword">install</span> -y gcc-<span class="number">4.7</span>

sudo apt-<span class="keyword">get</span> <span class="keyword">install</span> -y g++-<span class="number">4.7</span></span>
</code></pre><p>链接gcc/g++实现降级</p>
<pre><code><span class="keyword">cd</span> /usr/bin

sudo <span class="keyword">rm</span> gcc

sudo ln -s gcc-4.7 gcc

sudo <span class="keyword">rm</span> <span class="keyword">g</span>++

sudo ln -s <span class="keyword">g</span>++-4.7 <span class="keyword">g</span>++
</code></pre><hr>
<p>升级 gcc 到 gcc-5版本</p>
<p>首先添加ppa到库：</p>
<pre><code>sudo<span class="instruction"> add-apt-repository </span>ppa:ubuntu-toolchain-r/test
sudo apt-get update
</code></pre><p>如果提示未安装，还需要先安装它的包：</p>
<pre><code>sudo apt-get <span class="operator"><span class="keyword">install</span> software-properties-common

sudo apt-<span class="keyword">get</span> <span class="keyword">upgrade</span>
sudo apt-<span class="keyword">get</span> <span class="keyword">install</span> gcc-<span class="number">5</span> g++-<span class="number">5</span></span>
</code></pre><p>（非必须）现在可以考虑刷新一下，否则locate等命令是找不到的：</p>
<pre><code><span class="title">sudo</span> updatedb &amp;&amp; sudo ldconfig
locate gcc
</code></pre><p>你会发现  gcc -v 显示出来的版本还是gcc-4.7的，因此需要更新一下链接：</p>
<pre><code>update-alternatives --install <span class="regexp">/usr/</span>bin<span class="regexp">/gcc gcc /u</span>sr<span class="regexp">/bin/g</span>cc-<span class="number">5</span> <span class="number">53</span> \
--slave <span class="regexp">/usr/</span>bin<span class="regexp">/g++ g++ /u</span>sr<span class="regexp">/bin/g</span>++-<span class="number">5</span> \
--slave <span class="regexp">/usr/</span>bin<span class="regexp">/gcc-ar gcc-ar /u</span>sr<span class="regexp">/bin/g</span>cc-ar-<span class="number">5</span> \
--slave <span class="regexp">/usr/</span>bin<span class="regexp">/gcc-nm gcc-nm /u</span>sr<span class="regexp">/bin/g</span>cc-nm-<span class="number">5</span> \
--slave <span class="regexp">/usr/</span>bin<span class="regexp">/gcc-ranlib gcc-ranlib /u</span>sr<span class="regexp">/bin/g</span>cc-ranlib-<span class="number">5</span>
</code></pre><p>=======================================================</p>
<p>用Crack文件中的install替换matlab2014安装目录下/java/jar/下的install文件，然后执行install程序</p>
<pre><code><span class="built_in">cd</span> <span class="string">"MatlabFolder"</span>
sudo ./install
</code></pre><p>注意：选择“不联网安装”；当出现密钥时，随意输入20个数字12345-67890-12345-67890即可；需要激活时选择不要联网激活，用Crack目录下的“license_405329_R2014a.lic”文件激活。</p>
<p>安装完成之后，将Crack/Linux目录下的libmwservices.so文件拷贝到/usr/local/MATLAB/R2014a/bin/glnxa64。</p>
<pre><code>cd ..
cd Crack<span class="regexp">/Linux/</span>
sudo cp libmwservices.so <span class="regexp">/usr/</span>local<span class="regexp">/MATLAB/</span>R2014a<span class="regexp">/bin/g</span>lnxa64
</code></pre><p>打开Matlab并激活：</p>
<pre><code><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/MATLAB/R2014a/bin
sudo ./matlab <span class="comment"># sudo不可缺少，否则选择激活文件后报错</span>
</code></pre><p>Test GPUdevice in Matlab:</p>
<pre><code>&gt;&gt; gpuDevice

ans = 

  CUDADevice <span class="keyword">with</span> properties:

                  Name: <span class="string">'GeForce GTX TITAN X'</span>
                 <span class="keyword">Index</span>: <span class="number">1</span>
     ComputeCapability: <span class="string">'5.2'</span>
        SupportsDouble: <span class="number">1</span>
         DriverVersion: <span class="number">8</span>
        ToolkitVersion: <span class="number">5.5000</span>
    MaxThreadsPerBlock: <span class="number">1024</span>
      MaxShmemPerBlock: <span class="number">49152</span>
    MaxThreadBlockSize: [<span class="number">1024</span> <span class="number">1024</span> <span class="number">64</span>]
           MaxGridSize: [<span class="number">2.1475</span>e+<span class="number">09</span> <span class="number">65535</span> <span class="number">65535</span>]
             SIMDWidth: <span class="number">32</span>
           TotalMemory: <span class="number">1.2796</span>e+<span class="number">10</span>
            FreeMemory: <span class="number">1.2475</span>e+<span class="number">10</span>
       MultiprocessorCount: <span class="number">24</span>
          ClockRateKHz: <span class="number">1076000</span>
           ComputeMode: <span class="string">'Default'</span>
      GPUOverlapsTransfers: <span class="number">1</span>
    KernelExecutionTimeout: <span class="number">1</span>
      CanMapHostMemory: <span class="number">1</span>
       DeviceSupported: <span class="number">1</span>
        DeviceSelected: <span class="number">1</span>
</code></pre><p><strong>9.Python</strong></p>
<p>选用Ubuntu16.04默认的安装和配置，python版本2.7.12.</p>
<p><strong>10.BLAS安装与配置</strong></p>
<p>BLAS（基础线性代数集合）是一个应用程序接口的标准。caffe官网上推荐了三种实现：ATLAS, MKL, OpenBLAS。其中ATLAS可以直接通过命令行安装。MKL是微软开发的商业工具包，面向科研和学生免费开放。申请学生版的<a href="https://software.intel.com/en-us/qualify-for-free-software/student" target="_blank" rel="external">Parallel Studio XE Cluster Edition</a>，下载parallel_studio_xe_2017.tgz。注意接收邮件中的序列号(<em>2HWS-34Z7S69B</em>)。</p>
<pre><code>tar zxvf parallel_studio_xe_2017.tgz   <span class="comment">#解压下载文件</span>
 chmod <span class="number">777</span> parallel_studio_xe_2017 -R   <span class="comment">#获取文件权限</span>
<span class="built_in">cd</span> parallel_studio_xe_2017/
 sudo ./install_GUI.sh
</code></pre><p>安装完成之后，进行相关文件的链接：</p>
<pre><code>sudo gedit /etc/ld.<span class="keyword">so</span>.<span class="keyword">conf</span>.<span class="keyword">d</span>/intel_mkl.<span class="keyword">conf</span>
</code></pre><p>添加库文件:</p>
<pre><code><span class="regexp">/opt/i</span>ntel<span class="regexp">/lib/i</span>ntel64
<span class="regexp">/opt/i</span>ntel<span class="regexp">/mkl/</span>lib<span class="regexp">/intel64</span>
</code></pre><p>编译链接使lib文件生效：</p>
<pre><code><span class="title">sudo</span> ldconfig    
</code></pre><p>如果选择安装ATLAS，在终端输入<code>sudo apt-get install libatlas-base-dev</code>即可。</p>
<p><strong>11.Caffe的安装与配置</strong></p>
<p>Caffe是由BVLC开发的一个深度学习框架，主要由贾扬清在UC Berkeley攻读PhD期间完成。参考官网上的<a href="http://caffe.berkeleyvision.org/installation.html" target="_blank" rel="external">教程</a>以及Github上针对Ubuntu15.04和16.04的<a href="https://github.com/BVLC/caffe/wiki/Ubuntu-16.04-or-15.10-Installation-Guide" target="_blank" rel="external">教程</a>。从官方下载caffe源包<a href="https://github.com/BVLC/caffe" target="_blank" rel="external">caffe-master</a>。</p>
<p>安装库文件：</p>
<pre><code>sudo apt-<span class="built_in">get</span> install libprotobuf-<span class="built_in">dev</span> libleveldb-<span class="built_in">dev</span> libsnappy-<span class="built_in">dev</span> libboost-<span class="built_in">all</span>-<span class="built_in">dev</span> libhdf5-serial-<span class="built_in">dev</span> libgflags-<span class="built_in">dev</span> libgoogle-glog-<span class="built_in">dev</span> liblmdb-<span class="built_in">dev</span> protobuf-compiler
</code></pre><p>安装依赖：</p>
<pre><code>sudo apt-<span class="built_in">get</span> install -y build-essential cmake git pkg-config libprotobuf-<span class="built_in">dev</span> libleveldb-<span class="built_in">dev</span> libsnappy-<span class="built_in">dev</span> libopencv-<span class="built_in">dev</span> libhdf5-serial-<span class="built_in">dev</span> protobuf-compiler libatlas-base-<span class="built_in">dev</span> libgflags-<span class="built_in">dev</span> libgoogle-glog-<span class="built_in">dev</span> liblmdb-<span class="built_in">dev</span>
sudo apt-<span class="built_in">get</span> install --no-install-recommends libboost-<span class="built_in">all</span>-<span class="built_in">dev</span>
</code></pre><p>Python接口依赖：</p>
<pre><code>sudo apt-<span class="built_in">get</span> install <span class="keyword">python</span>-dev
sudo apt-<span class="built_in">get</span> install -<span class="keyword">y</span> <span class="keyword">python</span>-pip
sudo apt-<span class="built_in">get</span> install -<span class="keyword">y</span> <span class="keyword">python</span>-dev
sudo apt-<span class="built_in">get</span> install -<span class="keyword">y</span> <span class="keyword">python</span>-numpy <span class="keyword">python</span>-scipy # (Python <span class="number">2.7</span> development <span class="keyword">files</span>)
sudo apt-<span class="built_in">get</span> install -<span class="keyword">y</span> <span class="keyword">python3</span>-dev
sudo apt-<span class="built_in">get</span> install -<span class="keyword">y</span> <span class="keyword">python3</span>-numpy <span class="keyword">python3</span>-scipy # (Python <span class="number">3.5</span> development <span class="keyword">files</span>)
</code></pre><p>在python文件夹内，使用root执行依赖项的检查与安装：</p>
<pre><code>sudo <span class="keyword">su</span>
<span class="keyword">cd</span> caffe-master/python
<span class="keyword">for</span> req <span class="keyword">in</span> $(<span class="keyword">cat</span> requirements.txt); <span class="keyword">do</span> pip install <span class="label">$req</span>; done
</code></pre><p>Makefile.config：</p>
<pre><code>cd ~/caffe-master
cp Makefile<span class="class">.config</span><span class="class">.example</span> Makefile.config
</code></pre><p>配置如下：</p>
<pre><code><span class="preprocessor">## Refer to http://caffe.berkeleyvision.org/installation.html</span>
<span class="preprocessor"># Contributions simplifying and improving our build system are welcome!</span>

<span class="preprocessor"># cuDNN acceleration switch (uncomment to build with cuDNN).</span>
<span class="constant"> USE_CUDNN </span>:= <span class="number">1</span>

<span class="preprocessor"># CPU-only switch (uncomment to build without GPU support).</span>
<span class="preprocessor"># CPU_ONLY := 1</span>

<span class="preprocessor"># uncomment to disable IO dependencies and corresponding data layers</span>
 <span class="constant"> USE_OPENCV </span>:= <span class="number">1</span>
<span class="preprocessor"># USE_LEVELDB := 0</span>
<span class="preprocessor"># USE_LMDB := 0</span>

<span class="preprocessor"># uncomment to allow MDB_NOLOCK when reading LMDB files (only if necessary)</span>
<span class="preprocessor">#    You should not set this flag if you will be reading LMDBs with any</span>
<span class="preprocessor">#    possibility of simultaneous read and write</span>
<span class="preprocessor"># ALLOW_LMDB_NOLOCK := 1</span>

<span class="preprocessor"># Uncomment if you're using OpenCV 3</span>
<span class="constant"> OPENCV_VERSION </span>:= <span class="number">3</span>

<span class="preprocessor"># To customize your choice of compiler, uncomment and set the following.</span>
<span class="preprocessor"># N.B. the default for Linux is g++ and the default for OSX is clang++</span>
<span class="preprocessor"># CUSTOM_CXX := g++</span>

<span class="preprocessor"># CUDA directory contains bin/ and lib/ directories that we need.</span>
CUDA_DIR := /usr/local/cuda
<span class="preprocessor"># On Ubuntu 14.04, if cuda tools are installed via</span>
<span class="preprocessor"># "sudo apt-get install nvidia-cuda-toolkit" then use this instead:</span>
<span class="preprocessor"># CUDA_DIR := /usr</span>

<span class="preprocessor"># CUDA architecture setting: going with all of them.</span>
<span class="preprocessor"># For CUDA &lt; 6.0, comment the *_50 lines for compatibility.</span>
CUDA_ARCH := -gencode arch=compute_20,code=sm_20 \
        -gencode arch=compute_20,code=sm_21 \
        -gencode arch=compute_30,code=sm_30 \
        -gencode arch=compute_35,code=sm_35 \
        -gencode arch=compute_50,code=sm_50 \
        -gencode arch=compute_50,code=compute_50

<span class="preprocessor"># BLAS choice:</span>
<span class="preprocessor"># atlas for ATLAS (default)</span>
<span class="preprocessor"># mkl for MKL</span>
<span class="preprocessor"># open for OpenBlas</span>
BLAS := mkl
<span class="preprocessor"># Custom (MKL/ATLAS/OpenBLAS) include and lib directories.</span>
<span class="preprocessor"># Leave commented to accept the defaults for your choice of BLAS</span>
<span class="preprocessor"># (which should work)!</span>
<span class="preprocessor"># BLAS_INCLUDE := /path/to/your/blas</span>
<span class="preprocessor"># BLAS_LIB := /path/to/your/blas</span>

<span class="preprocessor"># Homebrew puts openblas in a directory that is not on the standard search path</span>
<span class="preprocessor"># BLAS_INCLUDE := $(shell brew --prefix openblas)/include</span>
<span class="preprocessor"># BLAS_LIB := $(shell brew --prefix openblas)/lib</span>

<span class="preprocessor"># This is required only if you will compile the matlab interface.</span>
<span class="preprocessor"># MATLAB directory should contain the mex binary in /bin.</span>
 <span class="constant"> MATLAB_DIR </span>:= /usr/local/MATLAB/R2014a
<span class="preprocessor"># MATLAB_DIR := /Applications/MATLAB_R2012b.app</span>

<span class="preprocessor"># NOTE: this is required only if you will compile the python interface.</span>
<span class="preprocessor"># We need to be able to find Python.h and numpy/arrayobject.h.</span>
PYTHON_INCLUDE := /usr/include/python2.7 \
        /usr/local/lib/python2.7/dist-packages/numpy/core/include
<span class="preprocessor"># Anaconda Python distribution is quite popular. Include path:</span>
<span class="preprocessor"># Verify anaconda location, sometimes it's in root.</span>
<span class="preprocessor"># ANACONDA_HOME := $(HOME)/anaconda</span>
<span class="preprocessor"># PYTHON_INCLUDE := $(ANACONDA_HOME)/include \</span>
        # $(ANACONDA_HOME)/include/python2.7 \
        # $(ANACONDA_HOME)/lib/python2.7/site-packages/numpy/core/include \

<span class="preprocessor"># Uncomment to use Python 3 (default is Python 2)</span>
<span class="preprocessor"># PYTHON_LIBRARIES := boost_python3 python3.5m</span>
<span class="preprocessor"># PYTHON_INCLUDE := /usr/include/python3.5m \</span>
<span class="preprocessor">#                 /usr/lib/python3.5/dist-packages/numpy/core/include</span>

<span class="preprocessor"># We need to be able to find libpythonX.X.so or .dylib.</span>
PYTHON_LIB := /usr/lib
<span class="preprocessor"># PYTHON_LIB := $(ANACONDA_HOME)/lib</span>

<span class="preprocessor"># Homebrew installs numpy in a non standard path (keg only)</span>
<span class="preprocessor"># PYTHON_INCLUDE += $(dir $(shell python -c 'import numpy.core; print(numpy.core.__file__)'))/include</span>
<span class="preprocessor"># PYTHON_LIB += $(shell brew --prefix numpy)/lib</span>

<span class="preprocessor"># Uncomment to support layers written in Python (will link against Python libs)</span>
 <span class="constant"> WITH_PYTHON_LAYER </span>:= <span class="number">1</span>

<span class="preprocessor"># Whatever else you find you need goes here.</span>
INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include  /usr/include/hdf5/serial
LIBRARY_DIRS := $(PYTHON_LIB) /usr/local/lib /usr/lib /usr/lib/x86_64-linux-gnu /usr/lib/x86_64-linux-gnu/hdf5/serial /usr/local/share/OpenCV/<span class="number">3</span>rdparty/lib/

<span class="preprocessor"># If Homebrew is installed at a non standard location (for example your home directory) and you use it for general dependencies</span>
<span class="preprocessor"># INCLUDE_DIRS += $(shell brew --prefix)/include</span>
<span class="preprocessor"># LIBRARY_DIRS += $(shell brew --prefix)/lib</span>

<span class="preprocessor"># Uncomment to use `pkg-config` to specify OpenCV library paths.</span>
<span class="preprocessor"># (Usually not necessary -- OpenCV libraries are normally installed in one of the above $LIBRARY_DIRS.)</span>
<span class="preprocessor"># USE_PKG_CONFIG := 1</span>

<span class="preprocessor"># N.B. both build and distribute dirs are cleared on `make clean`</span>
BUILD_DIR := build
DISTRIBUTE_DIR := distribute

<span class="preprocessor"># Uncomment for debugging. Does not work on OSX due to https://github.com/BVLC/caffe/issues/171</span>
<span class="preprocessor"># DEBUG := 1</span>

<span class="preprocessor"># The ID of the GPU that 'make runtest' will use to run unit tests.</span>
TEST_GPUID := <span class="number">0</span>

<span class="preprocessor"># enable pretty build (comment to see full commands)</span>
Q ?= @
</code></pre><p>在Makefile中配置：</p>
<pre><code><span class="label">LIBRARIES</span> += glog gflags protobuf <span class="keyword">boost_system </span><span class="keyword">boost_filesystem </span>m hdf5_hl hdf5 opencv_core opencv_highgui opencv_imgproc opencv_imgcodecs
</code></pre><p>hdf5的配置：官方说这对于Ubuntu 16.04是必须的。libhdf5的版本号需要根据实际来修改下。</p>
<pre><code>sudo find . -<span class="keyword">type</span> f -exec sed -i -<span class="keyword">e</span> 's^<span class="string">"hdf5.h"</span>^<span class="string">"hdf5/serial/hdf5.h"</span>^<span class="keyword">g</span>' -<span class="keyword">e</span> 's^<span class="string">"hdf5_hl.h"</span>^<span class="string">"hdf5/serial/hdf5_hl.h"</span>^<span class="keyword">g</span>' '{}' \;
<span class="keyword">cd</span> /usr/lib/x86_64-linux-gnu
sudo ln -s libhdf5_serial.<span class="keyword">so</span>.10.1.0 libhdf5.<span class="keyword">so</span>
sudo ln -s libhdf5_serial_hl.<span class="keyword">so</span>.10.0.2 libhdf5_hl.<span class="keyword">so</span>
</code></pre><p>编译：</p>
<pre><code><span class="keyword">cd</span> ~/caffe-master
<span class="keyword">make</span> clean
<span class="keyword">make</span> <span class="keyword">all</span> -j8
<span class="keyword">make</span> test -j8
<span class="keyword">make</span> runtest -j8
<span class="keyword">make</span> pycaffe -j8
<span class="keyword">make</span> matcaffe -j8
</code></pre><p>编译接口matcaffe时，有如下警告：</p>
<pre><code>Warning: You are <span class="keyword">using</span> gcc <span class="built_in">version</span> <span class="string">'5.4.0'</span>. The <span class="built_in">version</span> <span class="operator">of</span> gcc is <span class="operator">not</span> supported. The <span class="built_in">version</span> currently supported <span class="operator">with</span> MEX is <span class="string">'4.7.x'</span>. For <span class="operator">a</span> list <span class="operator">of</span> currently supported compilers see: <span class="keyword">http</span>://www.mathworks.com/support/compilers/current_release.
Warning: You are <span class="keyword">using</span> gcc <span class="built_in">version</span> <span class="string">'5.4.0-6ubuntu1~16.04.2)'</span>. The <span class="built_in">version</span> <span class="operator">of</span> gcc is <span class="operator">not</span> supported. The <span class="built_in">version</span> currently supported <span class="operator">with</span> MEX is <span class="string">'4.7.x'</span>. For <span class="operator">a</span> list <span class="operator">of</span> currently supported compilers see: <span class="keyword">http</span>://www.mathworks.com/support/compilers/current_release.
MEX completed successfully.
</code></pre><p>若OpenCV安装不正确则会在caffe编译过程中遇到如下错误：</p>
<pre><code><span class="regexp">/usr/</span>bin/<span class="string">ld:</span> cannot find -lopencv_imgcodecs
<span class="string">collect2:</span> <span class="string">error:</span> ld returned <span class="number">1</span> exit status
<span class="string">Makefile:</span><span class="number">566</span>: recipe <span class="keyword">for</span> target <span class="string">'.build_release/lib/libcaffe.so.1.0.0-rc3'</span> failed
<span class="string">make:</span> *** [.build_release<span class="regexp">/lib/</span>libcaffe.so.1.0.0-rc3] Error <span class="number">1</span>
</code></pre><p>MNIST测试：</p>
<pre><code>sh data/mnist/get_mnist<span class="class">.sh</span>  #数据预处理
sh examples/mnist/create_mnist<span class="class">.sh</span> #重建lmdb文件。Caffe支持多种数据格式: <span class="function"><span class="title">Image</span><span class="params">(.jpg, .png等)</span></span>,leveldb,lmdb,HDF5. 生成mnist-train-lmdb 和 mnist-train-lmdb文件夹，这里包含了lmdb格式的数据集
sh examples/mnist/train_lenet<span class="class">.sh</span> #训练mnist
</code></pre><p>输出：</p>
<pre><code>I<span class="number">1019 21:48</span>:<span class="number">30.078994</span> 20063 caffe.cpp:217] Using GPUs 0
I<span class="number">1019 21:48</span>:<span class="number">30.092034</span> 20063 caffe.cpp:222] GPU 0: GeForce GTX TITAN X
...
....
.....
I<span class="number">1019 21:48</span>:<span class="number">49.415398</span> 20063 solver.cpp:317] Iteration 10000, loss = <span class="number">0.00242468</span>
I<span class="number">1019 21:48</span>:<span class="number">49.415410</span> 20063 solver.cpp:337] Iteration 10000, Testing net (#0)
I<span class="number">1019 21:48</span>:<span class="number">49.479605</span> 20063 solver.cpp:404] Test net output #0: accuracy = 0.9914
I<span class="number">1019 21:48</span>:<span class="number">49.479625</span> 20063 solver.cpp:404] Test net output #1: loss = <span class="number">0.0284448</span> (* 1 = <span class="number">0.0284448</span> loss)
I<span class="number">1019 21:48</span>:<span class="number">49.479629</span> 20063 solver.cpp:322] Optimization Done.
I<span class="number">1019 21:48</span>:<span class="number">49.479632</span> 20063 caffe.cpp:254] Optimization Done.
</code></pre><p><strong>12.Caffe下Matlab接口Demo测试</strong></p>
<p>在使用Matlab运行caffe库时，即运行文件”caffe-master/matlab/demo/classification_demo.m”。遇到的错误信息如下：</p>
<pre><code>Invalid MEX-<span class="built_in">file</span> <span class="string">'caffe-master/matlab/+caffe/private/caffe_.mexa64'</span>: libcudart.so.8.0: cannot <span class="built_in">open</span> shared object <span class="built_in">file</span>: No such <span class="built_in">file</span> <span class="operator">or</span> <span class="built_in">directory</span>
</code></pre><p>错误原因是由于Matlab找不到caffe<em>.mexa64所依赖的所有库文件的路径，此时可以使用ldd命令来查看caffe\</em>.mexa64内库文件的地址：</p>
<p>//1. 在Ubuntu系统的命令终端</p>
<pre><code><span class="keyword">ldd</span> *caffe_.mexa64
</code></pre><p>结果输出的是库文件对应的地址，与下文相对的缺失的库文件的地址可在此找到：</p>
<pre><code>libcudart<span class="class">.so</span>.<span class="number">8.0</span> =&gt; /usr/local/cuda-<span class="number">8.0</span>/lib64/libcudart<span class="class">.so</span>.<span class="number">8.0</span>
libcublas<span class="class">.so</span>.<span class="number">8.0</span> =&gt; /usr/local/cuda-<span class="number">8.0</span>/lib64/libcublas<span class="class">.so</span>.<span class="number">8.0</span>
libcurand<span class="class">.so</span>.<span class="number">8.0</span> =&gt; /usr/local/cuda-<span class="number">8.0</span>/lib64/libcurand<span class="class">.so</span>.<span class="number">8.0</span>
libcudnn<span class="class">.so</span>.<span class="number">5</span> =&gt; /usr/local/cuda-<span class="number">8.0</span>/lib64/libcudnn<span class="class">.so</span>.<span class="number">5</span>
</code></pre><p>//2. 在Matlab命令窗口输入</p>
<pre><code>!<span class="keyword">ldd</span> *caffe_.mexa64
</code></pre><p>结果在Matlab窗口的输出信息中发现：</p>
<pre><code>libcudart<span class="class">.so</span>.<span class="number">8.0</span> =&gt; not found
libcublas<span class="class">.so</span>.<span class="number">8.0</span> =&gt; not found
libcurand<span class="class">.so</span>.<span class="number">8.0</span> =&gt; not found 
libcudnn<span class="class">.so</span>.<span class="number">5</span> =&gt; not found
</code></pre><p>解决方法：通过如下命令将默认路径链接到真实路径下：</p>
<pre><code>sudo ln -s <span class="regexp">/usr/</span>local<span class="regexp">/cuda-8.0/</span>lib64<span class="regexp">/libcudart.so.8.0 /</span>usr<span class="regexp">/local/</span>MATLAB<span class="regexp">/R2014a/</span>sys<span class="regexp">/os/</span>glnxa64/libcudart.so.8.0
sudo ln -s <span class="regexp">/usr/</span>local<span class="regexp">/cuda-8.0/</span>lib64<span class="regexp">/libcublas.so.8.0 /</span>usr<span class="regexp">/local/</span>MATLAB<span class="regexp">/R2014a/</span>sys<span class="regexp">/os/</span>glnxa64/libcublas.so.8.0
sudo ln -s <span class="regexp">/usr/</span>local<span class="regexp">/cuda-8.0/</span>lib64<span class="regexp">/libcurand.so.8.0 /</span>usr<span class="regexp">/local/</span>MATLAB<span class="regexp">/R2014a/</span>sys<span class="regexp">/os/</span>glnxa64/libcurand.so.8.0
sudo ln -s <span class="regexp">/usr/</span>local<span class="regexp">/cuda-8.0/</span>lib64<span class="regexp">/libcudnn.so.5 /</span>usr<span class="regexp">/local/</span>MATLAB<span class="regexp">/R2014a/</span>sys<span class="regexp">/os/</span>glnxa64/libcudnn.so.5
</code></pre><p>重新启动Matlab使之生效。</p>
<p>另外，运行此例需要下载CaffeNet模型（Please download CaffeNet from Model Zoo before you run this demo.）<a href="https://github.com/BVLC/caffe/wiki/Model-Zoo" target="_blank" rel="external">https://github.com/BVLC/caffe/wiki/Model-Zoo</a> </p>
<p>|| <em>name: BVLC CaffeNet Model</em></p>
<p>|| <em>caffemodel: bvlc_reference_caffenet.caffemodel</em></p>
<p>|| <em>caffemodel_url: <a href="https://dl.caffe.berkeleyvision.org/bvlc_reference_caffenet.caffemodel" target="_blank" rel="external">download</a></em></p>
<p>|| <em>license: unrestricted</em></p>
<p>详细说明可参见”caffe-master/models/bvlc_reference_caffenet”…</p>
<p><strong>参考：</strong></p>
<p><a href="http://www.2cto.com/os/201607/528798.html" target="_blank" rel="external">ubuntu14.04+cuda8.0（GTX1080）+caffe安装</a></p>
<p><a href="http://www.52nlp.cn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%BB%E6%9C%BA%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE-ubuntu-16-04-nvidia-gtx-1080-cuda-8" target="_blank" rel="external">深度学习主机环境配置: Ubuntu16.04+Nvidia GTX 1080+CUDA8.0</a></p>
<p><a href="http://www.jianshu.com/p/74e9c8697372" target="_blank" rel="external">深度学习框架torch/caffe/tensor/mxnet安装</a></p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/DeepLearning/">DeepLearning</a></li></ul>
	</div>

      
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/Research/">Research</a>
	</div>


      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-Ubuntu配置——Chrome XX-Net Sogou Nodejs Hexo" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/12/30/Ubuntu配置——Chrome XX-Net Sogou Nodejs Hexo/" class="article-date">
  	<time datetime="2016-12-30T01:59:46.000Z" itemprop="datePublished">2016-12-30</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Ubuntu 配置——Chrome，XX-Net，Sogou，Nodejs，Hexo</p>
<p>1.安装Chrome</p>
<pre><code>sudo wget https://repo.fdzh<span class="preprocessor">.org</span>/chrome/google-chrome<span class="preprocessor">.list</span> -P /etc/apt/sources<span class="preprocessor">.list</span>.d/
</code></pre><p>然后导入谷歌软件的公钥，用于下面步骤中对下载软件进行验证。命令将返回“OK”。</p>
<pre><code>wget -<span class="keyword">q</span> -O - http<span class="variable">s:</span>//<span class="keyword">dl</span>.google.<span class="keyword">com</span>/linux/linux_signing_key.pub  | sudo apt-key <span class="built_in">add</span> -
</code></pre><p>然后执行如下命令：</p>
<pre><code>sudo apt-<span class="built_in">get</span> <span class="keyword">update</span>
sudo apt-<span class="built_in">get</span> install google-chrome-stable
</code></pre><p>2.配置XX-Net</p>
<p>按照<a href="https://github.com/XX-net/XX-Net/wiki/%E4%BD%BF%E7%94%A8Chrome%E6%B5%8F%E8%A7%88%E5%99%A8" target="_blank" rel="external">说明文档</a>进行下载配置.</p>
<p>3.搜狗输入法</p>
<p>下载地址：<a href="http://pinyin.sogou.com/linux/" target="_blank" rel="external">http://pinyin.sogou.com/linux/</a></p>
<p>安装：</p>
<pre><code><span class="tag">sudo</span> <span class="tag">dpkg</span> <span class="tag">-i</span> <span class="tag">sogoupinyin_2</span><span class="class">.1</span><span class="class">.0</span><span class="class">.0082_amd64</span><span class="class">.deb</span>
</code></pre><p>若出现问题安装错误时，或是由于缺少依赖，因此可执行如下语句：</p>
<pre><code>sudo apt-<span class="keyword">get</span> install -f
</code></pre><p>然后再次执行安装命令即可：</p>
<pre><code><span class="tag">sudo</span> <span class="tag">dpkg</span> <span class="tag">-i</span> <span class="tag">sogoupinyin_2</span><span class="class">.1</span><span class="class">.0</span><span class="class">.0082_amd64</span><span class="class">.deb</span>
</code></pre><p>4.搭建hexo</p>
<p>4.1安装nodejs</p>
<p>一个是通过ubuntu自带的包管理进行安装。不过它自带的版本可能过低，所以需要添加源：</p>
<pre><code>sudo<span class="instruction"> add-apt-repository </span>ppa:chris-lea/node.js
sudo apt-get update
sudo apt-get install nodejs
</code></pre><p>创建一个nodejs到node的软链接:</p>
<pre><code>sudo ln -s <span class="regexp">/usr/</span>bin<span class="regexp">/nodejs /u</span>sr<span class="regexp">/bin/</span>node
</code></pre><p>4.2安装Git</p>
<pre><code>sudo apt-<span class="keyword">get</span> install git
</code></pre><p>4.3安装hexo</p>
<pre><code><span class="preprocessor"># 创建目录</span>
mkdir hexo
<span class="preprocessor"># 切换目录</span>
cd hexo
<span class="preprocessor"># 全局安装 Hexo，需要最高权限，记得输入root密码</span>
sudo apt-<span class="keyword">get</span> install npm
sudo npm install -g hexo-cli
<span class="preprocessor"># 初始化 Hexo</span>
hexo init
</code></pre><p>安装插件</p>
<pre><code>npm <span class="operator"><span class="keyword">install</span> hexo-generator-<span class="keyword">index</span> <span class="comment">--save</span>
npm <span class="keyword">install</span> hexo-generator-archive <span class="comment">--save</span>
npm <span class="keyword">install</span> hexo-generator-category <span class="comment">--save</span>
npm <span class="keyword">install</span> hexo-generator-tag <span class="comment">--save</span>
npm <span class="keyword">install</span> hexo-<span class="keyword">server</span> <span class="comment">--save</span>
npm <span class="keyword">install</span> hexo-deployer-git <span class="comment">--save</span>
npm <span class="keyword">install</span> hexo-deployer-heroku <span class="comment">--save</span>
npm <span class="keyword">install</span> hexo-deployer-rsync <span class="comment">--save</span>
npm <span class="keyword">install</span> hexo-deployer-openshift <span class="comment">--save</span>
npm <span class="keyword">install</span> hexo-renderer-marked <span class="comment">--save</span>
npm <span class="keyword">install</span> hexo-renderer-stylus <span class="comment">--save</span>
npm <span class="keyword">install</span> hexo-generator-feed <span class="comment">--save</span>
npm <span class="keyword">install</span> hexo-generator-sitemap <span class="comment">--save</span></span>
</code></pre><p>测试安装成功</p>
<pre><code>hexo <span class="keyword">server</span>
</code></pre><p>4.4配置本机全局git环境<br>首先请使用邮箱注册github账号，否则会影响下面操作，记住你注册的邮箱。</p>
<pre><code>git config --global user<span class="class">.email</span> <span class="string">"you@example.com"</span>
git config --global user<span class="class">.name</span> <span class="string">"Your Name"</span>
</code></pre><p>生成SSH秘钥</p>
<pre><code><span class="comment"># -C后面跟住你在github的用户名邮箱，这样公钥才会被github认可</span>
 ssh-keygen -t rsa -C you<span class="property">@example</span>.com
 <span class="comment"># 回车后，输入一个文件夹名字，存储新的SSH 秘钥</span>
<span class="regexp">/home/username/</span>.ssh/id_rsa
<span class="comment"># 查看 公钥内容 稍后加入Github 账户的 sshkey中</span>
 less ~/.ssh/id_rsa.pub
</code></pre><p>将id_rsa.pub中的文本拷贝到github设置SSh。</p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
      

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-Ubuntu backup" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/12/28/Ubuntu backup/" class="article-date">
  	<time datetime="2016-12-28T12:41:49.000Z" itemprop="datePublished">2016-12-28</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Ubuntu Backup</p>
<ol>
<li>backup</li>
</ol>
<p>然后打开终端，输入以下命令：</p>
<pre><code>sudo su
<span class="built_in">cd</span> /  <span class="comment">##转到根目录</span>
</code></pre><p>然後，下面就是我用来备份我的系统的完整的命令：</p>
<pre><code>tar -cvpzf /media/gwang/<span class="type">Work</span>/backup.tgz --exclude=/<span class="keyword">proc</span> --exclude=/lost+found --exclude=/mnt --exclude=/sys --exclude=/media --exclude=/tmp /
</code></pre><p>PS:</p>
<p>tar 是用来备份的程序</p>
<p>c - 新建一个备份文档</p>
<p>v - 详细模式， tar程序将在屏幕上实时输出所有信息。</p>
<p>p - 保存权限，并应用到所有文件。</p>
<p>z - 采用‘gzip’压缩备份文件，以减小备份文件体积。</p>
<p>f - 说明备份文件存放的路径， /media/sda7/backup.tgz 是本例子中备份文件名。这个备份文件备份的位置是其它分区，也就是原来的WIN分区中。因为我的根目录的空间不足，所以只有备份在其它的地方了。</p>
<p>—excloude - 排除指定目录,使其不被备份</p>
<ol>
<li><p>Linux 中美妙的事情之一就是在系统正在运行的情况下可以进行还原操作，而不需要启动光盘或者其他任何乱七八糟的东西。当然，如果您的系统已经崩溃，那您必须选择使用live CD，但是结果还是一样。</p>
<p> tar -xvpzf /media/gwang/Work/backup.tgz -C /</p>
</li>
</ol>
<p>如果您使用的是bz2压缩的：</p>
<pre><code>tar -xvpjf /media/gwang/Work/backup<span class="class">.tar</span><span class="class">.bz2</span> -C /
</code></pre><p>如果系统已经崩溃可以使用Live usb登录，然后</p>
<pre><code>mkdir <span class="regexp">/tmp/</span>root
mount <span class="regexp">/dev/</span>sdaX <span class="regexp">/tmp/</span>root

tar -xvpjf <span class="regexp">/media/g</span>wang<span class="regexp">/Work/</span>backup.tar.bz2 -C <span class="regexp">/tmp/</span>root
</code></pre><p>当然，恢复前可以先</p>
<pre><code>rm -rf <span class="regexp">/tmp/root/</span>* 
</code></pre><p>这样就删除根目录下的所有文件.</p>
<p>这个只是在本机上还原，如果是还原到别的机子上记得修改fstab文件。（可能还需要安装grub）</p>
<p>恢复命令结束时，别忘了重新创建那些在备份时被排除在外的目录：</p>
<pre><code><span class="preprocessor"># mkdir proc</span>
<span class="preprocessor"># mkdir lost+found</span>
<span class="preprocessor"># mkdir mnt</span>
<span class="preprocessor"># mkdir sys</span>
<span class="preprocessor"># mkdir media</span>
</code></pre>
      
    </div>
    
    <div class="article-info article-info-index">
      
      
      

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-数据挖掘界领军人物谢邦昌" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/11/29/数据挖掘界领军人物谢邦昌/" class="article-date">
  	<time datetime="2016-11-29T10:08:05.000Z" itemprop="datePublished">2016-11-29</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>好文丨数据挖掘界领军人物谢邦昌：深度剖析Data Mining </p>
<p>谢邦昌</p>
<p>深度剖析Data Mining</p>
<p><strong>简介</strong><br>谢邦昌教授，是台北医学大学医务管理学系研究所暨大数据研究中心及管理学院主任，也是数据挖掘界领军人物及世界知名统计学家，他对数据挖掘的定义是：Data Mining是从巨大数据仓储中找出有用信息的一种过程与技术。</p>
<p><strong>Data Mining主要功能</strong></p>
<p>Data Mining实际应用功能可分为三大类六分项来说明：Classification和Clustering属于分类区隔类；Regression和Time-series属于推算预测类；Association和Sequence则属于序列规则类。</p>
<p>Classification是根据一些变量的数值做计算，再依照结果作分类。（计算的结果最后会被分类为几个少数的离散数值，例如将一组数据分为 “可能会响应” 或是 “可能不会响应” 两类）。</p>
<p>Classification常被用来处理如前所述之邮寄对象筛选的问题。我们会用一些根据历史经验已经分类好的数据来研究它们的特征，然后再根据这些特征对其他未经分类或是新的数据做预测。</p>
<p>这些我们用来寻找特征的已分类数据可能是来自我们的现有的客户数据，或是将一个完整数据库做部份取样，再经由实际的运作来测试；譬如利用一个大型邮寄对象数据库的部份取样来建立一个Classification Model，再利用这个Model来对数据库的其它数据或是新的数据作分类预测。</p>
<p>Clustering用在将数据分群，其目的在于将群间的差异找出来，同时也将群内成员的相似性找出来。Clustering与Classification不同的是，在分析前并不知道会以何种方式或根据来分类。所以必须要配合专业领域知识来解读这些分群的意义。</p>
<p>Regression是使用一系列的现有数值来预测一个连续数值的可能值。若将范围扩大亦可利用Logistic Regression来预测类别变量，特别在广泛运用现代分析技术如类神经网络或决策树理论等分析工具，推估预测的模式已不在止于传统线性的局限，在预测的功能上大大增加了选择工具的弹性与应用范围的广度。</p>
<p>Time-Series Forecasting与Regression功能类似，只是它是用现有的数值来预测未来的数值。两者最大差异在于Time-Series所分析的数值都与时间有关。Time-Series Forecasting的工具可以处理有关时间的一些特性，譬如时间的周期性、阶层性、季节性以及其它的一些特别因素（如过去与未来的关连性）。</p>
<p>Association是要找出在某一事件或是数据中会同时出现的东西。举例而言，如果A是某一事件的一种选择，则B也出现在该事件中的机率有多少。（例如：如果顾客买了火腿和柳橙汁，那么这个顾客同时也会买牛奶的机率是85%。）</p>
<p>Sequence Discovery与Association关系很密切，所不同的是Sequence Discovery中事件的相关是以时间因素来作区隔（例如：如果A股票在某一天上涨12%，而且当天股市加权指数下降，则B股票在两天之内上涨的机率是 68%） 。</p>
<p><strong>目前业界最常用的Data Mining分析工具</strong></p>
<p>Data Mining工具市场大致可分为三类：</p>
<ol>
<li><p>一般分析目的用的软件包：<br>SAS Enterprise Miner<br>Microsoft SQL Server 2005 – 2008<br>IBM Intelligent Miner<br>Unica PRW<br>SPSS Clementine<br>SGI MineSet<br>Oracle Darwin<br>Angoss KnowledgeSeeker<br>Statistica</p>
</li>
<li><p>针对特定功能或产业而研发的软件：<br>KD1（针对零售业）<br>Options &amp; Choices（针对保险业）<br>HNC（针对信用卡诈欺或呆帐侦测）<br>Unica Model 1（针对营销业）</p>
</li>
<li><p>整合DSS（Decision Support Systems）/OLAP/Data Mining的大型分析系统：<br>Cognos Scenario and Business Objects</p>
</li>
</ol>
<p><strong>对于刚刚接触Data Mining的人来说，怎样把它学好？</strong></p>
<p>先从问题着手，Domain Knowledge 是很重要的具体应重视三方面的问题：</p>
<ol>
<li><p>强调需求，重视过程和结果。虽然统计学和数据挖掘一样，都是在寻求实际数据解决方案的过程中成长起来的，然而统计学家更关注模型，运用数据仅仅是为了发现新的模型，而数据挖掘则更强调知识的价值，模型是用来发现知识的工具。强调需求，重视过程和结果才能实现统计创新。</p>
</li>
<li><p>借鉴机器学习的特点，提炼方法，以算法的形式体现方法。统计学早已脱离正态的传统框架发展方法。但是，由于统计最新的可以被直接使用的成果太少，不仅阻碍了人们对统计方法的运用，甚至造成对先进统计方法的不甚了解。数据挖掘的兴起，为统计学与信息技术的结合带来了发展的契机。计算机技术将成为继数学之后，又一推动统计学发展的强大工具。</p>
</li>
<li><p>发挥统计软件的优势。许多“傻瓜”统计软件的设计，更适合统计学家研究使用，任何一个初通统计的数据分析员要想通过软件来进行数据分析，都极有可能由于对数据涵义的不求甚解，导致脱离实际的统计模型的滥用，数据挖掘软件也是如此；Clementine、SQL Server 2005及SAS和S-plus被设计为可以通过编程来调节软件的默认属性，用这样的软件工作可以增强统计研究者的算法意识；最后，统计软件为统计研究的目的，在图形和可视化方面的互动操作，应该在数据挖掘的软件中体现这一思想，因为它可以帮助数据分析员理解高维数据复杂的结构。</p>
</li>
</ol>
<p>从数据挖掘在国际上的发展来看，数据挖掘的研究重点已从提出概念和发现方法，转向系统应用和方法创新上，研究注重多种发现策略和技术的集成，以及多种学科之间的相互渗透，数据挖掘技术迫切需要系统、科学的理论体系作为其发展的有力支撑。</p>
<p>最近，由经验统计方法和人工智能相结合而产生的衍生技术，如分类回归树（Classification And Regression Tree, 简称CART），卡方自动交互探测法（Chi-square Automatic Interaction Detector，简称CHAID）等前沿方法，以算法的形式展示了统计和信息技术结合发展的新方向。这些都预示着数据挖掘技术与统计学的集成已成为必然的趋势。</p>
<p>我们坚信，随着统计学与现代信息技术的融合，在方法上不断进行新的探索，一定会为统计学和数据挖掘未来的发展开辟一片新的天地。</p>
<p><strong>Web Mining 和Data Mining的区别</strong></p>
<p>如果将Web视为CRM的一个新的Channel，则Web Mining便可单纯看做Data Mining应用在网络数据的泛称。</p>
<p>该如何测量一个网站是否成功？哪些内容、优惠、广告是人气最旺的？主要访客是哪些人？什么原因吸引他们前来？如何从堆积如山之大量由网络所得数据中找出让网站运作更有效率的操作因素？以上种种皆属Web Mining 分析之范畴。</p>
<p>Web Mining 不仅只限于一般较为人所知的log file分析，除了计算网页浏览率以及访客人次外，举凡网络上的零售、财务服务、通讯服务、政府机关、医疗咨询、远距教学等等，只要由网络连结出的数据库够大够完整，所有Off-Line可进行的分析，Web Mining都可以做，甚或更可整合Off-Line及On-Line的数据库，实施更大规模的模型预测与推估，毕竟凭借因特网的便利性与渗透力再配合网络行为的可追踪性与高互动特质，一对一营销的理念是最有机会在网络世界里完全落实的。</p>
<p><strong>整体而言，Web Mining具有以下特性</strong></p>
<ol>
<li><p>资料收集容易且不引人注意，所谓凡走过必留下痕迹，当访客进入网站后的一切浏览行为与历程都是可以立即被纪录的；</p>
</li>
<li><p>以交互式个人化服务为终极目标，除了因应不同访客呈现专属设计的网页之外，不同的访客也会有不同的服务；</p>
</li>
<li><p>可整合外部来源数据让分析功能发挥地更深更广，除了log file、cookies、会员填表数据、在线调查数据、在线交易数据等由网络直接取得的资源外，结合实体世界累积时间更久、范围更广的资源，将使分析的结果更准确也更深入。</p>
</li>
<li><p>利用Data Mining技术建立更深入的访客数据剖析，并赖以架构精准的预测模式，以期呈现真正智能型个人化的网络服务，是Web Mining努力的方向。</p>
</li>
<li><p>Data Warehousing（资料仓储） 和Data Mining 之间的关系若将Data Warehousing比喻作矿坑，Data Mining就是深入矿坑采矿的工作。毕竟Data Mining不是一种无中生有的魔术，也不是点石成金的炼金术，若没有够丰富完整的数据，是很难期待Data Mining能挖掘出什么有意义的信息的。</p>
</li>
</ol>
<p>要将庞大的数据转换成为有用的信息，必须先有效率地收集信息。随着科技的进步，功能完善的数据库系统就成了最好的收集资料的工具。「数据仓储」，简单地说，就是搜集来自其它系统的有用数据，存放在一整合的储存区内。所以其实就是一个经过处理整合，且容量特别大的关系型数据库，用以储存决策支持系统（Design Support System）所需的数据，供决策支持或数据分析使用。从信息技术的角度来看，数据仓储的目标是在组织中，在正确的时间，将正确的数据交给正确的人。</p>
<p>许多人对于Data Warehousing和Data Mining时常混淆，不知如何分辨。其实，数据仓储是数据库技术的一个新主题，在数据科技日渐普及下，利用计算机系统帮助我们操作、计算和思考，让作业方式改变，决策方式也跟着改变。数据仓储本身是一个非常大的数据库，它储存着由组织作业数据库中整合而来的数据，特别是指从在线交易系统OLTP（On-Line Transactional Processing）所得来的数据。</p>
<p>将这些整合过的数据置放于数据仓储中，而公司的决策者则利用这些数据作决策；但是，这个转换及整合数据的过程，是建立一个数据仓储最大的挑战。因为将作业中的数据转换成有用的的策略性信息是整个数据仓储的重点。综上所述，数据仓储应该具有这些数据：整合性数据（integrated data）、详细和汇总性的数据(detailed and summarized data)、历史数据、解释数据的数据。</p>
<p>从数据仓储挖掘出对决策有用的信息与知识，是建立数据仓储与使用Data Mining的最大目的，两者的本质与过程是两码子事。</p>
<p>换句话说，数据仓储应先行建立完成，Data Mining才能有效率的进行，因为数据仓储本身所含数据是干净(不会有错误的数据参杂其中）、完备，且经过整合的。因此两者关系或许可解读为「 Data Mining是从巨大数据仓储中找出有用信息的一种过程与技术」。</p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
      

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-初探计算机视觉的三个源头、兼谈人工智能｜正本清源" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/11/22/初探计算机视觉的三个源头、兼谈人工智能｜正本清源/" class="article-date">
  	<time datetime="2016-11-22T13:09:59.000Z" itemprop="datePublished">2016-11-22</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>初探计算机视觉的三个源头、兼谈人工智能｜正本清源</p>
<p>2016-11-22 视觉求索</p>
<p>谈话人：</p>
<p>杨志宏   视觉求索公众号编辑</p>
<p>朱松纯   加州大学洛杉矶分校UCLA统计学和计算机科学教授</p>
<p>Song-Chun Zhu<br>　<br>www.stat.ucla.edu/~sczhu</p>
<p>时间: 2016年10月 </p>
<p>杨: 朱教授，你在计算机视觉领域耕耘20余年，获得很多奖项， 是很资深的研究人员。近年来你又涉足认知科学、机器人和人工智能。受 《视觉求索公众号》编辑部委托，我想与你探讨一下计算机视觉的起源，这个学科是什么时候创建的， 有哪些创始和代表人物。兼谈一下目前热门的人工智能。</p>
<p>朱: 好， 我们首先谈一下为什么需要讨论这个问题。 然后， 再来探讨一下计算机视觉的三个重要人物David Marr， King-Sun Fu， Ulf Grenander以及他们的学术思想。我认为他们是这个领域的主要创始人、或者叫有重要贡献的奠基人物。</p>
<p>第一节： 为什么要追溯计算机视觉的源头， 这有什么现实意义?</p>
<p>中国有句很有名的话：“一个民族如果忘记了历史,她也注定将失去未来。”  我认为这句话对一个学科来讲，同样发人深省。我们先来看看现实的状况吧。</p>
<p>首先，假设你当前是一个刚刚进入计算机视觉领域的研究生，很快你会有一种错觉，觉得这个领域好像就是5年前诞生的。 跟踪最新发表的视觉的论文，很少有文章能够引用到5年之前的文献，大部分文献只是2-3年前的，甚至是1年之内的。现在的信息交换比较快，大家都在比一些 Benchmarks,把结果挂到arXiv 网上发布。 很少有一些认真的讨论追溯到10年前，20年前， 或30年前的一些论文，提及当时的一些思想和框架性的东西。现在大家都用同样的方法，只是比拼，你昨天是18.3%的记录（错误率），我今天搞到17.9%了。大家都相当短视，那么研究生毕业以后变成了博士，可能也会带学生做研究，他只知道这几年的历史和流行的方法的话，怎么可能去传承这个学科，让其长期健康发展呢？特别是等当前这一波方法退潮之后，这批人就慢慢失去了根基和源创力。这是一个客观的现象。</p>
<p>其次，还有一个现象是，随着视觉与机器学习结合，再混合到人工智能的这么一个社会关注度很高的领域去以后，目前各种工业界，资本、投资界都往这里面来炒作。所以，你可以在互联网上看到各种推送的文字，什么这个大师，那个什么牛人、达人说得有声有色，一大堆封号。中国是有出“大师”的肥沃的土壤的，特别是在这个万众创新、浮躁的年代。 这些文字在混淆公众的视听。也有的是一些中国的研究人员、研究生， 半懂不懂，写出来一些， 某某梳理机器学习、神经网络和人工智能的历史大事。说得神乎其神。我的大学同学把这种帖子转发给我，让我担忧。</p>
<p>杨：这大多是以学术的名义写的软文，看起来像学术文章，实际上就是带广告性质的，一般都是说创投、创业公司里的人，带着资本的目的，带商业推广性质的。</p>
<p>朱: 我甚至不排除有些教授，比如与硅谷结合很紧密的、在IT公司或者风投公司兼职的，有意识地参与、引领这种炒作。</p>
<p>这对我们的年轻学生其实是很致命的，因为他们不了解这背后的动机， 缺乏免疫力。而且现在年轻人和公众都依赖短平快的社交媒体，很少去读专业文献。当公众的思想被这些文字占领了，得出错误的社会性的共识，变成了 false common sense， 对整个社会， 甚至对学术界，都会产生长久的负面冲击。</p>
<p>这就形成了新时代的皇帝的新装。我们需要对这种现象发声， 做一些严肃的探讨。所以，正本清源有着重要的现实意义。</p>
<p>第二节：计算机视觉和人工智能、机器学习的关系</p>
<p>杨：谈到这里，我想先问一下计算机视觉和人工智能是什么关系？还有机器学习这三个东西。</p>
<p>朱：人工智能是在60年代中后期起步的。一直到80年代，翻开它的教科书，就是一些启发式搜索，研究最多的是下棋， 从国际象棋一直到最近的围棋，都是比较抽象的表达。棋盘的位置是有限的、下棋的动作也是有限的， 没有感知和动作执行的不确定性。 所有的问题都变成一个图搜索的问题，教科书上甚至出现了一个通用图搜索算法号称可以解决任何人工智能问题。当时视觉问题还没引起大家重视。我这里有一份1966  年7月 的  MIT AI 实验室的第100号报告（备忘录memo 100），很短，题目叫做“The Summer Vision Project”。这个备忘录的基本意思就是暑假的时候找几个学生构造一个视觉系统。他们当时可能就觉得这个问题基本上是不需要做什么研究的。所以你就一个暑假，几个人一起写个程序，就把它干掉算了。现在说起来，当然是个笑话。</p>
<p>人的大脑皮层的活动， 大约70%是在处理视觉相关信息。视觉就相当于人脑的大门，其它如听觉、触觉、味觉那都是带宽较窄的通道。视觉相当于八车道的高速， 其它感觉是两旁的人行道。如果不能处理视觉信息的话，整个人工智能系统是个空架子，只能做符号推理，比如下棋、定理证明， 没法进入现实世界。所以你刚才问到的人工智能和计算机视觉的关系，视觉，它相当于说芝麻开门。大门就在这里面，这个门打不开, 就没法研究真实世界的人工智能。</p>
<p>到80年代，人工智能， 连带机器人研究就跌入了低谷， 所谓的冬天。那个时候，很多实验室都改名字了， 因为拿不到经费了。 客观来说，80年代， 一个微型计算机的它的内存只有640K字节，还不到一兆（1MB一百万字节），我们现在一张图像，随便就是几个兆的大小，它根本无法读入一张图像，还谈什么理解呢？等到我做博士论文的时候（1992-1996），我导师把当时哈佛机器人实验室最好的SUN工作站给我用，也就是32兆字节。我们实验室花了25万美元构建了一个图像采集系统，因为当时没有数字照相机。可以这么说，一直到90年代中期的时候，我们基本上不具备研究视觉这个问题的硬件条件和数据基础。只能用一些特征点的对应关系做射影几何，用一些线条做形状分析。因为图像做不了，所以80年代计算机视觉的研究，很大部分是做几何。</p>
<p>杨：90 年代后，就是数字照相机大量生产了。</p>
<p>朱：在90年代的末期的时候，发生了一个叫做感知器的革命。带动了大数据和机器学习的蓬勃发展。</p>
<p>杨：那机器学习与计算机视觉的关系呢？</p>
<p>朱：计算机视觉是一个domain， 它有很多问题要研究， 就像物理学。 而机器学习基本是一个方法和工具，就像数学和统计学。 这个名词的兴起应该还是最近的事情， 在我看来，是来自于两股人马。 80年代人工智能走入低谷后，迎来了人工神经网络的一个高潮， 所谓的从符号主义到连接主义的过渡。在中国80年代与气功、人体科学一起走红，但这基本是昙花一现。到了90年代初， 退潮之后，就开始搞 NIPS这个会议， 引入统计的方法来做。还有一股就是做模式识别的一些工程人员EECS 背景的。 按道理来说， 这个领域应该叫做 统计学习 （Statistical Learning），因为它的方法都是由概率统计领域拿来的。这些人中的领军人物很有商业头脑， 把统计和物理的数理模型， 改名叫做机器， 比如<strong>模型（model）就叫</strong>机（machine），把一些层次模型（hierarchical model）说成是“网”（net）。这样，搞出了几个“机”和“网”之后， 这个领域就有了地盘。另一方面，我的那些做统计的同事们也都老实、图个清静，不与他们去争论， 也大多无力去争。当然，统计学领域也有不少人参与了机器学习的浪潮。简单说，机器学习中的 “机器”就是统计模型，“学习”就是用数据来拟合模型。 是由做计算机的人抢占了统计人的理论和方法，然后，应用到视觉、语音语言等 domains。 我在计算机和统计两个系当教授， 看得一清二楚。 这个问题我以后可以专门讨论。</p>
<p>这个机器学习的群体在2000年之后，加上大量数据的到来，很快就成长了， 商业上取得很大的成功。机器学习和计算机视觉大概有百分之六七十是重合的。顺便说一句，2019年我们两个领域会在一起在洛杉矶开CVPR 和 ICML年会， 我是CVPR19的大会主席。因为学习搞来搞去，最丰富的数据是在视觉（图像和视频）。现在这次机器学习的一些大的动作和工程上的推广工作，还是从计算机视觉这边开始的。</p>
<p>杨：谢谢你讲述人工智能,计算机视觉和机器学习的关系。下面我们回到本次访谈的主题。刚才说了这个感知器革命是90年代以后，出了很多的数据要处理了。那么为什么马尔（Marr）在70年代末思考的问题，在面对我们当今处理这个数据的时候, 还有意义？就是说马尔用了什么方法？什么思路框架？使它有生命力？</p>
<p>朱：好，就回到1975-1980年这个时间段。我们今天的主题是想初步探讨一下计算机视觉的起源。我们这个领域也没有一个统一的教科书来谈这个事情。我认为视觉的起源，可以追溯到三个人，David Marr, King-Sun Fu 和Ulf Grenander。这三个人代表三个完全不同的方面，为计算机视觉这个领域奠定了基础。</p>
<p>杨：好， 我们逐个来介绍吧。</p>
<p>第三节：视觉的开创者之一：David Marr 的学术思想</p>
<p>朱： David Marr 【1945-1980】，中文音译为马尔， 他奠定了这个领域叫做Computational Vision计算视觉，这包含了两个领域： 一个就是计算机视觉（Computer Vision），一个是计算神经学（Computational Neuroscience）。他的工作对认知科学（CognitiveScience）也产生了很深远的影响。</p>
<p>我们计算机视觉CV，第一届国际会议ICCV 1987年就以David Marr的名字来命名最佳论文奖， 而且一直到2007年之前的20年间， 是CV唯一的奖项和最高的荣誉，两年一次。认知科学年会 （CogSci）也设有一个 Marr Prize给最佳的学生论文。这三个领域在80-90年代走得很近， 最近十多年交叉越来越少了。就是说，原来都是亲戚，表兄弟， 现在很少有人在之间走动了。</p>
<p>Marr 1972年从剑桥大学毕业，博士论文是从理论的角度研究大脑功能，具体来说，是研究的小脑， 主管运动的Cerebellum。1973年受MIT 人工智能实验室主任Minsky的邀请， 开始是做访问学者（博士后）。 1977年转为教职。 可是， 1978年冬诊断得了急性白血病。1980年转为正教授不久就去世了， 时年35岁。他在得知来日无多后，就赶紧整理了一本书，就叫 “Vision：A Computational Investigation into the HumanRepresentation and Processing of Visual Information”, 《视觉：从计算的视角研究人的视觉信息表达与处理》。他去世后由学生和同事修订，1982年出版。</p>
<p>杨：“Vision”2010年再版了，再版了以后在亚马逊仍然是卖得很好。</p>
<p>朱：它是个经典的东西。我是1989年冬天本科三年级从中科大认知科学实验室的老师那里，读到这本书的中文译本。因为缺乏背景知识，我当时基本读不懂。因为是中文，每句话都明白，但是一段话就不知道是什么意思了。在过去的20多年中， 我每隔1-2年都会再翻一翻这本书。后来我和同事花了大约8年时间，将他的一些思路转化成数理模型，比如primal sketch。</p>
<p>杨：这个人生故事是可以拍电影的。</p>
<p>朱：的确。 很多年前我与他的大弟子 Shimon Ullman饭桌上谈到这段历史， 他说当时大家到处找药，就是救不过来。当年这是一个30多岁正值科学顶峰的、交叉学科的领军人物。顺便说一句， 当年中日友好，1984播放日本电视剧《血疑》， 那是万人空巷， 感人至深。里面的大岛幸子（三口百惠饰）得的就是同样的病。</p>
<p>可惜， 目前计算机视觉这个领域，你如果去问学生的话，他们很多人都没听说过David Marr。“喔，想起来了，好像有个Marr奖吧”。可是你去问认知科学、神经科学的人，他们基本上对Marr非常的清楚。这也是我所担心的， 计算机视觉的发展太工程化、功利化了，逐步脱离了科学的范畴。这是短视和危险的。最近又受到机器学习来的冲击。</p>
<p>我这里顺便说一句， Marr 对我的另外一个间接的影响。他1973年来到MIT， 就租住在JayantShah的房子里， Shah 与 Minsky很熟， 他当时是研究代数几何（Algebraic geometry）的。 而我导师Mumford也是研究代数几何的， 并获得1974年的菲尔兹奖。他们两人很熟，后来在Shah的影响下，Mumford转入计算机视觉， 他们从提取物体边缘开始 （boundarydetection），也就是产生了著名的 Mumford-Shah 模型，搞图像处理的应用数学人员基本都是从这个模型开始做。这是后话。关于这段历史，我们以后可以展开谈。</p>
<p>杨：好， 那么 Marr的学术贡献是什么呢？</p>
<p>朱：在我看来，David Marr对我们这个学科最主要的贡献有三条。从而基本上可以说，定义了这个学科的格局。</p>
<p>第一条，就是说在那个时代，60年代开始的时候大家已经很多人研究视觉神经生理学、心理学问题。也有人做一些边缘检测的工作。但是，视觉到底要解决哪些问题？是怎么实现的？大家莫衷一是，谈不清楚，那么David Marr的第一个贡献就是分出了三个层次。他说， 要解决这个问题，可以把它分成计算（其实应该说成是表达）、算法、和实现三层次。首先，在表达的层次，我们问一下这是个什么问题呢？如何把它写成一个数学问题。任务是什么？输出是什么？这是独立于解决问题的方法的。其次，对这个数学问题去求解时，可以选择不同的算法， 可以并行或者串行。再次，一个算法如何在硬件上实现，可以用CPU，DSP， 或者神经网络来实现。 很多观察到的心理学和神经科学的现象都是跟系统硬件有关的东西，比如说人的一些注意机制，记忆力。这些应该从表达层面剔除。这样， 视觉就可以从纯粹的理论、计算的角度来研究了。我们可以参考心理学和神经科学的结论， 但这不是主要的。 打个比方，要造飞机， 可以参考鸟类的结构， 但关键还是建立空气动力学，才能从根本上解释这个现象， 并创造各种飞行器， 走得更远。</p>
<p>杨：他这么一说，今天看来好像很自然的可以理解了，但是在当时，可能没有多少人，是把问题这样分解的。</p>
<p>朱：当时分不开。因为当时站在像神经科学和认知科学角度，是拿一些实验现象来说事，但是不知道这个现象是在哪一层出现的。</p>
<p>比如神经网络和目前的深度神经网络的学习，他们的模型（表达）、算法、和实现的结构三层 是混在一起的。就变成一个特用的计算设备， 算法就是由这个结构来实现的。当它性能不好的时候，到底是因为表达不对，还是算法不对，还是实现不对？ 这个不好分析了，目前的神经网络，或者是机器学习，深度学习，它的本源存在这个问题。</p>
<p>以前我们审稿的时候，会追问论文贡献是提出了一个新的模型？还是一个新的算法？在哪一个层级上你有贡献，必须说得清清楚楚。2012年，我作为国际计算机视觉和模式识别年会（CVPR）的大会主席， 就发生一个事件。收到神经网络和机器学习学派的一个领军人物 LeCun的抱怨信，他的论文报告了很好的实验结果， 但是审稿的三个人都认为论文说不清楚到底为什么有这个结果， 就拒稿。他一气之下就说再也不给CVPR投稿了，把审稿意见挂在网上以示抗议。2012 年是个转折点。</p>
<p>现在呢？随着深度学习的红火， 这三层就又混在一块去了。 一般论文直接就报告结果， 一堆表格、曲线图。我就是这么做，然后再这么做，我在某些个数据集上提高了两个百分点，那就行了。你审稿人也别问我这个东西里面有什么贡献，哪个节点代表是什么意思，你别问，我也不知道。那算法收敛了吗？是全局收敛还是一个局部收敛？我也不知道，但是我就提高了两个百分点。</p>
<p>杨：或者要用多少数据来训练材料才能够呢？</p>
<p>朱：对，这个也不用管，而且说不清。反正我这个数据集就提高是吧？所以从这个角度来讲，它就很难是一个科学的方法。可以认为它就是一个工程或者是一个经验的，有点像中医。那么要往前再发展的时候，你必须要理清楚这三层的事情。</p>
<p>杨：对。</p>
<p>朱：那么他第二个贡献的话，是理清视觉到底要计算什么。Marr提出了一个系列的表达，从primal sketch（首要简约图）， 到2 ½ D sketch（深度简约图）， 到3D sketch。 这里面还包含了纹理、立体视觉、运动分析、表面形状、等等。比如说我要估计一个物体的深度和形状，我就估计它的光照，和物理材料特性；还有，三维几何形状怎么去表达？ 他试图去建立一个完整的体系。</p>
<p>现在的视觉就基本上被很多人错误地看成一个分类问题，你给我一张图像，我说这个图像里有一只狗或者没有狗，狗在哪儿都不知道。头在哪？脚在哪？不知道。Marr框架是有秩序的，现在的秩序在做深度学习的人眼中还不存在，或者没有忙过来。各人做各人的分类问题，比如说有人算这个动物分类，有的人算这个家具的分类。各种分类以后，他们之间怎么样的关系呢？要对这个图像或者场景要产生一个整体的语义解释。</p>
<p>第三个贡献，Marr提出了一个非常重要的概念，到现在一直还没有一个完整的解答。他说，计算视觉是一个计算的“过程”。这是什么意思？ 我们以前用贝叶斯方法（以及现在的深度网络）认为视觉就是表达成为一个后验概率，寻求一个最优解。这个解就是图像的解释。这个求解过程就会终止。可是Marr说的这个事情，它不是单纯去求一个解，而是一个连续不断的计算过程。我给你一张图像，你越看、越琢磨，你可能看到的东西会越多。</p>
<p>我给你一秒钟，你可能看到某些东西。我给你一分钟，你可能有另外一种理解，这两个理解可能是不一样的。还有一个重要的概念是你的任务决定了你怎么去看这个图像，比如说我在慌忙之中在做饭，那么我对这个场景，只看其中的很小一部分，足够来完成我的任务就行了。里面好多东西改变你根本没注意到。</p>
<p>杨：好像有些魔术就利用了这一点。</p>
<p>朱：就是， 很多心理学实验表明，你眼睛盯着这个图片看的时候，眼睛不眨，我告诉你这个图片在改变。你盯着看，结果它改了你都没看见。在让你看这个图片的时候，把你的注意力引到某个任务所需要计算的关键要素上，其它部分你就视而不见。视觉是受任务驱动的。而任务是时刻在改变之中。 比方说， 视觉求解不是打一个固定的靶子， 而是打一个运动目标。 </p>
<p>杨：这听起来是一个耳目一新的概念。</p>
<p>朱：回到人工智能这个问题，视觉，它最后的用途，要给机器人用，机器人目前面临一个什么任务，来决定它要计算什么。这第三个贡献是在算法的层面。就是说我根据我们目前面临的任务，我才决定要计算什么。而且人的任务是在不断变化的，在此时此刻我任务都在变化，那么计算的过程中是没完没了地在改变。这个理念到目前，我们目前在研究这个事情，还没有完全实现。就是说，这将是人工智能和机器人视觉的一个关键。</p>
<p>杨：明白。</p>
<p>朱：我们现在很多人研究这个智能，比如说分类问题。他都是从谷歌的一些应用，比如搜索图片、广告投放，变成分类问题。 从而忽视了更大的本质问题。如果说人工智能往前发展机器人，要从机器人的角度来用视觉的话，那么它就有很多不同的任务。我现在做饭，我在打球，我在欣赏风景，这个时候我看到的东西是完全不一样的。我怎么样通过这千千万万的任务，而不是简单一个分类，来驱动我的计算的过程，来找到我的需求，来支持我目前的任务，这是一个巨大的研究的方向。David Marr的思想，到今天，反而意义非常重大，因为大家现在一窝蜂的去搞深度学习，把这些基本东西给忘掉了。但是这才是人工智能和机器人视觉的长远发展方向。</p>
<p>我前两年给过几个谈话，说研究视觉要从一个agent（执行者）的角度，带着任务进来的这么一个人或机器人，主动地去激发视觉。</p>
<p>目前的计算机视觉的研究还有一大部分是由视频监控的应用来驱动的，比如说我检测一些异常现象，看这个人是男还是女？那这也是一种被动的，就是说它只是在看，没有去做。要去做的话，就涉及到因果关系和更多的不确定性。所以现在的研究生觉得，他整天在做机器学习， 就在调参数，就在跟别人比拼百分之几的性能。 一些公司的研究所就报道， 他们在某某问题（数据集）上国际领先了，排名第一了。他们自己也觉得这个研究没多少意思。那是因为他们没有接触到这些基本的问题上来。 </p>
<p>杨：他们可能还没有发现这个问题本身是多么有趣。</p>
<p>朱：因为作为一个科学来发展的话，那它就是要认认真真的来做，把这个理清楚。当前的火热来源于工业界， 工业界没有多少耐心资助他们的研究人员去做科学研究，大家很现实。 那么，David Marr先谈这么多好不好？以后我们可能还会继续深入谈的。</p>
<p>杨：好。那我们第二个人就谈一下傅京孫。</p>
<p>第四节：视觉的开创者之二：傅京孫（King-Sun Fu）的学术思想</p>
<p>朱： David Marr是从这个神经科学和脑科学这个方向来的。傅京孫【1930-1985】，他当时代表的是计算机科学，搞人工智能的人。他是一个有领导才能的人物。他和其他人于1973年组织了第一届国际模式识别会议（ICPR），并担任主席。会议后来演变成国际模式识别学会IAPR，在1976年成立，并被选为其主席。他重组了另外一个IEEE学会下面的模式识别委员会，并于1974年成为其第一任主席，创办了IEEE模式分析和机器智能（PAMI）会刊，并于1978年担任第一任总编。这是目前计算机视觉和相关领域最权威的一本期刊了。很多中国学生现在不知道，这个领域的老大本来是华人。目前， 国际模式识别学会IAPR设立了一个傅京孫奖， 作为终身成就奖， 是模式识别的最高荣誉。</p>
<p>杨：可惜他1985年去世了。听说去世前他每年都在中国举办讲座，并于1978年担任台湾的中央研究院院士。</p>
<p>朱：我正要说的这一点。他去世的时候55岁，在普渡大学，据说他的实验室是一个Chinatown。1978年中国打开国门，中国最早的一批中科院的计算机人员都到他那里进修，在普渡。所以他对中国计算机的发展，可以说是一个贡献非常巨大的人。我也是受到他的恩惠，我大学一二年级就开始跟着科大陈国良老师学习，他之前去普度进修。周末我有时就到陈老师家听他讲外面的一些研究人员和工作。你想想，计算机界那时候华人在美国站住脚的可能没几个人。</p>
<p>杨：对，他对中国计算机发展真的是有历史性的贡献的。我在科学院上研究生的时候，我们那些老师是说他过世太早了，要不然对中国的研究还会更好，他多活10来年就会好很多。</p>
<p>朱：他1985年拿到一个很大的国家项目，好像是开宴会的时候心脏病突发了。 他要是活着，华人在这个领域的话，不止是现在这个样子。不过在他之后， 稍晚一点我们有另外一个杰出华人，黄煦涛（Tom Huang）。他当时也在普渡任教，培养了大量华人研究人员。 我们以后会专门介绍。</p>
<p>杨：傅京孫的故事也可以拍电影。</p>
<p>朱：这是我们这个领域的不幸，两个奠基人很快就走了。他们刚刚把这个地基打起来，人就没了。</p>
<p>杨：那傅的主要贡献是什么呢？</p>
<p>朱：傅京孫的贡献， 我也谈三点。第一个贡献应该就是对这个学科和学会的建设，以及工程师的培养上面，他起到了开创性的作用。一般公认他是模式识别的开山鼻祖，模式识别与计算机视觉分不开的。第二个作用，就是关于他的这个句法结构性的表达与计算，就是句法模式识别，Syntactic Pattern Recognition这个词，这个词其实非常深刻。他在走之前，他那个时候也没有多少数据，那么他只是画一些图，图表性的东西，来表达他的概念，他从计算机这边来的，你想很自然就会用到形式语言，因为计算机里面的几个基础之一是形式语言。逻辑、形式语言，对吧？</p>
<p>杨：这好像是在编译原理里面学到过，因为编译的基础是形式语言。</p>
<p>朱：我们这个世界的模式， 一个最基本的组织原则是composition。一张图像就像语言、句子符合语法结构， 视频中的一个事件也有语法结构。寻找一个层次化、结构化的解释是计算视觉的核心问题。从傅京孫1985年丢下来这个摊子后，基本很少有人去碰。差不多18年以后，我和我第一个博士生继续做图像解译Image Parsing这个方向，于2003年得了Marr马尔奖。然后我和我导师专门于2006年写了一本小书，总结了图像的随机语法。我刚才谈到了，在做识别，做分类的时候，只是单独在分类某一个东西，怎么去把各个识别器和分类器给它整合在一起，变成一个统一的表达？就必须产生一个结构上的表达。现在机器学习界把它换了另外名字，叫做结构化的输出，其实是一个东西。他们提出一个新的名词，把原创的图像解译名称覆盖住，这事现在经常发生。所以我说机器学习领域经常到别人那里偷概念，改头换面。数学界不允许这样做的。我还是坚持把它叫做解译、语法。</p>
<p>因为语法，它就是一些规则，其实语法并不见得是一个确定性的，它可以跟统计连在一块，它也可以跟目前的一些神经网络结合，这个都没问题。它表达了一个骨架或者支柱，形成一个统一表达。</p>
<p>第三点，从算法的角度来讲，有一个层次化的表达以后，意义就不一样了，比如自底向上或自顶向下的计算的过程就可以在上面体现出来，就是马尔说的计算的过程，就可以在这里面体现出来。视觉的计算过程应该是由大量的自底向上（bottom-up）和 自顶向下（top-down）过程交互和同时进行的。顺便再说一句，当前的深度神经网络就是一个feedforward的自底向上的计算， 缺乏自顶向下的过程。而在人脑计算中，自顶向下的计算占据很大一部分。</p>
<p>杨：那就是说， 这个语法结构对计算过程有了规范和表达的途路。</p>
<p>朱：对，你的搜索的过程，这个计算的过程是什么？马尔他提出了第二个概念，说视觉是个计算的过程，那么这个计算过程你什么时候算哪个，这是个调度的问题，就像操作系统。那么David Marr计算的过程，没完没了的，随着你的任务不断改变，那么它就有一个调度的问题。所以说我现在要去做饭，或者我要欣赏风景，或者说我要去走路，开车，那么它的不同的任务产生了不同的进程。这个进程，要在层次化的表达里面的统一起来调度。从这个意义看，感知是计算一个解译图（parse graph）， 认知是对这个parse graph进一步推理扩大， 而机器人的任务规划（task planning）也是一个同样结构的parse graph， 那就更别说语言是用parse graph来表达的。所以，人工智能的一个核心表达就是随机的语法和解译图。   </p>
<p>杨：对。</p>
<p>朱：这个是绕不掉的，不管谁来做，都要做这个事情。当然，现在有人千方百计想绕过去，重新发明一套名词， 让新来的学生忘记历史， 这样他们就可以变成社会公认的大师。有些教授、研究人员在学术上没什么原创贡献， 却在网上、社会上成了当红明星, 学科代言人。用社会上的知名度再给学术界施压。</p>
<p>总结一下，傅京孫三点主要贡献：一是学科的人才和组织基础，二是他提出这么一个的语法表达方法， 三是这个表达支撑了自底向上或自顶向下的计算的过程。他去世后， 这个方向一直处于一种休眠状态，我的研究有一条线是跟着这个方向做。2011年马里兰大学周少华他的导师有一个演讲，题目叫：语法模式识别—从傅到朱 （From Fu to Zhu）。我们在继承他的框架往前走。</p>
<p>杨：真好！那么咱们下面就谈第三个人Ulf Grenander。</p>
<p>朱：这个人的话，知道的人非常少。</p>
<p>杨：我翻看了网上资料，他是这个领域里头真正的是大神了，但绝对是个小众人物。</p>
<p>第五节：视觉的开创者之三：Ulf Grenander的学术思想</p>
<p>朱：Ulf Grenander 【1923-2016】是很少有人知道的。感觉有点像金庸小说《天龙八部》里的在藏经阁扫地的灰衣老僧。武功和思想都出神入化，但是，他基本是世外高人，不参与江湖争斗， 金庸也没有交代他的名字。所以江湖上的人大多没听说过他。 这样也好， 他自自在在活了93岁， 今年刚刚去世的。国际应用数学季刊邀请我和其他人写纪念文章，正准备出版专刊呢。</p>
<p>杨：对，我读他的生平，他这个人简直就是把欧洲美洲的，还有俄国的所有的精华的人物都接触过。</p>
<p>朱：那是，他出身在瑞典，他的导师叫Harald Cramér。概率论里面的一个重要的定理，还有数论里的一个猜想是用他命名的。然后，他也跟 Bohr（波尔），Kolmogorov（科尔莫戈罗夫）他们走得比较近。他的起点就是做概率统计， 时间序列， 随机过程，因为你现在想概率论和统计学的一些重要应用，就是那个时候发力了。</p>
<p>杨：从保险业开始了，北欧那边因为航海，保险业非常发达，所以这也有点道理。</p>
<p>朱：关于概率和统计学对于科学、视觉、以及人工智能的重要意义， Mumford 1999年写了一篇论文，是在一个大会的发言，叫做《随机性时代的曙光》（Dawning of the Age of Stochasticity）。</p>
<p>杨：对，那是你们老师写的， 网上能找到。</p>
<p>朱：他总结说，过去两千多年的西方科学的发展是建立在亚里士多德以来的数理逻辑基础之上的。但是，后面一千年包括人工智能、人的思维这些东西是随机性过程。人的思维应该是建立在概率推理基础之上。其实， 我们看到现在的机器学习， 人工智能完全就是从这个方向走了。</p>
<p>杨：你的导师说，整个世界的数学可以用概率的这套思想重新写一遍，就像罗素和怀特海的写这个数学原理似的，可以把数学重新建立起来，用概率的这种思想。</p>
<p>朱：这个工作已经有人做了。E. T. Jaynes就是发明最大熵原理的那个人，他写了一本很厚的书，《Probability Theory: The Logic of Science》， 他就是用这个原理去写。这也是一篇遗作。他没写完就过世了。这也是以后可以谈的话题。</p>
<p>朱： Ulf Grenander就诞生在这么一个概率发源的中心的地带，跟几个大师学习，博士毕业后出来游历，做概率论随机过程的这些东西。到六、七十年代的时候，他就开始提出来，想用数学来把这个模式识别与智能的现象的问题定义清楚。我们前面谈到的David Marr 是从神经科学、认知科学来的。傅京孫是一个计算机科学与工程的人。这两者基本没有多少严格的数学定义，提出的框架是漂浮的。Ulf是从数学的角度，奠定基础。他提出来一个应用数学的分支， 叫做 Pattern Theory。他的出发点完全不同， 就是要给世界上的各种模式、现象， 建立一个数学的框架来研究。 格局就很宏伟。而不是急于去解决某种实际问题， 后者叫做模式识别 （pattern recognition）。 他在90岁高龄出版了最后一本书， 想用数学来研究人的思想是从哪里来的。 你看我们脑袋里的念头、主意也往往是随机产生，像冒泡一样， 所谓思如泉涌。到底怎么来的？</p>
<p>杨：那太了不起了。这个事说起来，我想到当时我的老师是让我读Geman and Geman 1984年的吉布斯采样算法，那就已经了不起了。</p>
<p>朱：Grenander最后落脚在布朗大学应用数学系，Geman是他当年（70年代末80年代初）招到组里的年轻教员之一。这个吉布斯采样（Gibbs Sampler）的算法是一个里程碑的东西，在80年代初引起轰动。但那只是这个学派的诸多贡献的一个片段。</p>
<p>Grenander的理论解释起来的确有点费劲，既然谈历史，我先从我个人的经历谈一下。</p>
<p>他1994年出了一部总结性的书，900多页，叫做《General Pattern Theory》，广义模式理论。有点爱因斯坦做广义相对论的意思。但这本书很抽象， 没多少人读。我1995年在哈佛研究纹理模型（texture models），因为我用的学习算法就是吉布斯采样，在训练的时候，跑一遍要等两个星期才收敛，机器被占了，我就有时间，也是耐着性子把这本书读完了。我估计世界上不超过20人，能有耐心完整地读他的书。然后，我1996年1月答辩论文，我导师和我每周开车去布朗大学参加讨论。波士顿的冬天很冷， 哈佛到布朗1个小时左右，漫天大雪， 我们有时在高速上车被陷住， 下来铲雪。到了6月， 我导师从哈佛提前退休，带着我一起加入布朗的应用数学系。那在当时是一个学术思想的中心。组会里有Grenander，Mumford， Geman 还有其他20来人， 一坐就是2个多小时。这些人都明察秋毫， 做报告的人无法含混过去的， 一步一步都必须理清楚，说不清楚你就下去想， 下次再来。</p>
<p>我一直认为计算机视觉和模式识别领域亏欠Grenander, 因为统计建模和随机计算逐渐成为我们领域的核心理论基础，而大家并不知道，很多思想、算法都源于这个人或者他的学派。所以，2012年， 我主持CVPR（国际计算机视觉和模式识别）大会， 特意放到布朗大学附近召开，我和另外两个主席一说，大家立即就同意了。并特制了一个银质的大奖章， 在大会上颁给他，表达我们的敬意。这里发生很多故事，我们以后再谈吧。</p>
<p>杨：那你能简短总结一下Grenander对计算机视觉、甚至人工智能的主要贡献吗。</p>
<p>朱：还是谈三点主要的吧。 首先，他提出了一个思想， 叫做 analysis-by-synthesis， 这是所谓 产生式建模的核心理念。当你要去识别、分析一个模式，比如一个动物，人脸， 一个事件， 你首先要建立一个数理模型， 这个模型通过数据来拟合， 也就是当前的机器学习。 那么， 判断这个模型好坏， 或者模型是否充分，的一个依据是什么呢？产生式建模的方法就是对这个模型随机抽样，也就是，合成（synthesis）。 我把这个过程直观叫做“计算机之梦”。计算机模型一开始初始化为空（完全随机）， 那它做的梦就是白噪声， 或者一张白纸。通俗来说， 这个模型就是一个“白痴”。人脑有这个功能，我们把眼睛一闭，没有外界输入了，就能做梦， 白日梦就是想象力的体现。一个好的模型采样产生的图片（模式）， 与真实观察的图片（模式）， 就应该是真假难辨。如果你能分辨，那说明这个模型不到位。  现在很多机器学习的方法是没法去随机合成图片的。  举个例子来说，我要检验你是不是真的听懂和理解中文，就看你能不能说流利的中文。如果你说话语法有错，词汇量不够，或者有口音，那就揭示你在哪方面还需要提高。 </p>
<p>杨：这个要求好像比光是听懂 要更严格。</p>
<p>朱：的确。我们当年考英语， 多半是读，说和写都不行。我们考TOEFL， GRE Verbal的时候， 就算没搞懂， 也能蒙个60%-70%。 新东方的题海战术也很奏效。当你做了大量考题， 就算不懂， 也能考好。当前大数据、机器学习就用题海战术。 这个方法强调在实战中检验，考什么就拼命复习什么，不考的东西就不学，这也很有道理，很直接， 来得快。 但是， 因为你的模型没有真正理解， 没有“真懂”，考试大纲外面的东西更不懂， 那么后遗症就是， 遇到新考题， 缺乏泛化能力，遇到新问题，缺乏创造力。</p>
<p>想一想， 如果我的学生一步步考试都是靠题海战术这么学过来的， 那多可怕，要让他们去搞研究、创新，那就基本不可能。很遗憾的是，现在中国学生从幼儿园开始，就是在题海中泡大的。机器人、人工智能，靠题海战术是可以演示不少功能的， 但是， 那还离真正的智能比较遥远。 </p>
<p>杨：好， 我明白这个analysis-by-synthesis 的意义了。他的第二贡献呢？</p>
<p>朱：他提出了一整套建模的理论和方法。把代数、几何、概率整合起来。 代数指的是一些结构，比如群论， 记得在科大本科我学过 群、环、域这些概念吧？也就是说我有一些基本元素，叫 generator，连接成为图graph，然后是群group，在上面进行操作, 产生了各种各样的变化。还有很多几何， 变换， 在连续情况就产生形变。通过组合，语法、产生丰富的图模式。然后，再在这个图模式的空间上定义距离（测度）和概率。</p>
<p>朱：比如一个概率模型， 是定义在一个什么样的结构上，它是个什么样的解空间？这个数理上你必须交代清楚，否则你的论文写不下去了。现在它的一个很大的应用在医疗图像上面，比如说一个病人，他的肝变形了，那么他的肝的形状和正常人的肝的形状之间怎么定义一个合理的距离？两张人脸，怎么定义这个距离的呢？这个距离定义在一个流型上，数学的流型（manifold）。</p>
<p>杨：这些东西真用上了吗？ </p>
<p>朱：他有个Postdoc，名叫Michael Miller， 现在是Johns Hopkins 大学图像中心主任， 就用这一套方法来做医疗图像、脑科学（Brain Mapping）等方面的应用。</p>
<p>杨：他的第三方面的贡献呢？</p>
<p>朱：第三个方面主要是算法上面。当我们去做求解的时候，在一个解空间，这个求解空间肯定是一个非凸的，他有千千万万的局部最优解local minimum 在里面。</p>
<p>杨：对。这是当时八十年代的时候提出来一个很尖锐的问题，好像有什么模拟煺火方法。</p>
<p>朱：很多蒙特卡洛算法都是他和这个学派的人提出来的。这个解空间是一个异构空间，空间里面非常复杂的，包含有很多子空间，子空间里面又包含又子空间，每个子空间维度又不一样，他们之间，从一个解跳到另外一个解的时候，这跳转必须是可逆的。在计算机里面就叫可以回溯。从这个学派走出来的人，他们设计算法每一个步骤都是有章法的，要做到合规合矩。包括上面提到的吉布斯采样算法、可逆蒙特卡洛跳转法，还有变分法（variational methods）和偏微分方程式， 还有一些随机下降法（stochastic gradient）， 这后者是目前训练深度学习模型的主要办法。他也开创了非参数模型的学习方法。这里面东西太多，先谈到这里吧。</p>
<p>正因为很多人没有接触过Grenander的理论， 缺乏这方面的理论素养， 造成我们学科发展的一个巨大的问题：很多教授、博士、研究生就是用别人的模型（机），拿来调试，基本缺乏自己发明新模型、新算法的能力。我们这个领域，很多美国名牌大学助理教授、副教授、教授， 他们的论文中的公式错误百出。现在干脆大家在论文中都不写公式了， 直接报告最后的实验结果，提高了几个百分点。这就“一俊掩百丑”了。 英文有个类似的说法叫做 “sweep the dirt under the carpet把污垢扫到地毯下”。 这些人在大量培养博士、他们出来的人评审论文。 这样一来，学科的发展堪忧！  </p>
<p>第六节：结束语</p>
<p>杨：听了你番谈话，我明白很多。记得我当时念研究生，包括念博士生的时候，实际上是很糊涂的。就是对这个领域到底做多少东西，没有信心。觉得很多研究像画鬼一样，原理不清楚。我觉得那样的话，与其那样做事情, 那不如干脆到工业界那更快乐。</p>
<p>朱：正因为我们这个领域很多历史、框架性的东西，没有搞清楚，培养出来的博士，缺乏分析能力。大家被一些工程的任务和数据驱动，被一些性能的指标牵制，对科学的发展比较迷茫。</p>
<p>杨：好， 谈了很多， 我们做个总结吧。</p>
<p>朱：那我就说两点。 </p>
<p>首先， 我在开场白中提到 “一个民族如果忘记了历史, 她也注定将失去未来。”一个学科要健康发展，需要研究人员、研究生们理解自己领域的历史和大的发展方向，建立文化的认同。否则，自己家的东西，被别人偷取，浑然不知。就像日本打入中国，想把我们的地名改掉，大家开始说日语，把名字都改做山本太郎之类，感觉很酷吗？  或者是韩国人把中国的文化拿去申报世界文化遗产，这都是要制止的。否则，过了一代人，还真说不清楚了。我记得刚来美国的时候，美国同事把汉字叫做“Kang-ji”，说是日本字。  我们领域很多人对保护这个领域的文化和传统缺乏清醒认识。皮之不存，毛将焉附？</p>
<p>其次，一个学科内部，大家互相不够了解，各自为政。特别现在会议审稿人很多是研究生，以自己的狭窄的眼光和标准去评判别人的方法，造成很多混乱。搞工程的看不到理论的重要性，反之亦然。大家又都疏远心理学和认知科学的研究。我提倡我们的研究人员、学生要提高理论修养、培养长远眼光，向相关学科取经，取长补短。</p>
<p>我希望这个微信公众号，能够帮助大家正视问题，让计算机视觉这个领域健康、稳健、可持续地发展。</p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
      

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
  
    <nav id="page-nav">
      <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/2/">Next &raquo;</a>
    </nav>
  
</div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
    	<div class="footer-left">
    		&copy; 2017 Gang Wang
    	</div>
      	<div class="footer-right">
      		<a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/litten/hexo-theme-yilia" target="_blank">Yilia</a> by Litten
      	</div>
    </div>
  </div>
</footer>
    </div>
    
  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">


<script>
	var yiliaConfig = {
		fancybox: true,
		mathjax: true,
		animate: true,
		isHome: true,
		isPost: false,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: false
	}
</script>
<script src="http://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js"></script>
<script src="/js/main.js"></script>






<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


  </div>
</body>
</html>